{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40758 sha256=52a3ce9c9de7e032cb60e8948051387d29b3753f9b6d8dd7dd81098c5b6d656f\n",
      "  Stored in directory: /Users/kevinhall/Library/Caches/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file \n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Ingest and embed\n",
    "1. Recursively load PDFs from documents\\ToSort\\Inspiration_folder\n",
    "2. Split them into chunks\n",
    "3. Generate embeddings using OpenAI\n",
    "4. Save the result as a FAISS vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading PDFs from inspiration folders: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:24<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Total documents loaded: 8775\n",
      "\\nüìÅ Folder distribution in corpus:\n",
      "  - CRP: 260 documents\n",
      "  - Curriculum Development: 286 documents\n",
      "  - NGSS_Documents: 401 documents\n",
      "  - OpenSciEd: 7674 documents\n",
      "  - Equip_Rubric: 154 documents\n",
      "‚úÇÔ∏è Splitting into chunks...\n",
      "üîπ Total chunks: 48564\n",
      "üß† Generating embeddings and saving vectorstore...\n",
      "‚úÖ Saved FAISS vectorstore to: data/embeddings/faiss_index\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Script: Ingest PDFs, Split, Embed, and Save FAISS Vector Store\n",
    "# 5 minutes on MAC\n",
    "# This script loads PDF documents from a specified folder, splits them into chunks, generates embeddings using OpenAI's text-embedding-3-small model, and saves the resulting vector store using FAISS.\n",
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üîß CONFIG\n",
    "pdf_folder = \"documents/ToSort/Inspiration_folder\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "chunk_size = 500\n",
    "chunk_overlap = 50\n",
    "\n",
    "# üì• 1. Load all PDFs (recursive)\n",
    "# === Load All PDFs from Subfolders ===\n",
    "def load_all_pdfs_with_metadata(folder_path):\n",
    "    all_docs = []\n",
    "    pdf_paths = list(Path(folder_path).rglob(\"*.pdf\"))\n",
    "    for path in tqdm(pdf_paths, desc=\"Loading PDFs from inspiration folders\"):\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(path))\n",
    "            docs = loader.load()\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"filename\"] = path.name\n",
    "                doc.metadata[\"source_folder\"] = path.parent.name\n",
    "            all_docs.extend(docs)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {path}: {e}\")\n",
    "    return all_docs\n",
    "\n",
    "# üß± 2. Split into chunks\n",
    "def split_documents(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "# üíæ 3. Save vectorstore\n",
    "def save_vectorstore(chunks, embeddings, output_path=\"data/embeddings/faiss_index\"):\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    vectorstore.save_local(output_path)\n",
    "    print(f\"‚úÖ Saved FAISS vectorstore to: {output_path}\")\n",
    "\n",
    "# üîÑ Run pipeline\n",
    "def ingest_pipeline():\n",
    "    print(\"üìÇ Loading documents...\")\n",
    "    docs = load_all_pdfs_with_metadata(pdf_folder)\n",
    "    print(f\"üìÑ Total documents loaded: {len(docs)}\")\n",
    "\n",
    "    # Show folder distribution\n",
    "    from collections import Counter\n",
    "    folders = [doc.metadata.get(\"source_folder\", \"Unknown\") for doc in docs]\n",
    "    folder_counts = Counter(folders)\n",
    "    print(\"\\üìÅ Folder distribution in corpus:\")\n",
    "    for folder, count in folder_counts.items():\n",
    "        print(f\"  - {folder}: {count} documents\")\n",
    "\n",
    "    print(\"‚úÇÔ∏è Splitting into chunks...\")\n",
    "    chunks = split_documents(docs)\n",
    "    print(f\"üîπ Total chunks: {len(chunks)}\")\n",
    "\n",
    "    print(\"üß† Generating embeddings and saving vectorstore...\")\n",
    "    save_vectorstore(chunks, embedding_model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ingest_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Write prompts to files\n",
    "1. The script write_prompts_to_files.py is now ready. When you run it, it will:\n",
    "2. Create a prompts/ folder if it doesn‚Äôt exist\n",
    "3. Write 3 templated prompt files:\n",
    "4. unit_outline_prompt.txt\n",
    "5. lesson_set_expansion_prompt.txt\n",
    "6. teacher_reflection_prompt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prompts written to: prompts\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Script: Write Prompt Templates to /prompts folder\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "PROMPTS = {\n",
    "    \"unit_outline_prompt.txt\": \"\"\"\n",
    "You are an experienced curriculum design thinking partner for a middle school science teacher. You have \n",
    "full knowledge of creating Next Generation Science Standards (NGSS) aligned lessons supported by understanding\n",
    "of the EQuIP Rubric for Lessons & Units: Science as well as Culturally Responsive Pedagogy.\n",
    "Use the retrieved examples from high-quality NGSS and OpenSciEd units to help generate a general outline for a new unit.\n",
    "Your task is to design a High Quality unit that is culturally relevant and responsive to the students' community context rooted in and NGSS.\n",
    "Design a unit on the topic of: {topic}\n",
    "Grade Level: {grade_level}\n",
    "Student Context: {student_context}\n",
    "\n",
    "As you design, consider how this unit can:\n",
    "- Reflect students‚Äô cultural identities or community experiences\n",
    "- Promote inclusive participation and multiple ways of knowing in science\n",
    "- Encourage relevance to students' local lives and social issues\n",
    "\n",
    "The output should include:\n",
    "1. Title of the Unit\n",
    "2. NGSS Anchoring Phenomenon\n",
    "3. Driving Question\n",
    "4. Summary of the storyline arc (8-10 descriptive sentences in length)\n",
    "5. List of 3‚Äì5 Lesson Sets (1 paragraph each)\n",
    "6. List of 3‚Äì5 Key Investigations (1 paragraph each)\n",
    "6. NGSS Performance Expectations (if known or retrievable)\n",
    "7. Suggested Teacher Reflection Prompts\n",
    "\n",
    "# Inspiration Context:\n",
    "{context}\n",
    "\n",
    "# Draft Unit Outline:\n",
    "\"\"\",\n",
    "\n",
    "    \"lesson_set_expansion_prompt.txt\": \"\"\"\n",
    "You are continuing the collaborative curriculum design process for a middle school science teacher.\n",
    "Expand the following lesson set description into a complete lesson sequence.\n",
    "\n",
    "Student Context: {student_context}\n",
    "Grade Level: {grade_level}\n",
    "Lesson Set Description: {lesson_summary}\n",
    "\n",
    "Use examples from high-quality instructional materials to generate:\n",
    "1. Lesson Titles\n",
    "2. Learning Objectives\n",
    "3. Key Activities or Investigations\n",
    "4. Instructional Strategies and Supports\n",
    "5. Assessment Opportunities\n",
    "6. Optional: Opportunities for integrating cultural knowledge or community assets\n",
    "\n",
    "# Related Context:\n",
    "{context}\n",
    "\n",
    "# Expanded Lesson Set:\n",
    "\"\"\",\n",
    "\n",
    "    \"teacher_reflection_prompt.txt\": \"\"\"\n",
    "After reviewing the generated unit plan or lesson sequence, reflect on the following:\n",
    "\n",
    "1. How might this unit connect to students' lived experiences?\n",
    "2. What voices or perspectives might be missing?\n",
    "3. Are there opportunities to center local knowledge or community partnerships?\n",
    "4. How does this unit reflect your values as a science educator?\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# ‚úçÔ∏è Save to prompts folder\n",
    "def write_prompts(folder_path=\"prompts\"):\n",
    "    Path(folder_path).mkdir(parents=True, exist_ok=True)\n",
    "    for filename, content in PROMPTS.items():\n",
    "        with open(Path(folder_path) / filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content.strip())\n",
    "    print(f\"‚úÖ Prompts written to: {folder_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    write_prompts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load Prompts\n",
    "1. The script Load Prompts Dynamic is ready and will:\n",
    "2. Load any .txt prompt file from the prompts/ folder\n",
    "3. Wrap it as a PromptTemplate for use in LangChain chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prompts loaded successfully.\n",
      "\n",
      "--- Unit Outline Prompt ---\n",
      "\n",
      "You are an experienced curriculum design thinking partner for a middle school science teacher. You have \n",
      "full knowledge of creating Next Generation Science Standards (NGSS) aligned lessons supported by understanding\n",
      "of the EQuIP Rubric for Lessons & Units: Science as well as Culturally Responsive Pedagogy.\n",
      "Use the retrieved examples from high-quality NGSS and OpenSciEd units to help generate a gen...\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Utility Script: Load Prompt Templates from Files\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def load_prompt_from_file(file_path: str) -> PromptTemplate:\n",
    "    \"\"\"Loads a prompt template from a text file and returns a LangChain PromptTemplate.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompt_text = f.read()\n",
    "    return PromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = Path(\"prompts\")\n",
    "\n",
    "    unit_prompt = load_prompt_from_file(base_path / \"unit_outline_prompt.txt\")\n",
    "    lesson_prompt = load_prompt_from_file(base_path / \"lesson_set_expansion_prompt.txt\")\n",
    "    reflection_prompt = load_prompt_from_file(base_path / \"teacher_reflection_prompt.txt\")\n",
    "\n",
    "    print(\"‚úÖ Prompts loaded successfully.\")\n",
    "    print(\"\\n--- Unit Outline Prompt ---\\n\")\n",
    "    print(unit_prompt.template[:400] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Teacher Outline generator\n",
    "1. Prompts for topic, grade, and student context\n",
    "2. Loads your custom unit design prompt\n",
    "3. Pulls relevant examples using your vectorstore\n",
    "4. Generates a rich outline with GPT-4\n",
    "5. Saves the result as a .md file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Generating unit outline... Please wait...\n",
      "\n",
      "\n",
      "üìù Generated Unit Plan:\n",
      "\n",
      "1. Title of the Unit: \"Biology and Society: Understanding Sex, Gender, and Athletic Performance\"\n",
      "\n",
      "2. NGSS Anchoring Phenomenon: The differences in athletic performance between individuals of different biological sexes, and how these differences are influenced by genetic mutations and societal perceptions of gender.\n",
      "\n",
      "3. Driving Question: \"How do biological sex, genetic mutations, and societal understanding of gender influence athletic performance?\"\n",
      "\n",
      "4. Summary of the Storyline Arc: \n",
      "The unit begins with students observing a local sports event, noting differences in performance between male and female athletes. They then explore the concepts of biological sex and gender, understanding that while they are often used interchangeably, they are distinct. Students will learn about the role of chromosomes in determining biological sex and how genetic mutations can affect the development of sex characteristics. They will then investigate how these biological factors can influence athletic performance. The unit concludes with a discussion on societal perceptions of gender and how these can impact opportunities and expectations in athletics. Throughout the unit, students will be encouraged to consider their local context and the implications of these concepts on their community.\n",
      "\n",
      "5. Lesson Sets:\n",
      "   - Lesson 1: Observing and Discussing Local Sports Events\n",
      "   - Lesson 2: Understanding Biological Sex and Gender\n",
      "   - Lesson 3: Exploring Chromosomes and Genetic Mutations\n",
      "   - Lesson 4: Investigating the Impact of Biology on Athletic Performance\n",
      "   - Lesson 5: Discussing Societal Perceptions of Gender in Athletics\n",
      "\n",
      "6. Key Investigations:\n",
      "   - Investigation 1: Observing Differences in Athletic Performance\n",
      "   - Investigation 2: Modeling Chromosomes and Genetic Mutations\n",
      "   - Investigation 3: Researching the Biological Factors Influencing Athletic Performance\n",
      "   - Investigation 4: Exploring Societal Perceptions of Gender in Local Athletics\n",
      "   - Investigation 5: Reflecting on the Impact of Biology and Society on Athletic Performance\n",
      "\n",
      "7. NGSS Performance Expectations: \n",
      "   - HS-LS1-4: Use a model to illustrate the role of cellular division (mitosis) and differentiation in producing and maintaining complex organisms.\n",
      "   - HS-LS3-1: Ask questions to clarify relationships about the role of DNA and chromosomes in coding the instructions for characteristic traits passed from parents to offspring.\n",
      "\n",
      "8. Suggested Teacher Reflection Prompts:\n",
      "   - How did students' understanding of biological sex and gender evolve throughout the unit?\n",
      "   - How effectively did students apply their understanding of genetics to the context of athletic performance?\n",
      "   - How did the unit promote inclusive participation and multiple ways of knowing in science?\n",
      "   - How did students connect the content to their local lives and social issues?\n",
      "   - How can this unit be improved to better reflect students‚Äô cultural identities or community experiences?\n",
      "\n",
      "‚úÖ Saved unit plan to: unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_200924.md\n",
      "‚úÖ Saved structured JSON to: unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_200924.json\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Updated Notebook Script: Teacher Input + Unit Outline Generator with JSON Output\n",
    "\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": None,\n",
    "        \"lesson_sets\": [],\n",
    "        \"investigations\": [],\n",
    "        \"ngss\": None,\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"1. Title\"):\n",
    "            current_section = \"title\"\n",
    "        elif line.startswith(\"2. Anchoring Phenomenon\"):\n",
    "            current_section = \"phenomenon\"\n",
    "        elif line.startswith(\"3. Driving Question\"):\n",
    "            current_section = \"driving_question\"\n",
    "        elif line.startswith(\"4. Summary\"):\n",
    "            current_section = \"summary\"\n",
    "        elif line.startswith(\"5. Lesson Sets\"):\n",
    "            current_section = \"lesson_sets\"\n",
    "        elif line.startswith(\"6. NGSS\"):\n",
    "            current_section = \"ngss\"\n",
    "        elif line.startswith(\"7. Suggested Teacher Reflection\"):\n",
    "            current_section = \"reflection_prompts\"\n",
    "        elif current_section:\n",
    "            if current_section in [\"lesson_sets\", \"reflection_prompts\"] and line.startswith(\"-\"):\n",
    "                sections[current_section].append(line[1:].strip())\n",
    "            elif current_section in [\"title\", \"phenomenon\", \"driving_question\", \"summary\", \"ngss\"] and line:\n",
    "                if not sections[current_section]:\n",
    "                    sections[current_section] = line\n",
    "                else:\n",
    "                    sections[current_section] += f\" {line}\"\n",
    "\n",
    "    return sections\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Prompt Template\n",
    "# -----------------------------\n",
    "prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    vectorstore_path,\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Chain\n",
    "# -----------------------------\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Simulated Teacher Input\n",
    "# -----------------------------\n",
    "topic = input(\"üß™ What is the topic for the unit? \")\n",
    "grade_level = input(\"üéì What is the grade level? \")\n",
    "student_context = input(\"üë• Describe the student/community context: \")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Run Chain and Save Output\n",
    "# -----------------------------\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "print(\"\\nü§ñ Generating unit outline... Please wait...\\n\")\n",
    "outline_response = rag_chain.invoke(data)\n",
    "print(\"\\nüìù Generated Unit Plan:\\n\")\n",
    "print(outline_response)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save as Markdown and JSON\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Markdown\n",
    "md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(outline_response)\n",
    "\n",
    "# JSON\n",
    "sections = extract_sections(outline_response)\n",
    "sections.update(data)\n",
    "json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved unit plan to: {md_path.name}\")\n",
    "print(f\"‚úÖ Saved structured JSON to: {json_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Generating unit outline... Please wait...\n",
      "\n",
      "\n",
      "üìù Generated Unit Plan:\n",
      "\n",
      "1. **Title of the Unit:** \"Understanding Biological Sex, Gender, and Genetic Mutations: A Biological and Sociocultural Exploration\"\n",
      "\n",
      "2. **NGSS Anchoring Phenomenon:** The variation in physical characteristics and athletic abilities among individuals due to differences in biological sex and the impact of genetic mutations.\n",
      "\n",
      "3. **Driving Question:** How do biological sex and gender differ, and how can genetic mutations affect the development of sex characteristics and athletic performance?\n",
      "\n",
      "4. **Summary of the Storyline Arc:** The unit begins by exploring the concepts of biological sex and gender, emphasizing their differences and societal implications. Students then delve into the role of genes in determining biological sex and how mutations can affect the development of sex characteristics. They will examine real-world examples of genetic mutations and their impacts on individuals. The unit then transitions to the influence of biological sex on athletic performance, exploring physiological differences and their effects on various sports. The unit concludes with a discussion on the societal and ethical implications of these biological differences in sports and other areas of life.\n",
      "\n",
      "5. **Lesson Sets:**\n",
      "   - Lesson 1: Introduction to Biological Sex and Gender: This lesson introduces students to the concepts of biological sex and gender, highlighting their differences and societal constructs around them.\n",
      "   - Lesson 2: Role of Genes in Determining Biological Sex: Students explore the role of genes in determining biological sex, including the X and Y chromosomes.\n",
      "   - Lesson 3: Genetic Mutations and Sex Characteristics: This lesson delves into how genetic mutations can affect the development of sex characteristics, using real-world examples.\n",
      "   - Lesson 4: Biological Sex and Athletic Performance: Students investigate how biological sex can influence athletic performance, examining physiological differences.\n",
      "   - Lesson 5: Societal and Ethical Implications: The final lesson involves a discussion on the societal and ethical implications of biological sex differences in sports and other areas of life.\n",
      "\n",
      "6. **Key Investigations:**\n",
      "   - Investigation 1: Research on Genetic Mutations: Students research real-world examples of genetic mutations affecting sex characteristics.\n",
      "   - Investigation 2: Case Study Analysis: Students analyze case studies of athletes with different biological sex characteristics and their performances.\n",
      "   - Investigation 3: Debate on Ethical Implications: Students participate in a debate on the ethical implications of biological sex differences in sports.\n",
      "\n",
      "7. **NGSS Performance Expectations:** HS-LS1-4, HS-LS3-1, HS-LS3-2\n",
      "\n",
      "8. **Suggested Teacher Reflection Prompts:**\n",
      "   - How did students respond to the differentiation between biological sex and gender? \n",
      "   - Were students able to understand and explain the role of genes in determining biological sex?\n",
      "   - How effectively did students apply their understanding of genetic mutations to real-world examples?\n",
      "   - Did students demonstrate a clear understanding of the influence of biological sex on athletic performance?\n",
      "   - Were students able to engage in thoughtful discussion about the societal and ethical implications of biological sex differences?\n",
      "\n",
      "‚úÖ Saved unit plan to: unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_200709.md\n",
      "‚úÖ Saved structured JSON to: unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_200709.json\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Updated Notebook Script: Teacher Input + Unit Outline Generator with JSON Output\n",
    "\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": None,\n",
    "        \"lesson_sets\": [],\n",
    "        \"investigations\": [],\n",
    "        \"ngss\": None,\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Match section headers more flexibly\n",
    "        if re.match(r\"^1\\.\\s*Title\", line, re.IGNORECASE):\n",
    "            current_section = \"title\"\n",
    "        elif re.match(r\"^2\\.\\s*Anchoring Phenomenon\", line, re.IGNORECASE):\n",
    "            current_section = \"phenomenon\"\n",
    "        elif re.match(r\"^3\\.\\s*Driving Question\", line, re.IGNORECASE):\n",
    "            current_section = \"driving_question\"\n",
    "        elif re.match(r\"^4\\.\\s*Summary\", line, re.IGNORECASE):\n",
    "            current_section = \"summary\"\n",
    "        elif re.match(r\"^5\\.\\s*Lesson Sets\", line, re.IGNORECASE):\n",
    "            current_section = \"lesson_sets\"\n",
    "        elif re.match(r\"^6\\.\\s*NGSS\", line, re.IGNORECASE):\n",
    "            current_section = \"ngss\"\n",
    "        elif re.match(r\"^7\\.\\s*Suggested Teacher Reflection\", line, re.IGNORECASE):\n",
    "            current_section = \"reflection_prompts\"\n",
    "        elif current_section:\n",
    "            if current_section in [\"lesson_sets\", \"reflection_prompts\", \"investigations\"]:\n",
    "                # Accept bullets or numbered list items\n",
    "                if re.match(r\"^[-*]\\s+\", line) or re.match(r\"^\\d+\\.\\s+\", line):\n",
    "                    clean_text = re.sub(r\"^[-*\\d.]+\\s+\", \"\", line)\n",
    "                    sections[current_section].append(clean_text.strip())\n",
    "                elif line:\n",
    "                    # Unprefixed continuation lines inside list items\n",
    "                    sections[current_section].append(line.strip())\n",
    "            elif current_section in [\"title\", \"phenomenon\", \"driving_question\", \"summary\", \"ngss\"] and line:\n",
    "                if not sections[current_section]:\n",
    "                    sections[current_section] = line\n",
    "                else:\n",
    "                    sections[current_section] += f\" {line}\"\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Prompt Template\n",
    "# -----------------------------\n",
    "prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    vectorstore_path,\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Chain\n",
    "# -----------------------------\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Simulated Teacher Input\n",
    "# -----------------------------\n",
    "topic = input(\"üß™ What is the topic for the unit? \")\n",
    "grade_level = input(\"üéì What is the grade level? \")\n",
    "student_context = input(\"üë• Describe the student/community context: \")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Run Chain and Save Output\n",
    "# -----------------------------\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "print(\"\\nü§ñ Generating unit outline... Please wait...\\n\")\n",
    "outline_response = rag_chain.invoke(data)\n",
    "print(\"\\nüìù Generated Unit Plan:\\n\")\n",
    "print(outline_response)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save as Markdown and JSON\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Markdown\n",
    "md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(outline_response)\n",
    "\n",
    "# JSON\n",
    "sections = extract_sections(outline_response)\n",
    "sections.update(data)\n",
    "json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved unit plan to: {md_path.name}\")\n",
    "print(f\"‚úÖ Saved structured JSON to: {json_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Generating unit outline... Please wait...\n",
      "\n",
      "\n",
      "üìù Generated Unit Plan:\n",
      "\n",
      "**Title of the Unit:**\n",
      "Climate Justice: Local Actions, Global Impact\n",
      "\n",
      "**NGSS Anchoring Phenomenon:**\n",
      "The increasing frequency and intensity of wildfires in California and their disproportionate impact on marginalized communities.\n",
      "\n",
      "**Driving Question:**\n",
      "How can we, as a community, address climate justice to mitigate the impacts of climate change on vulnerable populations in Oakland?\n",
      "\n",
      "**Summary of the Storyline Arc:**\n",
      "This unit explores the concept of climate justice through the lens of local environmental challenges and their broader global implications. Students will begin by examining the science behind climate change, focusing on the specific impacts seen in California, such as wildfires and air quality issues. They will investigate how these environmental changes disproportionately affect marginalized communities, particularly in urban areas like Oakland. Through a series of investigations, students will analyze data, engage with community members, and explore historical and current social justice movements. The unit will culminate in students designing and proposing actionable solutions to promote climate justice in their community, integrating scientific understanding with social and political action. Throughout the unit, students will reflect on their cultural identities and community experiences, fostering a deeper connection to the material and empowering them to become agents of change.\n",
      "\n",
      "**List of 3‚Äì5 Lesson Sets:**\n",
      "\n",
      "1. **Understanding Climate Change:**\n",
      "   Students will explore the scientific principles behind climate change, including the greenhouse effect and carbon cycle. They will analyze local climate data and compare it to global trends, developing an understanding of how climate change manifests in their community.\n",
      "\n",
      "2. **Impacts on Local Communities:**\n",
      "   This lesson set focuses on the social and environmental impacts of climate change in Oakland. Students will investigate case studies of local communities affected by wildfires and poor air quality, emphasizing the disproportionate effects on marginalized groups.\n",
      "\n",
      "3. **Community Voices and Climate Justice:**\n",
      "   Students will engage with community leaders and activists to understand ongoing efforts to address climate justice. They will participate in discussions and interviews, learning about the intersection of environmental science and social justice.\n",
      "\n",
      "4. **Designing Solutions:**\n",
      "   In this set, students will work collaboratively to design solutions that address climate justice issues in their community. They will integrate scientific knowledge with insights from community interactions to propose actionable plans.\n",
      "\n",
      "5. **Taking Action:**\n",
      "   The final lesson set focuses on implementing and reflecting on proposed solutions. Students will present their projects to community stakeholders and receive feedback, fostering a sense of empowerment and responsibility.\n",
      "\n",
      "**List of 3‚Äì5 Key Investigations:**\n",
      "\n",
      "1. **Wildfire Simulation and Analysis:**\n",
      "   Students will use computational models to simulate wildfire scenarios and analyze the factors contributing to their frequency and intensity. They will assess the impact of these fires on air quality and public health.\n",
      "\n",
      "2. **Community Air Quality Monitoring:**\n",
      "   In this investigation, students will collect and analyze air quality data from different neighborhoods in Oakland. They will identify patterns and discuss the implications for community health and climate justice.\n",
      "\n",
      "3. **Historical Context of Climate Justice:**\n",
      "   Students will research historical events and policies that have contributed to environmental inequities. They will analyze how these historical contexts shape current climate justice challenges.\n",
      "\n",
      "4. **Interviews with Local Activists:**\n",
      "   Students will conduct interviews with local activists and community leaders to gain insights into grassroots efforts for climate justice. They will document these stories and reflect on their implications for scientific and social action.\n",
      "\n",
      "5. **Solution Design Workshop:**\n",
      "   In this hands-on investigation, students will brainstorm and prototype solutions to local climate justice issues. They will use design thinking principles to iterate on their ideas and prepare for community presentations.\n",
      "\n",
      "**NGSS Performance Expectations:**\n",
      "- HS-ESS3-1: Construct an explanation based on evidence for how the availability of natural resources, occurrence of natural hazards, and climate change have influenced human activity.\n",
      "- HS-ESS3-4: Evaluate or refine a technological solution that reduces impacts of human activities on natural systems.\n",
      "- HS-ETS1-3: Evaluate a solution to a complex real-world problem based on prioritized criteria and trade-offs that account for a range of constraints, including cost, safety, reliability, and aesthetics, as well as possible social, cultural, and environmental impacts.\n",
      "\n",
      "**Suggested Teacher Reflection Prompts:**\n",
      "1. How did students' cultural identities and community experiences influence their engagement with the unit?\n",
      "2. In what ways did the unit promote inclusive participation and multiple ways of knowing in science?\n",
      "3. How effectively did the unit connect scientific concepts to students' local lives and social issues?\n",
      "4. What challenges did students face in designing and proposing solutions, and how were these addressed?\n",
      "5. How can the unit be adapted or expanded to further enhance its relevance and impact on students' understanding of climate justice?\n",
      "\n",
      "‚úÖ Saved unit plan to: unit_outline_climate_justice_9th_grade_20250411_093836.md\n",
      "‚úÖ Saved structured JSON to: unit_outline_climate_justice_9th_grade_20250411_093836.json\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Updated Notebook Script: Teacher Input + Unit Outline Generator with JSON Output\n",
    "\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": None,\n",
    "        \"lesson_sets\": [],\n",
    "        \"investigations\": [],\n",
    "        \"ngss\": None,\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Directly extract inline values with colon headers\n",
    "        if match := re.match(r'^1\\.\\s*Title of the Unit:\\s*[\"‚Äú]?(.*)[\"‚Äù]?$', line):\n",
    "            sections[\"title\"] = match.group(1).strip()\n",
    "            current_section = None\n",
    "        elif match := re.match(r'^2\\.\\s*NGSS Anchoring Phenomenon:\\s*(.*)$', line):\n",
    "            sections[\"phenomenon\"] = match.group(1).strip()\n",
    "            current_section = None\n",
    "        elif match := re.match(r'^3\\.\\s*Driving Question:\\s*[\"‚Äú]?(.*)[\"‚Äù]?$', line):\n",
    "            sections[\"driving_question\"] = match.group(1).strip()\n",
    "            current_section = None\n",
    "        elif re.match(r'^4\\.\\s*Summary', line):\n",
    "            current_section = \"summary\"\n",
    "        elif re.match(r'^5\\.\\s*Lesson Sets', line):\n",
    "            current_section = \"lesson_sets\"\n",
    "        elif re.match(r'^6\\.\\s*Key Investigations', line):\n",
    "            current_section = \"investigations\"\n",
    "        elif re.match(r'^7\\.\\s*NGSS Performance Expectations', line):\n",
    "            current_section = \"ngss\"\n",
    "        elif re.match(r'^8\\.\\s*Suggested Teacher Reflection', line):\n",
    "            current_section = \"reflection_prompts\"\n",
    "        elif current_section:\n",
    "            if current_section in [\"lesson_sets\", \"investigations\", \"reflection_prompts\"]:\n",
    "                # Accept bulleted list items\n",
    "                if re.match(r\"^[-*]\\s+\", line):\n",
    "                    clean_text = re.sub(r\"^[-*]\\s+\", \"\", line)\n",
    "                    sections[current_section].append(clean_text.strip())\n",
    "            elif current_section in [\"summary\", \"ngss\"]:\n",
    "                if not sections[current_section]:\n",
    "                    sections[current_section] = line\n",
    "                else:\n",
    "                    sections[current_section] += f\" {line}\"\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Prompt Template\n",
    "# -----------------------------\n",
    "prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    vectorstore_path,\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Chain\n",
    "# -----------------------------\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Simulated Teacher Input\n",
    "# -----------------------------\n",
    "topic = input(\"üß™ What is the topic for the unit? \")\n",
    "grade_level = input(\"üéì What is the grade level? \")\n",
    "student_context = input(\"üë• Describe the student/community context: \")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Run Chain and Save Output\n",
    "# -----------------------------\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "print(\"\\nü§ñ Generating unit outline... Please wait...\\n\")\n",
    "outline_response = rag_chain.invoke(data)\n",
    "print(\"\\nüìù Generated Unit Plan:\\n\")\n",
    "print(outline_response)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save as Markdown and JSON\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Markdown\n",
    "md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(outline_response)\n",
    "\n",
    "# JSON\n",
    "sections = extract_sections(outline_response)\n",
    "sections.update(data)\n",
    "json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved unit plan to: {md_path.name}\")\n",
    "print(f\"‚úÖ Saved structured JSON to: {json_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Generating unit outline... Please wait...\n",
      "\n",
      "\n",
      "üìù Generated Unit Plan:\n",
      "\n",
      "Unit Title: \n",
      "\"Climate Justice in Our Backyard: Understanding and Addressing Environmental Inequities in Oakland\"\n",
      "\n",
      "NGSS Anchoring Phenomenon: \n",
      "Why does Oakland, a city with a significant Black and Brown population, experience more severe effects of climate change compared to other cities?\n",
      "\n",
      "Driving Question: \n",
      "How can we leverage scientific understanding and community knowledge to combat environmental injustice and promote climate resilience in Oakland?\n",
      "\n",
      "Unit Summary: \n",
      "In this unit, students will delve into the science behind climate change and its disproportionate impacts on communities of color, particularly in their hometown of Oakland. They will explore real-life case studies from their local area, examining how systemic racism and policy decisions have led to disparities in pollution exposure, heat stress, and access to green spaces. Students will learn how to analyze environmental data, investigate local solutions, and advocate for climate justice. The unit will culminate with students developing action plans or advocacy campaigns to promote climate justice in their own communities.\n",
      "\n",
      "Lesson Sets: \n",
      "\n",
      "1. Climate Science and Environmental Justice: Introduction to climate change and its impacts, with a focus on environmental justice principles and how they apply to Oakland.\n",
      "\n",
      "2. Community Impacts and Local Data: Analysis of local environmental data, including air and water quality, and exploration of how these issues affect students' communities.\n",
      "\n",
      "3. Investigating Solutions: Evaluation of potential solutions, such as green infrastructure, and brainstorming of new ideas to address local environmental problems.\n",
      "\n",
      "4. Taking Action: Development of student-led action plans or advocacy campaigns to promote climate justice in Oakland.\n",
      "\n",
      "Key Investigations: \n",
      "\n",
      "1. Analysis of Local Environmental Data: Students will analyze local environmental data to understand the specific climate-related challenges facing their communities.\n",
      "\n",
      "2. Case Study Exploration: Students will explore case studies of environmental injustice in Oakland, understanding the historical and systemic factors that have led to these issues.\n",
      "\n",
      "3. Solution Evaluation and Brainstorming: Students will evaluate potential solutions to local environmental problems and brainstorm new ideas.\n",
      "\n",
      "4. Action Plan Development: Students will develop action plans or advocacy campaigns to promote climate justice in their communities.\n",
      "\n",
      "NGSS Performance Expectations: \n",
      "HS-ESS3-1, HS-ESS3-4, HS-LS2-7, HS-ETS1-3\n",
      "\n",
      "Suggested Teacher Reflection Prompts: \n",
      "\n",
      "1. How did students connect the scientific concepts of climate change to their local context in Oakland?\n",
      "2. In what ways did students demonstrate understanding of environmental justice principles?\n",
      "3. How did students engage with the process of analyzing environmental data and proposing solutions?\n",
      "4. What strategies were most effective in promoting inclusive participation and multiple ways of knowing in science?\n",
      "5. How did the unit foster relevance to students' local lives and social issues?\n",
      "\n",
      "‚úÖ Saved unit plan to: unit_outline_climate_justice_9th_grade_20250411_090204.md\n",
      "‚úÖ Saved structured JSON to: unit_outline_climate_justice_9th_grade_20250411_090204.json\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Updated Notebook Script: Teacher Input + Unit Outline Generator with Enhanced JSON Output\n",
    "\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": \"\",\n",
    "        \"lesson_sets\": {},\n",
    "        \"investigations\": {},\n",
    "        \"ngss\": [],\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    current_section = None\n",
    "    lines = markdown_text.splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Header with inline content handling\n",
    "        if re.match(r\"^1\\.\", line):\n",
    "            current_section = \"title\"\n",
    "            sections[\"title\"] = line.split(\":\", 1)[1].strip().strip(\"\\\"\") if \":\" in line else \"\"\n",
    "            continue\n",
    "        elif re.match(r\"^2\\.\", line):\n",
    "            current_section = \"phenomenon\"\n",
    "            sections[\"phenomenon\"] = line.split(\":\", 1)[1].strip().strip(\"\\\"\") if \":\" in line else \"\"\n",
    "            continue\n",
    "        elif re.match(r\"^3\\.\", line):\n",
    "            current_section = \"driving_question\"\n",
    "            sections[\"driving_question\"] = line.split(\":\", 1)[1].strip().strip(\"\\\"\") if \":\" in line else \"\"\n",
    "            continue\n",
    "        elif re.match(r\"^4\\.\", line):\n",
    "            current_section = \"summary\"\n",
    "            continue\n",
    "        elif re.match(r\"^5\\.\", line):\n",
    "            current_section = \"lesson_sets\"\n",
    "            continue\n",
    "        elif re.match(r\"^6\\.\", line):\n",
    "            current_section = \"investigations\"\n",
    "            continue\n",
    "        elif re.match(r\"^7\\.\", line):\n",
    "            current_section = \"ngss\"\n",
    "            continue\n",
    "        elif re.match(r\"^8\\.\", line):\n",
    "            current_section = \"reflection_prompts\"\n",
    "            continue\n",
    "\n",
    "        if current_section in [\"lesson_sets\", \"investigations\"]:\n",
    "            match = re.match(r\"^[-*]?\\s*(Lesson|Investigation)\\s*(\\d+):?\\s*(.*)\", line)\n",
    "            if match:\n",
    "                key = f\"{match.group(1)} {match.group(2)}\"\n",
    "                val = match.group(3).strip().strip(\"\\\"\")\n",
    "                sections[current_section][key] = val\n",
    "            else:\n",
    "                match2 = re.match(r\"^[-*]\\s*(.*)\", line)\n",
    "                if match2:\n",
    "                    key = f\"{current_section.title()} {len(sections[current_section]) + 1}\"\n",
    "                    sections[current_section][key] = match2.group(1).strip(\"\\\"\")\n",
    "\n",
    "        elif current_section == \"ngss\":\n",
    "            standards = re.findall(r\"HS-[A-Z]+\\d+-\\d+[^-\\n]*\", line)\n",
    "            sections[\"ngss\"].extend(standards)\n",
    "\n",
    "        elif current_section == \"reflection_prompts\":\n",
    "            match = re.match(r\"^[-*]\\s*(.*)\", line)\n",
    "            if match:\n",
    "                sections[current_section].append(match.group(1).strip(\"\\\"\"))\n",
    "\n",
    "        elif current_section == \"summary\":\n",
    "            sections[\"summary\"] += line + \" \"\n",
    "\n",
    "    sections[\"summary\"] = sections[\"summary\"].strip()\n",
    "    return sections\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Prompt Template\n",
    "# -----------------------------\n",
    "prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    vectorstore_path,\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Chain\n",
    "# -----------------------------\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Simulated Teacher Input\n",
    "# -----------------------------\n",
    "topic = input(\"üß™ What is the topic for the unit? \")\n",
    "grade_level = input(\"üéì What is the grade level? \")\n",
    "student_context = input(\"üë• Describe the student/community context: \")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Run Chain and Save Output\n",
    "# -----------------------------\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "print(\"\\nü§ñ Generating unit outline... Please wait...\\n\")\n",
    "outline_response = rag_chain.invoke(data)\n",
    "print(\"\\nüìù Generated Unit Plan:\\n\")\n",
    "print(outline_response)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save as Markdown and JSON\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Markdown\n",
    "md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(outline_response)\n",
    "\n",
    "# JSON\n",
    "sections = extract_sections(outline_response)\n",
    "sections.update(data)\n",
    "json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved unit plan to: {md_path.name}\")\n",
    "print(f\"‚úÖ Saved structured JSON to: {json_path.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Lesson_expansion_generator\n",
    "\n",
    "1. Accepts a short lesson summary\n",
    "2. Pulls relevant examples using MMR search\n",
    "3. Expands it into a full lesson sequence (titles, objectives, strategies, etc.)\n",
    "4. Saves the output to a markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding Lesson 1...\n",
      "Expanding Lesson 2...\n",
      "Expanding Lesson 3...\n",
      "Expanding Lesson 4...\n",
      "Expanding Lesson 5...\n",
      "\n",
      "‚úÖ Saved expanded lessons to: lesson_expansions_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_234405.md\n",
      "‚úÖ Saved lesson JSON to: lesson_expansions_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_234405.json\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Lesson Expansion Script: Expand All Lesson Sets in Unit JSON\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# -----------------------------\n",
    "# Config and Paths\n",
    "# -----------------------------\n",
    "json_file_path = \"outputs/unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_234405.json\"  # UPDATE with actual filename\n",
    "prompt_path = Path(\"prompts\") / \"lesson_set_expansion_prompt.txt\"\n",
    "\n",
    "# -----------------------------\n",
    "# Load JSON Data from Unit Outline\n",
    "# -----------------------------\n",
    "with open(json_file_path, encoding=\"utf-8\") as f:\n",
    "    unit_data = json.load(f)\n",
    "\n",
    "lesson_sets = unit_data.get(\"lesson_sets\", {})\n",
    "\n",
    "# -----------------------------\n",
    "# Load Prompt and LLM\n",
    "# -----------------------------\n",
    "lesson_prompt = PromptTemplate.from_template(Path(prompt_path).read_text(encoding=\"utf-8\"))\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# Define Lesson Expansion Chain\n",
    "# -----------------------------\n",
    "lesson_chain = (\n",
    "    RunnableMap({\n",
    "        \"lesson_summary\": lambda x: x[\"lesson_summary\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x[\"grade_level\"],\n",
    "        \"context\": lambda x: x.get(\"context\", \"\")\n",
    "    })\n",
    "    | lesson_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Expand All Lessons\n",
    "# -----------------------------\n",
    "all_expansions = {}\n",
    "\n",
    "for lesson_title, lesson_summary in lesson_sets.items():\n",
    "    lesson_data = {\n",
    "        \"lesson_summary\": lesson_summary,\n",
    "        \"student_context\": unit_data[\"student_context\"],\n",
    "        \"grade_level\": unit_data[\"grade_level\"],\n",
    "        \"context\": unit_data.get(\"phenomenon\", \"\")\n",
    "    }\n",
    "    print(f\"Expanding {lesson_title}...\")\n",
    "    expansion = lesson_chain.invoke(lesson_data)\n",
    "    all_expansions[lesson_title] = expansion\n",
    "\n",
    "# -----------------------------\n",
    "# Save to JSON and Markdown\n",
    "# -----------------------------\n",
    "timestamp = json_file_path.split(\"unit_outline_\")[1].replace(\".json\", \"\")\n",
    "base_filename = f\"lesson_expansions_{timestamp}\"\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Markdown\n",
    "md_path = output_dir / f\"{base_filename}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for title, content in all_expansions.items():\n",
    "        f.write(f\"## {title}\\n\\n{content}\\n\\n\")\n",
    "\n",
    "# JSON\n",
    "json_path = output_dir / f\"{base_filename}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_expansions, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved expanded lessons to: {md_path.name}\")\n",
    "print(f\"‚úÖ Saved lesson JSON to: {json_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lesson Expansion Script ===\n",
      "\n",
      "=== Found the following Lesson Sets portion ===\n",
      "\n",
      "List of Lesson Sets:\n",
      "   - Lesson 1: Introduction to Biological Sex and Gender: Understanding the differences and societal implications.\n",
      "   - Lesson 2: The Role of Genes in Sex Determination: Exploring the genetic basis of biological sex.\n",
      "   - Lesson 3: Genetic Mutations and Variations: Examining how mutations can affect sex characteristics.\n",
      "   - Lesson 4: Biological Sex Characteristics and Athletic Performance: Investigating the potential impacts on sports and competition.\n",
      "   - Lesson 5: Reflecting on Gender Categories in Sports: Discussing the implications of biological sex characteristics for gender divisions in athletics.\n",
      "6. NGSS Performance Expectations: \n",
      "   - HS-LS1-4: Use a model to illustrate the role of cellular division (mitosis) and differentiation in producing and maintaining complex organisms.\n",
      "   - HS-LS3-1: Ask questions to clarify relationships about the role of DNA and chromosomes in coding the instructions for characteristic traits passed from parents to offspring.\n",
      "7. Suggested Teacher Reflection Prompts:\n",
      "   - How did students' understanding of the difference between biological sex and gender evolve throughout the unit?\n",
      "   - Did students demonstrate an understanding of how genetic mutations can affect sex characteristics?\n",
      "   - How did students respond to the discussion of biological sex characteristics' impact on athletic performance?\n",
      "   - How effectively did the unit promote inclusive participation and respect for diverse perspectives on gender?\n",
      "   - How can I improve the unit to better reflect students' cultural identities and community experiences?\n",
      "\n",
      "==============================================\n",
      "\n",
      "Loading Vector Store for expansions if needed ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Lesson expansions saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpansions_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 115\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# 10) Run the chain\u001b[39;00m\n\u001b[1;32m    110\u001b[0m data_for_expansion \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m: lesson_summary,\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_context\u001b[39m\u001b[38;5;124m\"\u001b[39m: student_context,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m\"\u001b[39m: grade_level\n\u001b[1;32m    114\u001b[0m }\n\u001b[0;32m--> 115\u001b[0m expansions_response \u001b[38;5;241m=\u001b[39m \u001b[43mexpansions_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_for_expansion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== EXPANDED LESSONS ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(expansions_response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:3144\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3132\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3133\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3134\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3143\u001b[0m         ]\n\u001b[0;32m-> 3144\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3145\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:3144\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3132\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3133\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3134\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3143\u001b[0m         ]\n\u001b[0;32m-> 3144\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3145\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:3961\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3959\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m   3960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3963\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3968\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3969\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3970\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3971\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1624\u001b[0m         Output,\n\u001b[0;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1633\u001b[0m     )\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:3835\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3833\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   3834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3835\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   3837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3838\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   3839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 102\u001b[0m, in \u001b[0;36mmain.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     94\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# 9) Construct a chain \u001b[39;00m\n\u001b[1;32m     97\u001b[0m expansions_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     98\u001b[0m     RunnableMap({\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_context\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_context\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m--> 102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msome query about expansions for \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlesson_summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     })\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;241m|\u001b[39m lesson_expansion_prompt\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# 10) Run the chain\u001b[39;00m\n\u001b[1;32m    110\u001b[0m data_for_expansion \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m: lesson_summary,\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_context\u001b[39m\u001b[38;5;124m\"\u001b[39m: student_context,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m\"\u001b[39m: grade_level\n\u001b[1;32m    114\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/retrievers.py:141\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mstr\u001b[39m, config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    140\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/retrievers.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    244\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    248\u001b[0m         result,\n\u001b[1;32m    249\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/retrievers.py:238\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 238\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/vectorstores.py:705\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    703\u001b[0m     docs \u001b[38;5;241m=\u001b[39m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities]\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 705\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_marginal_relevance_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:757\u001b[0m, in \u001b[0;36mFAISS.max_marginal_relevance_search\u001b[0;34m(self, query, k, fetch_k, lambda_mult, filter, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmax_marginal_relevance_search\u001b[39m(\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    733\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    739\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    740\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs selected using the maximal marginal relevance.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[38;5;124;03m    Maximal marginal relevance optimizes for similarity to query AND diversity\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;124;03m        List of Documents selected by maximal marginal relevance.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search_by_vector(\n\u001b[1;32m    759\u001b[0m         embedding,\n\u001b[1;32m    760\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:156\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function\u001b[38;5;241m.\u001b[39membed_query(text)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not callable"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Updated Lesson Expansion Script \n",
    "# This code reads the \"unit_outline_*.md\" file from the Outline step, \n",
    "# parses out the \"List of Lesson Sets\", and then helps the teacher expand \n",
    "# one chosen lesson set.\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1) Load the lesson expansion prompt from file (or define inline)\n",
    "def load_prompt_from_file(prompt_path: Path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return PromptTemplate.from_template(text)\n",
    "\n",
    "def parse_lesson_sets_from_file(filename: Path) -> str:\n",
    "    \"\"\"\n",
    "    Tries to locate the 'List of Lesson Sets' portion from the unit outline file,\n",
    "    returning them as a single text string. \n",
    "    If not found, returns empty string.\n",
    "    \"\"\"\n",
    "    content = filename.read_text(encoding=\"utf-8\")\n",
    "    \n",
    "    # A naive approach: Look for heading that says \"List of Lesson Sets\"\n",
    "    # and read the subsequent lines up to the next heading or blank line \n",
    "    # This is just an example. You may refine or do a better parse.\n",
    "    pattern = r\"(List of Lesson Sets.*?)(?:\\n\\n|\\Z)\"\n",
    "    match = re.search(pattern, content, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    print(\"=== Lesson Expansion Script ===\")\n",
    "\n",
    "    # 2) We assume the teacher's previously generated unit outline is saved \n",
    "    # as something like \"unit_outline_7th_grade.md\".\n",
    "    # We'll ask the teacher for that filename here or use a default:\n",
    "    default_outline_file = \"outputs/unit_outline_7th_grade.md\"\n",
    "    outline_file_str = input(f\"Enter path to your unit outline markdown file [default: {default_outline_file}]: \").strip()\n",
    "    if not outline_file_str:\n",
    "        outline_file_str = default_outline_file\n",
    "    outline_file = Path(outline_file_str)\n",
    "    if not outline_file.exists():\n",
    "        print(f\"Error: Outline file '{outline_file}' does not exist.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 3) Parse out the \"List of Lesson Sets\"\n",
    "    lesson_sets_text = parse_lesson_sets_from_file(outline_file)\n",
    "    if not lesson_sets_text:\n",
    "        print(\"Warning: Could not find 'List of Lesson Sets' in the outline. The teacher may have to do this step manually.\")\n",
    "        print(\"Full file content:\\n\", outline_file.read_text(encoding='utf-8'))\n",
    "    \n",
    "    # Show teacher the lesson sets\n",
    "    print(\"\\n=== Found the following Lesson Sets portion ===\\n\")\n",
    "    print(lesson_sets_text)\n",
    "    print(\"\\n==============================================\\n\")\n",
    "\n",
    "    # 4) In your original Outline code, you might have stored the grade level & context. \n",
    "    # For demonstration, let's ask user if they want to manually specify them \n",
    "    # or parse them from the file. \n",
    "    # For now, let's just do input:\n",
    "    grade_level = input(\"Enter the same grade level you used in the Outline step (e.g., '7th grade'): \")\n",
    "    student_context = input(\"Enter the same student context from the outline step: \")\n",
    "\n",
    "    # 5) Now ask teacher which lesson set they want to expand\n",
    "    lesson_summary = input(\"Copy/paste the text for a single Lesson Set you want to expand:\\n> \")\n",
    "\n",
    "    # 6) Load the expansions prompt \n",
    "    expansions_prompt_path = Path(\"prompts\") / \"lesson_set_expansion_prompt.txt\"\n",
    "    lesson_expansion_prompt = load_prompt_from_file(expansions_prompt_path)\n",
    "\n",
    "    # 7) Setup RAG if you want or if you have to retrieve from vectorstore \n",
    "    # for additional references. \n",
    "    # For demonstration, we skip or do a minimal approach:\n",
    "    print(\"Loading Vector Store for expansions if needed ...\")\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings_model = ... # e.g. OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        vectorstore_path, \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    # 8) LLM\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    # 9) Construct a chain \n",
    "    expansions_chain = (\n",
    "        RunnableMap({\n",
    "            \"lesson_summary\": lambda x: x[\"lesson_summary\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x[\"grade_level\"],\n",
    "            \"context\": lambda x: retriever.invoke(\"some query about expansions for \" + x[\"lesson_summary\"])\n",
    "        })\n",
    "        | lesson_expansion_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 10) Run the chain\n",
    "    data_for_expansion = {\n",
    "        \"lesson_summary\": lesson_summary,\n",
    "        \"student_context\": student_context,\n",
    "        \"grade_level\": grade_level\n",
    "    }\n",
    "    expansions_response = expansions_chain.invoke(data_for_expansion)\n",
    "    print(\"\\n=== EXPANDED LESSONS ===\\n\")\n",
    "    print(expansions_response)\n",
    "\n",
    "    # 11) Optionally save expansions\n",
    "    out_dir = Path(\"outputs\")\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    expansions_file = out_dir / f\"lesson_expansion_{grade_level.replace(' ','_')}.md\"\n",
    "    expansions_file.write_text(expansions_response, encoding='utf-8')\n",
    "    print(f\"\\n‚úÖ Lesson expansions saved to: {expansions_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Unit bundler\n",
    "1. Select a unit outline\n",
    "2. Choose one or more expanded lessons\n",
    "3. Bundle them into a clean, organized .md file\n",
    "4. Save it with a timestamp for version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Available Unit Outlines:\n",
      "[0] unit_outline_climate_justice.md\n",
      "[1] unit_outline_9th_grade_biology.md\n",
      "[2] unit_outline_ecosystems_and_human_impact.md\n",
      "\n",
      "üìö Available Lesson Expansions:\n",
      "[0] lesson_expansion_climate_justice.md\n",
      "[1] lesson_expansion_unit_outline_9th_grade_bi.md\n",
      "\n",
      "‚úÖ Final bundled unit saved to: outputs/full_unit_plan_20250410-1646.md\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Notebook Script: Bundle Unit Outline and Lesson Expansions into One File\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Config Paths\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_files = list(outputs_dir.glob(\"unit_outline_*.md\"))\n",
    "lesson_files = list(outputs_dir.glob(\"lesson_expansion_*.md\"))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Choose Unit Outline\n",
    "# -----------------------------\n",
    "print(\"üì¶ Available Unit Outlines:\")\n",
    "for i, f in enumerate(unit_files):\n",
    "    print(f\"[{i}] {f.name}\")\n",
    "unit_index = int(input(\"\\nEnter number for unit to bundle: \"))\n",
    "unit_path = unit_files[unit_index]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Select Lessons to Include\n",
    "# -----------------------------\n",
    "print(\"\\nüìö Available Lesson Expansions:\")\n",
    "for i, f in enumerate(lesson_files):\n",
    "    print(f\"[{i}] {f.name}\")\n",
    "selected_lesson_indexes = input(\"\\nEnter numbers of lessons to include (comma separated): \")\n",
    "selected_indexes = [int(i.strip()) for i in selected_lesson_indexes.split(\",\") if i.strip().isdigit()]\n",
    "selected_lessons = [lesson_files[i] for i in selected_indexes]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Bundle Content\n",
    "# -----------------------------\n",
    "def read_text(path):\n",
    "    return path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "unit_text = read_text(unit_path)\n",
    "lesson_texts = [read_text(p) for p in selected_lessons]\n",
    "\n",
    "final_text = f\"\"\"\n",
    "# üß™ Bundled Science Unit Plan\n",
    "\n",
    "## üìù Unit Outline\n",
    "\n",
    "{unit_text}\n",
    "\n",
    "## üìö Expanded Lessons\n",
    "\n",
    "\"\"\"\n",
    "for i, text in enumerate(lesson_texts):\n",
    "    final_text += f\"\\n---\\n\\n### Lesson {i+1}\\n{text}\\n\"\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Save Bundled File\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "filename = outputs_dir / f\"full_unit_plan_{timestamp}.md\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_text)\n",
    "\n",
    "print(f\"\\n‚úÖ Final bundled unit saved to: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04 Teacher Reflection notebook is now set up!\n",
    "\n",
    "It will:\n",
    "\n",
    "Automatically load the most recent bundled unit\n",
    "\n",
    "Present a series of thoughtful, CRP-aligned reflection questions\n",
    "\n",
    "Capture teacher responses interactively\n",
    "\n",
    "Save the reflection as a .md file for iterative documentation\n",
    "\n",
    "This closes the loop for a powerful first cycle of your RAG tool: Inspire ‚Üí Design ‚Üí Expand ‚Üí Bundle ‚Üí Reflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded unit file: full_unit_plan_20250402-1657.md\n",
      "\n",
      "ü™û Teacher Reflection Questions:\n",
      "\n",
      "1. How might this unit connect to your students' lived experiences?\n",
      "\n",
      "---\n",
      "\n",
      "2. What voices or perspectives might be missing in this unit?\n",
      "\n",
      "---\n",
      "\n",
      "3. Are there opportunities to center local knowledge, language, or community assets?\n",
      "\n",
      "---\n",
      "\n",
      "4. How does this unit reflect your goals and values as a science educator?\n",
      "\n",
      "---\n",
      "\n",
      "5. What elements might support or challenge your existing beliefs about who science is for?\n",
      "\n",
      "---\n",
      "\n",
      "6. How might this unit invite multiple ways of knowing, doing, or expressing ideas in science?\n",
      "\n",
      "---\n",
      "\n",
      "‚úÖ Reflection saved to: outputs\\unit_reflection_20250402-1702.md\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Notebook Script: Teacher Reflection + Ideological Prompts\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Latest Bundled Unit\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_files = sorted(outputs_dir.glob(\"full_unit_plan_*.md\"), reverse=True)\n",
    "\n",
    "if not unit_files:\n",
    "    raise FileNotFoundError(\"‚ö†Ô∏è No bundled unit files found. Run 03_unit_bundler first.\")\n",
    "\n",
    "latest_unit_path = unit_files[0]\n",
    "print(f\"üìÑ Loaded unit file: {latest_unit_path.name}\\n\")\n",
    "\n",
    "unit_text = latest_unit_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Reflection Prompts\n",
    "# -----------------------------\n",
    "reflection_prompts = [\n",
    "    \"1. How might this unit connect to your students' lived experiences?\",\n",
    "    \"2. What voices or perspectives might be missing in this unit?\",\n",
    "    \"3. Are there opportunities to center local knowledge, language, or community assets?\",\n",
    "    \"4. How does this unit reflect your goals and values as a science educator?\",\n",
    "    \"5. What elements might support or challenge your existing beliefs about who science is for?\",\n",
    "    \"6. How might this unit invite multiple ways of knowing, doing, or expressing ideas in science?\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Interactive Reflection Form\n",
    "# -----------------------------\n",
    "responses = []\n",
    "print(\"ü™û Teacher Reflection Questions:\\n\")\n",
    "for prompt in reflection_prompts:\n",
    "    print(prompt)\n",
    "    answer = input(\"‚úèÔ∏è  Your thoughts: \")\n",
    "    responses.append((prompt, answer))\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Save Annotated Reflection\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "filename = outputs_dir / f\"unit_reflection_{timestamp}.md\"\n",
    "\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# üß† Teacher Reflection on Unit Design\\n\\n\")\n",
    "    f.write(f\"## Based on Unit: {latest_unit_path.name}\\n\\n\")\n",
    "    f.write(\"\\n---\\n\\n\")\n",
    "    for prompt, answer in responses:\n",
    "        f.write(f\"**{prompt}**\\n\\n{answer}\\n\\n\")\n",
    "\n",
    "print(f\"‚úÖ Reflection saved to: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflection Analytics / Logging\n",
    "We‚Äôll track:\n",
    "\n",
    "Frequency of reflective responses\n",
    "\n",
    "Sentiment or tone (e.g. using a simple NLP classifier)\n",
    "\n",
    "Shifts in ideology or themes over time across units\n",
    "\n",
    "Load all saved reflections\n",
    "\n",
    "Analyze each response for sentiment (via TextBlob)\n",
    "\n",
    "Visualize trends across prompts\n",
    "\n",
    "Save the full dataset as a .csv for deeper qualitative or longitudinal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Notebook Script: Analyze Teacher Reflections for Growth & Themes\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Reflections\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "reflection_files = sorted(outputs_dir.glob(\"unit_reflection_*.md\"))\n",
    "\n",
    "if not reflection_files:\n",
    "    raise FileNotFoundError(\"‚ö†Ô∏è No reflection files found. Run 04_teacher_reflection first.\")\n",
    "\n",
    "reflection_data = []\n",
    "for file in reflection_files:\n",
    "    text = file.read_text(encoding=\"utf-8\")\n",
    "    lines = text.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"**\") and i + 1 < len(lines):\n",
    "            question = line.strip(\"* \")\n",
    "            response = lines[i + 1].strip()\n",
    "            reflection_data.append({\n",
    "                \"file\": file.name,\n",
    "                \"question\": question,\n",
    "                \"response\": response\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(reflection_data)\n",
    "print(f\"‚úÖ Loaded {len(df)} reflection responses from {len(reflection_files)} files.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Sentiment Analysis\n",
    "# -----------------------------\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df[\"sentiment\"] = df[\"response\"].apply(get_sentiment)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Display Summary Stats\n",
    "# -----------------------------\n",
    "print(\"\\nüìä Sentiment Summary by Question:\")\n",
    "print(df.groupby(\"question\")[\"sentiment\"].mean().round(2))\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Visualization\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot(column=\"sentiment\", by=\"question\", rot=45)\n",
    "plt.title(\"Sentiment by Reflection Question\")\n",
    "plt.suptitle(\"\")\n",
    "plt.ylabel(\"Sentiment Polarity (-1 to 1)\")\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Export as CSV (optional)\n",
    "# -----------------------------\n",
    "df.to_csv(outputs_dir / \"reflection_analysis.csv\", index=False)\n",
    "print(\"\\nüìÅ Saved raw reflection data to: reflection_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export PDF\n",
    "06_export_pdf_doc will:\n",
    "\n",
    "Grab your most recent bundled unit and reflection\n",
    "\n",
    "Export them to both PDF (via fpdf) and Word/Google Doc format (via python-docx)\n",
    "\n",
    "Keep everything organized in your outputs/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Notebook Script: Export Bundled Unit and Reflection to PDF or Google Doc\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from fpdf import FPDF\n",
    "import markdown2\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Most Recent Files\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_file = sorted(outputs_dir.glob(\"full_unit_plan_*.md\"), reverse=True)[0]\n",
    "reflection_file = sorted(outputs_dir.glob(\"unit_reflection_*.md\"), reverse=True)[0]\n",
    "\n",
    "unit_text = unit_file.read_text(encoding=\"utf-8\")\n",
    "reflection_text = reflection_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Convert Markdown to HTML (for reference)\n",
    "# -----------------------------\n",
    "html_unit = markdown2.markdown(unit_text)\n",
    "html_reflection = markdown2.markdown(reflection_text)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Convert to PDF using FPDF\n",
    "# -----------------------------\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font(\"Arial\", \"B\", 12)\n",
    "        self.cell(0, 10, \"Bundled Science Unit + Reflection\", ln=True, align=\"C\")\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font(\"Arial\", \"B\", 11)\n",
    "        self.cell(0, 10, title, ln=True)\n",
    "        self.ln(4)\n",
    "\n",
    "    def chapter_body(self, text):\n",
    "        self.set_font(\"Arial\", size=10)\n",
    "        self.multi_cell(0, 6, text)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "pdf.chapter_title(\"Unit Plan\")\n",
    "pdf.chapter_body(unit_text)\n",
    "pdf.chapter_title(\"Teacher Reflection\")\n",
    "pdf.chapter_body(reflection_text)\n",
    "\n",
    "pdf_file = outputs_dir / f\"unit_bundle_export_{datetime.now().strftime('%Y%m%d-%H%M')}.pdf\"\n",
    "pdf.output(str(pdf_file))\n",
    "\n",
    "print(f\"‚úÖ PDF exported to: {pdf_file}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Google Docs (Optional, Outline Only)\n",
    "# -----------------------------\n",
    "try:\n",
    "    from docx import Document\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"Bundled Science Unit + Teacher Reflection\", 0)\n",
    "\n",
    "    doc.add_heading(\"Unit Plan\", level=1)\n",
    "    doc.add_paragraph(unit_text)\n",
    "\n",
    "    doc.add_heading(\"Teacher Reflection\", level=1)\n",
    "    doc.add_paragraph(reflection_text)\n",
    "\n",
    "    docx_file = outputs_dir / f\"unit_bundle_export_{datetime.now().strftime('%Y%m%d-%H%M')}.docx\"\n",
    "    doc.save(docx_file)\n",
    "    print(f\"‚úÖ Word Doc exported to: {docx_file}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è To enable Word/Google Docs export, run: pip install python-docx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07 Teacher interface App\n",
    "\n",
    " unified Streamlit app is now ready in 07_teacher_interface_app.py!\n",
    "\n",
    "This prototype lets teachers:\n",
    "\n",
    "Input a topic, grade, and student context\n",
    "\n",
    "Generate a culturally responsive unit outline with RAG + GPT-4\n",
    "\n",
    "View the result in-browser and save it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 11:03:19.225 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.227 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.340 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\mrhal\\anaconda3\\envs\\ragtest1-env\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-03 11:03:19.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.345 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.346 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-03 11:03:19.347 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.352 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Updated Unified Teacher-Facing App ‚Äì Streamlit Prototype\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Assume a utility function for loading prompts\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"üß† Curriculum CoDesigner ‚Äì AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ‚è≥\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"üìò Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"‚úÖ Saved to: {filename.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Upload\n",
    "Teachers can now:\n",
    "\n",
    "Upload custom PDFs (e.g., low-quality or local lessons)\n",
    "\n",
    "Have those documents instantly split, embedded, and used for RAG generation\n",
    "\n",
    "Fall back to your core inspiration corpus if no files are uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Unified Teacher-Facing App ‚Äì Streamlit Prototype with File Uploads\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"üß† Curriculum CoDesigner ‚Äì AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"üìÅ Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"‚úÖ Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ‚è≥\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"üìò Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"‚úÖ Saved to: {filename.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add CRP reflection prompts\n",
    "\n",
    "Streamlit app now includes built-in CRP reflection prompts!\n",
    "\n",
    "After a unit outline is generated, teachers are guided to reflect on:\n",
    "\n",
    "Cultural relevance\n",
    "\n",
    "Epistemological diversity\n",
    "\n",
    "Local significance\n",
    "\n",
    "Equity-related uncertainties\n",
    "\n",
    "Reflections are saved per unit alongside the design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Unified Teacher-Facing App ‚Äì Streamlit Prototype with File Uploads + Reflection Prompts\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"üß† Curriculum CoDesigner ‚Äì AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"üìÅ Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"‚úÖ Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ‚è≥\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"üìò Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"‚úÖ Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"ü™û Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"üíæ Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"‚úÖ Reflection saved to: {reflection_file.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson expansion is now built into the Streamlit app!\n",
    "\n",
    "After generating the unit outline, teachers can:\n",
    "\n",
    "Select how many lessons they want (2‚Äì10)\n",
    "\n",
    "Automatically generate detailed lesson-level plans\n",
    "\n",
    "Save and view those lessons in-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_prompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_prompt_from_file\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnableMap\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Unified Teacher-Facing App ‚Äì Streamlit Prototype with File Uploads + Reflection Prompts + Lesson Expansion\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"üß† Curriculum CoDesigner ‚Äì AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"üìÅ Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"‚úÖ Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    lesson_path = Path(\"prompts\") / \"lesson_expander_prompt.txt\"\n",
    "    lesson_prompt = load_prompt_from_file(lesson_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ‚è≥\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"üìò Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"‚úÖ Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Lesson Expansion Prompt\n",
    "    # -----------------------------\n",
    "    st.subheader(\"üìö Expand Unit into Detailed Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"How many lessons would you like to expand into?\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: unit_output,\n",
    "                \"topic\": lambda x: x[\"topic\"],\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        lesson_data = {\"topic\": topic, \"num_lessons\": num_lessons}\n",
    "        expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(expanded_lessons)\n",
    "\n",
    "        expanded_file = output_dir / f\"lesson_expansion_{topic.replace(' ', '_')}.md\"\n",
    "        with open(expanded_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(expanded_lessons)\n",
    "        st.success(f\"‚úÖ Expanded lessons saved to: {expanded_file.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"ü™û Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"üíæ Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"‚úÖ Reflection saved to: {reflection_file.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF export added! After reflection is submitted, your app now:\n",
    "\n",
    "Combines unit outline, lessons, and reflection into one PDF\n",
    "\n",
    "Saves and displays a download button for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Unified Teacher-Facing App ‚Äì Streamlit Prototype with File Uploads + Reflection Prompts + Lesson Expansion + PDF Export\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"üß† Curriculum CoDesigner ‚Äì AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"üìÅ Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"‚úÖ Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    lesson_path = Path(\"prompts\") / \"lesson_expander_prompt.txt\"\n",
    "    lesson_prompt = load_prompt_from_file(lesson_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ‚è≥\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"üìò Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"‚úÖ Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Lesson Expansion Prompt\n",
    "    # -----------------------------\n",
    "    st.subheader(\"üìö Expand Unit into Detailed Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"How many lessons would you like to expand into?\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: unit_output,\n",
    "                \"topic\": lambda x: x[\"topic\"],\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        lesson_data = {\"topic\": topic, \"num_lessons\": num_lessons}\n",
    "        expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(expanded_lessons)\n",
    "\n",
    "        expanded_file = output_dir / f\"lesson_expansion_{topic.replace(' ', '_')}.md\"\n",
    "        with open(expanded_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(expanded_lessons)\n",
    "        st.success(f\"‚úÖ Expanded lessons saved to: {expanded_file.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"ü™û Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"üíæ Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"‚úÖ Reflection saved to: {reflection_file.name}\")\n",
    "\n",
    "        # Export to PDF\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "        for line in (unit_output + \"\\n\" + expanded_lessons + \"\\n\" + reflection_text).split(\"\\n\"):\n",
    "            pdf.multi_cell(0, 10, line)\n",
    "        pdf_filename = output_dir / f\"unit_bundle_{topic.replace(' ', '_')}.pdf\"\n",
    "        pdf.output(str(pdf_filename))\n",
    "        with open(pdf_filename, \"rb\") as f:\n",
    "            st.download_button(\"üìÑ Download Full Unit PDF\", data=f, file_name=pdf_filename.name)\n",
    "        st.success(\"üìÅ Full unit PDF exported!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review and export\n",
    " Review & Export tab is now live! You can:\n",
    "\n",
    "See the full unit + lessons + reflection all together\n",
    "\n",
    "Download it as a bundled PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Unified Teacher-Facing App ‚Äì Streamlit Prototype with Review + Export Page\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"üß† Curriculum CoDesigner ‚Äì AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# App State & Session Storage\n",
    "# -----------------------------\n",
    "if \"unit_output\" not in st.session_state:\n",
    "    st.session_state.unit_output = \"\"\n",
    "if \"expanded_lessons\" not in st.session_state:\n",
    "    st.session_state.expanded_lessons = \"\"\n",
    "if \"reflection_text\" not in st.session_state:\n",
    "    st.session_state.reflection_text = \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step-by-step workflow\n",
    "# -----------------------------\n",
    "st.sidebar.title(\"Navigation\")\n",
    "page = st.sidebar.radio(\"Go to:\", [\"1Ô∏è‚É£ Upload & Inputs\", \"2Ô∏è‚É£ Unit Builder\", \"3Ô∏è‚É£ Lesson Expansion\", \"4Ô∏è‚É£ Reflection\", \"5Ô∏è‚É£ Review & Export\"])\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 1: Upload & Inputs\n",
    "# -----------------------------\n",
    "if page == \"1Ô∏è‚É£ Upload & Inputs\":\n",
    "    with st.expander(\"üìÅ Upload Custom Documents (optional)\"):\n",
    "        uploaded_files = st.file_uploader(\"Upload PDFs for inspiration\", type=\"pdf\", accept_multiple_files=True)\n",
    "        temp_dir = Path(\"data/uploads\")\n",
    "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        st.session_state.custom_docs = []\n",
    "        if uploaded_files:\n",
    "            for file in uploaded_files:\n",
    "                file_path = temp_dir / file.name\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file.read())\n",
    "                loader = PyMuPDFLoader(str(file_path))\n",
    "                docs = loader.load()\n",
    "                splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "                split_docs = splitter.split_documents(docs)\n",
    "                st.session_state.custom_docs.extend(split_docs)\n",
    "            st.success(f\"‚úÖ Loaded {len(st.session_state.custom_docs)} chunks from PDFs.\")\n",
    "\n",
    "    with st.form(\"unit_form\"):\n",
    "        st.session_state.topic = st.text_input(\"Unit Topic\", \"ecosystems and human impact\")\n",
    "        st.session_state.grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "        st.session_state.context = st.text_area(\"Describe your student/community context\", \"Black and Latinx students in LA\")\n",
    "        st.session_state.submit_inputs = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 2: Unit Builder\n",
    "# -----------------------------\n",
    "if page == \"2Ô∏è‚É£ Unit Builder\" and st.session_state.get(\"submit_inputs\"):\n",
    "    st.info(\"üîÑ Generating outline using your topic and context...\")\n",
    "    unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if st.session_state.get(\"custom_docs\"):\n",
    "        custom_vectorstore = FAISS.from_documents(st.session_state.custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    data = {\n",
    "        \"topic\": st.session_state.topic,\n",
    "        \"student_context\": st.session_state.context,\n",
    "        \"grade_level\": st.session_state.grade\n",
    "    }\n",
    "    st.session_state.unit_output = rag_chain.invoke(data)\n",
    "    st.subheader(\"üìò Generated Unit Outline\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 3: Lesson Expansion\n",
    "# -----------------------------\n",
    "if page == \"3Ô∏è‚É£ Lesson Expansion\" and st.session_state.unit_output:\n",
    "    st.subheader(\"üìö Expand Into Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"Number of lessons\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_prompt = load_prompt_from_file(Path(\"prompts\") / \"lesson_expander_prompt.txt\")\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: st.session_state.unit_output,\n",
    "                \"topic\": lambda x: st.session_state.topic,\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        lesson_data = {\"num_lessons\": num_lessons}\n",
    "        st.session_state.expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(st.session_state.expanded_lessons)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 4: Reflection\n",
    "# -----------------------------\n",
    "if page == \"4Ô∏è‚É£ Reflection\" and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"ü™û Teacher Reflection\")\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities of your students?\")\n",
    "        q2 = st.text_area(\"2. Where can students bring in multiple ways of knowing?\")\n",
    "        q3 = st.text_area(\"3. What could make this more locally meaningful?\")\n",
    "        q4 = st.text_area(\"4. What are open questions you still have about equity in this unit?\")\n",
    "        submit_reflection = st.form_submit_button(\"üíæ Save Reflection\")\n",
    "\n",
    "    if submit_reflection:\n",
    "        st.session_state.reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {st.session_state.topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        st.success(\"‚úÖ Reflection saved. Proceed to Review & Export tab.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 5: Review and Export\n",
    "# -----------------------------\n",
    "if page == \"5Ô∏è‚É£ Review & Export\" and st.session_state.unit_output and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"üì¶ Review Final Bundle\")\n",
    "    st.markdown(\"### üßæ Unit Plan\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "    st.markdown(\"### üß© Lessons\")\n",
    "    st.markdown(st.session_state.expanded_lessons)\n",
    "    st.markdown(\"### ü™û Reflection\")\n",
    "    st.markdown(st.session_state.reflection_text)\n",
    "\n",
    "    full_text = f\"\"\"\n",
    "{st.session_state.unit_output}\n",
    "\n",
    "{st.session_state.expanded_lessons}\n",
    "\n",
    "{st.session_state.reflection_text}\n",
    "\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    for line in full_text.split(\"\\n\"):\n",
    "        pdf.multi_cell(0, 10, line)\n",
    "    filename = output_dir / f\"unit_bundle_{st.session_state.topic.replace(' ', '_')}.pdf\"\n",
    "    pdf.output(str(filename))\n",
    "    with open(filename, \"rb\") as f:\n",
    "        st.download_button(\"üìÑ Download Full Unit PDF\", data=f, file_name=filename.name)\n",
    "    st.success(\"‚úÖ Your full curriculum design has been bundled!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrated CRP pedagogical enhancements into your app:\n",
    "\n",
    "A concise explanation and resource link added in the sidebar.\n",
    "\n",
    "Helpful CRP tips added to guide reflections and review steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Unified Teacher-Facing App ‚Äì Streamlit Prototype with Review + Export Page\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# CRP Pedagogical Resources\n",
    "CRP_RESOURCES = \"\"\"\n",
    "### üåü What is Culturally Responsive Pedagogy (CRP)?\n",
    "Culturally Responsive Pedagogy emphasizes using students' cultural backgrounds, experiences, and perspectives as valuable resources for teaching and learning.\n",
    "\n",
    "- **Validate Students' Identities:** Affirm and celebrate diverse cultural identities.\n",
    "- **Multiple Ways of Knowing:** Encourage students to bring their cultural, linguistic, and experiential knowledge into the classroom.\n",
    "- **Social Relevance:** Connect learning to issues that are significant within students' communities.\n",
    "\n",
    "[Learn more about CRP here](https://www.tolerance.org/professional-development/culturally-responsive-teaching)\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"üß† Curriculum CoDesigner ‚Äì AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# App State & Session Storage\n",
    "# -----------------------------\n",
    "if \"unit_output\" not in st.session_state:\n",
    "    st.session_state.unit_output = \"\"\n",
    "if \"expanded_lessons\" not in st.session_state:\n",
    "    st.session_state.expanded_lessons = \"\"\n",
    "if \"reflection_text\" not in st.session_state:\n",
    "    st.session_state.reflection_text = \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step-by-step workflow\n",
    "# -----------------------------\n",
    "st.sidebar.title(\"Navigation\")\n",
    "st.sidebar.markdown(CRP_RESOURCES)\n",
    "page = st.sidebar.radio(\"Go to:\", [\"1Ô∏è‚É£ Upload & Inputs\", \"2Ô∏è‚É£ Unit Builder\", \"3Ô∏è‚É£ Lesson Expansion\", \"4Ô∏è‚É£ Reflection\", \"5Ô∏è‚É£ Review & Export\"])\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 1: Upload & Inputs\n",
    "# -----------------------------\n",
    "if page == \"1Ô∏è‚É£ Upload & Inputs\":\n",
    "    with st.expander(\"üìÅ Upload Custom Documents (optional)\"):\n",
    "        uploaded_files = st.file_uploader(\"Upload PDFs for inspiration\", type=\"pdf\", accept_multiple_files=True)\n",
    "        temp_dir = Path(\"data/uploads\")\n",
    "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        st.session_state.custom_docs = []\n",
    "        if uploaded_files:\n",
    "            for file in uploaded_files:\n",
    "                file_path = temp_dir / file.name\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file.read())\n",
    "                loader = PyMuPDFLoader(str(file_path))\n",
    "                docs = loader.load()\n",
    "                splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "                split_docs = splitter.split_documents(docs)\n",
    "                st.session_state.custom_docs.extend(split_docs)\n",
    "            st.success(f\"‚úÖ Loaded {len(st.session_state.custom_docs)} chunks from PDFs.\")\n",
    "\n",
    "    with st.form(\"unit_form\"):\n",
    "        st.session_state.topic = st.text_input(\"Unit Topic\", \"ecosystems and human impact\")\n",
    "        st.session_state.grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "        st.session_state.context = st.text_area(\"Describe your student/community context\", \"Black and Latinx students in LA\")\n",
    "        st.session_state.submit_inputs = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 2: Unit Builder\n",
    "# -----------------------------\n",
    "if page == \"2Ô∏è‚É£ Unit Builder\" and st.session_state.get(\"submit_inputs\"):\n",
    "    st.info(\"üîÑ Generating outline using your topic and context...\")\n",
    "    unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if st.session_state.get(\"custom_docs\"):\n",
    "        custom_vectorstore = FAISS.from_documents(st.session_state.custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    data = {\n",
    "        \"topic\": st.session_state.topic,\n",
    "        \"student_context\": st.session_state.context,\n",
    "        \"grade_level\": st.session_state.grade\n",
    "    }\n",
    "    st.session_state.unit_output = rag_chain.invoke(data)\n",
    "    st.subheader(\"üìò Generated Unit Outline\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 3: Lesson Expansion\n",
    "# -----------------------------\n",
    "if page == \"3Ô∏è‚É£ Lesson Expansion\" and st.session_state.unit_output:\n",
    "    st.subheader(\"üìö Expand Into Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"Number of lessons\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_prompt = load_prompt_from_file(Path(\"prompts\") / \"lesson_expander_prompt.txt\")\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: st.session_state.unit_output,\n",
    "                \"topic\": lambda x: st.session_state.topic,\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        lesson_data = {\"num_lessons\": num_lessons}\n",
    "        st.session_state.expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(st.session_state.expanded_lessons)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 4: Reflection\n",
    "# -----------------------------\n",
    "if page == \"4Ô∏è‚É£ Reflection\" and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"ü™û Teacher Reflection\")\n",
    "st.info(\"Tip: Think about how your unit design incorporates aspects of CRP. See sidebar for guidance.\")\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities of your students?\")\n",
    "        q2 = st.text_area(\"2. Where can students bring in multiple ways of knowing?\")\n",
    "        q3 = st.text_area(\"3. What could make this more locally meaningful?\")\n",
    "        q4 = st.text_area(\"4. What are open questions you still have about equity in this unit?\")\n",
    "        submit_reflection = st.form_submit_button(\"üíæ Save Reflection\")\n",
    "\n",
    "    if submit_reflection:\n",
    "        st.session_state.reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {st.session_state.topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        st.success(\"‚úÖ Reflection saved. Proceed to Review & Export tab.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 5: Review and Export\n",
    "# -----------------------------\n",
    "if page == \"5Ô∏è‚É£ Review & Export\" and st.session_state.unit_output and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"üì¶ Review Final Bundle\")\n",
    "st.markdown(\"üîç **Reflect**: Have you addressed the principles of Culturally Responsive Pedagogy in your curriculum?\")\n",
    "    st.markdown(\"### üßæ Unit Plan\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "    st.markdown(\"### üß© Lessons\")\n",
    "    st.markdown(st.session_state.expanded_lessons)\n",
    "    st.markdown(\"### ü™û Reflection\")\n",
    "    st.markdown(st.session_state.reflection_text)\n",
    "\n",
    "    full_text = f\"\"\"\n",
    "{st.session_state.unit_output}\n",
    "\n",
    "{st.session_state.expanded_lessons}\n",
    "\n",
    "{st.session_state.reflection_text}\n",
    "\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    for line in full_text.split(\"\\n\"):\n",
    "        pdf.multi_cell(0, 10, line)\n",
    "    filename = output_dir / f\"unit_bundle_{st.session_state.topic.replace(' ', '_')}.pdf\"\n",
    "    pdf.output(str(filename))\n",
    "    with open(filename, \"rb\") as f:\n",
    "        st.download_button(\"üìÑ Download Full Unit PDF\", data=f, file_name=filename.name)\n",
    "    st.success(\"‚úÖ Your full curriculum design has been bundled!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side by Side RAG vs GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç RAG Output:\n",
      "1. Title of the Unit: \"Climate Change: Understanding and Impacting Our Local Environment\"\n",
      "\n",
      "2. NGSS Anchoring Phenomenon: The increase in frequency and intensity of heatwaves in Los Angeles over the past decade.\n",
      "\n",
      "3. Driving Question: How does climate change impact our local community in Los Angeles, and what can we do to mitigate its effects?\n",
      "\n",
      "4. Summary of the Storyline Arc: \n",
      "The unit begins with students observing and discussing the anchoring phenomenon of increasing heatwaves in Los Angeles. They then explore the concept of climate change, its causes, and its effects on local and global scales. Students investigate the role of human activities in climate change, focusing on the local context of Los Angeles. They analyze local data on air quality, temperature trends, and energy use. Students then research and discuss the impacts of climate change on their community, including health, economy, and lifestyle. They also explore the concept of environmental justice, discussing how climate change disproportionately affects Black and Latinx communities. The unit concludes with students proposing and evaluating potential solutions to mitigate the effects of climate change in their community.\n",
      "\n",
      "5. Lesson Sets:\n",
      "   - Lesson Set 1: Understanding Climate Change: Students explore the concept of climate change, its causes, and its effects on local and global scales.\n",
      "   - Lesson Set 2: Human Impact and Climate Change: Students investigate the role of human activities in climate change, focusing on the local context of Los Angeles.\n",
      "   - Lesson Set 3: Climate Change and Our Community: Students research and discuss the impacts of climate change on their community, including health, economy, and lifestyle.\n",
      "   - Lesson Set 4: Environmental Justice and Climate Change: Students explore the concept of environmental justice, discussing how climate change disproportionately affects Black and Latinx communities.\n",
      "   - Lesson Set 5: Mitigating Climate Change: Students propose and evaluate potential solutions to mitigate the effects of climate change in their community.\n",
      "\n",
      "6. Key Investigations:\n",
      "   - Investigation 1: Analyzing Local Climate Data: Students analyze local data on air quality, temperature trends, and energy use.\n",
      "   - Investigation 2: Impacts of Climate Change: Students research and discuss the impacts of climate change on their community.\n",
      "   - Investigation 3: Environmental Justice: Students explore the concept of environmental justice, discussing how climate change disproportionately affects Black and Latinx communities.\n",
      "   - Investigation 4: Solutions to Climate Change: Students propose and evaluate potential solutions to mitigate the effects of climate change in their community.\n",
      "\n",
      "7. NGSS Performance Expectations: MS-ESS3-3, MS-ESS3-4, MS-ESS3-5\n",
      "\n",
      "8. Suggested Teacher Reflection Prompts:\n",
      "   - How did students connect the concept of climate change to their local community?\n",
      "   - What strategies were effective in promoting inclusive participation and multiple ways of knowing in science?\n",
      "   - How did students engage with the concept of environmental justice in relation to climate change?\n",
      "   - How effectively did students propose and evaluate potential solutions to mitigate the effects of climate change in their community?\n",
      "\n",
      "ü§ñ GPT-4 Direct Prompt Output:\n",
      "1. Title: \"Climate Change: Understanding and Addressing its Impact on Our Community\"\n",
      "\n",
      "2. Anchoring Phenomenon: The increasing frequency of heatwaves and wildfires in Los Angeles and their impact on the local community and environment.\n",
      "\n",
      "3. Driving Question: How is climate change affecting our local community and what can we do to mitigate its effects?\n",
      "\n",
      "4. Storyline Summary: This unit will explore the concept of climate change, its causes, and effects, with a particular focus on its impact on the Los Angeles community. Students will investigate the increasing frequency of heatwaves and wildfires, and how these changes are affecting local ecosystems, public health, and community infrastructure. The unit will also explore how different communities are disproportionately affected by climate change, and how individual and collective actions can help mitigate its effects. Students will be encouraged to connect their learning to their own experiences and to consider how they can contribute to climate change solutions.\n",
      "\n",
      "5. Lesson Sets:\n",
      "   - Lesson Set 1: Understanding Climate Change: Students will learn about the greenhouse effect, global warming, and the scientific evidence for climate change.\n",
      "   - Lesson Set 2: Local Impacts of Climate Change: Students will investigate how climate change is affecting Los Angeles, focusing on heatwaves, wildfires, and their impacts on local ecosystems and communities.\n",
      "   - Lesson Set 3: Climate Justice: Students will explore how climate change disproportionately affects different communities, focusing on the experiences of Black and Latinx communities in Los Angeles.\n",
      "   - Lesson Set 4: Climate Action: Students will learn about different strategies for mitigating climate change, from individual actions to policy changes, and will develop their own action plan to address climate change in their community.\n",
      "\n",
      "6. NGSS Performance Expectations: MS-ESS3-3, MS-ESS3-4, MS-ESS3-5\n",
      "\n",
      "7. Suggested Teacher Reflection Prompts:\n",
      "   - How did students connect their learning to their own experiences and community context?\n",
      "   - How did students engage with the concept of climate justice, and how did they respond to the idea that climate change disproportionately affects different communities?\n",
      "   - How did students demonstrate their understanding of the causes and effects of climate change, and their ability to develop solutions?\n",
      "   - How can I better incorporate students' cultural backgrounds and experiences into our discussions about climate change and its impacts?\n",
      "   - How can I further promote inclusive participation and multiple ways of knowing in my classroom?\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Side-by-Side Comparison Notebook: RAG vs GPT-4o\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "unit_prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "pdf_folder = Path(\"documents/Inspiration_folder\")\n",
    "vectorstore_path = Path(\"data/embeddings/faiss_index\")\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "llm_gpt4 = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# Load Prompt Template\n",
    "# -----------------------------\n",
    "with open(unit_prompt_path, encoding=\"utf-8\") as f:\n",
    "    unit_prompt = PromptTemplate.from_template(f.read())\n",
    "\n",
    "# -----------------------------\n",
    "# Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore = FAISS.load_local(\n",
    "    str(vectorstore_path), \n",
    "    embedding_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# Define RAG Chain\n",
    "# -----------------------------\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm_gpt4\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Define Test Input\n",
    "# -----------------------------\n",
    "test_input = {\n",
    "    \"topic\": \"climate change\",\n",
    "    \"grade_level\": \"7th grade\",\n",
    "    \"student_context\": \"Black and Latinx middle school students in Los Angeles\"\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Run RAG-based Generation\n",
    "# -----------------------------\n",
    "print(\"\\nüîç RAG Output:\")\n",
    "rag_response = rag_chain.invoke(test_input)\n",
    "print(rag_response)\n",
    "\n",
    "# -----------------------------\n",
    "# Run Direct GPT-4 Prompt (no retrieval)\n",
    "# -----------------------------\n",
    "base_prompt = f\"\"\"\n",
    "You are a curriculum design coach. Generate a 7th grade science unit plan for the topic of: {test_input['topic']}.\n",
    "\n",
    "The student context is: {test_input['student_context']}.\n",
    "\n",
    "Use NGSS-aligned practices and focus on culturally responsive pedagogy:\n",
    "- Reflect students‚Äô identities or community experiences\n",
    "- Promote inclusive participation and multiple ways of knowing\n",
    "- Connect learning to local lives and social issues\n",
    "\n",
    "Include:\n",
    "1. Title\n",
    "2. Anchoring Phenomenon\n",
    "3. Driving Question\n",
    "4. Storyline Summary\n",
    "5. 3‚Äì5 Lesson Sets\n",
    "6. NGSS Performance Expectations (if known)\n",
    "7. Suggested Teacher Reflection Prompts\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nü§ñ GPT-4 Direct Prompt Output:\")\n",
    "direct_response = llm_gpt4.invoke(base_prompt)\n",
    "print(direct_response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance test of embedding and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Embedding Perf Logger ‚Äì Notebook Version\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "query = \"How do genetic mutations influence biological sex and athletic performance?\"\n",
    "pdf_folder = \"documents/Inspiration_folder/OpenSciEd\"\n",
    "chunk_size = 500\n",
    "chunk_overlap = 50\n",
    "\n",
    "# -----------------------------\n",
    "# Load and Split PDFs\n",
    "# -----------------------------\n",
    "def load_and_split_pdfs(folder_path):\n",
    "    pdf_paths = list(Path(folder_path).rglob(\"*.pdf\"))\n",
    "    all_chunks = []\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    for path in tqdm(pdf_paths, desc=\"üìÑ Loading PDFs\"):\n",
    "        loader = PyMuPDFLoader(str(path))\n",
    "        docs = loader.load()\n",
    "        chunks = splitter.split_documents(docs)\n",
    "        for chunk in chunks:\n",
    "            chunk.metadata[\"filename\"] = path.name\n",
    "        all_chunks.extend(chunks)\n",
    "    return all_chunks\n",
    "\n",
    "# -----------------------------\n",
    "# Embed with two models\n",
    "# -----------------------------\n",
    "def embed_with_models(docs, models):\n",
    "    results = {}\n",
    "    for name, embedding_model in models.items():\n",
    "        start = time.time()\n",
    "        print(f\"üîç Embedding with {name}...\")\n",
    "        vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        start_q = time.time()\n",
    "        docs_found = vectorstore.similarity_search_with_score(query, k=5)\n",
    "        elapsed_q = time.time() - start_q\n",
    "\n",
    "        results[name] = {\n",
    "            \"time_embed\": elapsed,\n",
    "            \"time_query\": elapsed_q,\n",
    "            \"results\": docs_found,\n",
    "            \"vectorstore\": vectorstore\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# Visualize Differences\n",
    "# -----------------------------\n",
    "def visualize_results(results):\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Embed Time (s)\": round(data[\"time_embed\"], 2),\n",
    "            \"Query Time (s)\": round(data[\"time_query\"], 2)\n",
    "        }\n",
    "        for name, data in results.items()\n",
    "    ])\n",
    "    display(df)\n",
    "\n",
    "    df.plot(x=\"Model\", kind=\"barh\", title=\"Embedding & Query Time by Model\", figsize=(10, 4))\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Run Notebook-Friendly Comparison\n",
    "# -----------------------------\n",
    "def run_benchmark():\n",
    "    print(\"üöÄ Loading documents...\")\n",
    "    docs = load_and_split_pdfs(pdf_folder)\n",
    "\n",
    "    models = {\n",
    "        \"text-embedding-3-small\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "        \"text-embedding-3-large\": OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    }\n",
    "\n",
    "    results = embed_with_models(docs, models)\n",
    "\n",
    "    print(\"üìä Timing and Results Summary\")\n",
    "    visualize_results(results)\n",
    "\n",
    "    # Log comparison\n",
    "    log = {}\n",
    "    for name, data in results.items():\n",
    "        log[name] = {\n",
    "            \"embed_time\": data[\"time_embed\"],\n",
    "            \"query_time\": data[\"time_query\"],\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"score\": score,\n",
    "                    \"text\": doc.page_content[:200],\n",
    "                    \"source\": doc.metadata.get(\"filename\")\n",
    "                } for doc, score in data[\"results\"]\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    output_path = Path(\"outputs\") / \"embedding_model_comparison_log.json\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(log, f, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Results saved to: {output_path}\")\n",
    "\n",
    "# To run inside a notebook\n",
    "# run_benchmark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.run_benchmark()>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_benchmark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
