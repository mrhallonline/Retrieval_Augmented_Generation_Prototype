{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b72f9e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Streamlit App: Teacher Input + Unit Outline Generator with Evaluation Mode + CSV Logging (No Lesson Expansion)\n",
    "\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": None,\n",
    "        \"lesson_sets\": {},\n",
    "        \"investigations\": {},\n",
    "        \"ngss\": [],\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"## Unit Title\"):\n",
    "            current_section = \"title\"\n",
    "        elif line.startswith(\"### Anchoring Phenomenon\"):\n",
    "            current_section = \"phenomenon\"\n",
    "        elif line.startswith(\"### Driving Question\"):\n",
    "            current_section = \"driving_question\"\n",
    "        elif line.startswith(\"### Storyline Arc Summary\") or line.startswith(\"### Introduction\"):\n",
    "            current_section = \"summary\"\n",
    "        elif line.startswith(\"### Lesson Sets\"):\n",
    "            current_section = \"lesson_sets\"\n",
    "        elif line.startswith(\"### Key Investigations\"):\n",
    "            current_section = \"investigations\"\n",
    "        elif line.startswith(\"### NGSS Performance Expectations\"):\n",
    "            current_section = \"ngss\"\n",
    "        elif line.startswith(\"### Suggested Teacher Reflection Prompts\"):\n",
    "            current_section = \"reflection_prompts\"\n",
    "        elif current_section == \"lesson_sets\" and re.match(r\"^\\d+\\.\\s+\\*\\*Lesson\", line):\n",
    "            match = re.match(r\"^(\\d+)\\.\\s+\\*\\*(Lesson.*?)\\*\\*[:\\s]*(.*)\", line)\n",
    "            if match:\n",
    "                idx, title, desc = match.groups()\n",
    "                sections[\"lesson_sets\"][f\"Lesson {idx}: {title}\"] = desc.strip()\n",
    "        elif current_section == \"investigations\" and re.match(r\"-\\s+Investigation\", line):\n",
    "            match = re.match(r\"-\\s+(Investigation \\d+):\\s*(.*)\", line)\n",
    "            if match:\n",
    "                key, value = match.groups()\n",
    "                sections[\"investigations\"][key] = value.strip()\n",
    "        elif current_section == \"ngss\" and line.startswith(\"- \"):\n",
    "            sections[\"ngss\"].append(line[2:].strip())\n",
    "        elif current_section == \"reflection_prompts\" and line.startswith(\"- \"):\n",
    "            sections[\"reflection_prompts\"].append(line[2:].strip())\n",
    "        elif current_section in [\"title\", \"phenomenon\", \"driving_question\", \"summary\"] and line:\n",
    "            if not sections[current_section]:\n",
    "                sections[current_section] = line\n",
    "            else:\n",
    "                sections[current_section] += f\" {line}\"\n",
    "\n",
    "    return sections\n",
    "\n",
    "# -----------------------------\n",
    "# Load Prompt and Vectorstore\n",
    "# -----------------------------\n",
    "unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(vectorstore_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# Streamlit UI\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"üß† Curriculum CoDesigner ‚Äì RAG1 Unit Planner\")\n",
    "\n",
    "with st.sidebar:\n",
    "    st.markdown(\"\"\"\n",
    "    ### üßæ How to Use\n",
    "    1. Input a topic, grade level, and student context.\n",
    "    2. Click to generate a unit outline.\n",
    "    3. Optional: Enable evaluation mode to view retrieved document sources.\n",
    "\n",
    "    ### üìÅ Inspiration Bucket Should Include:\n",
    "    - OpenSciEd Units (PDFs)\n",
    "    - NGSS-Aligned Science Lessons\n",
    "    - Equity or Justice Frameworks (e.g., CRP, Cultivating Genius)\n",
    "    - Case Studies or Local Examples\n",
    "    \"\"\")\n",
    "    eval_mode = st.checkbox(\"Enable Evaluation Mode\", value=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Input Form\n",
    "# -----------------------------\n",
    "st.subheader(\"1Ô∏è‚É£ Teacher Inputs\")\n",
    "with st.form(\"input_form\"):\n",
    "    topic = st.text_input(\"Unit Topic\", \"climate justice\")\n",
    "    grade_level = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"9th\", \"middle school\"])\n",
    "    student_context = st.text_area(\"Describe Your Student/Community Context\", \"Black and Latinx students in Chicago\")\n",
    "    submitted = st.form_submit_button(\"‚ú® Generate Unit Outline\")\n",
    "\n",
    "if submitted:\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"grade_level\": grade_level,\n",
    "        \"student_context\": student_context\n",
    "    }\n",
    "\n",
    "    st.info(\"üîÑ Generating outline using your topic and context...\")\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    outline_response = rag_chain.invoke(data)\n",
    "    st.subheader(\"üìò Generated Unit Plan\")\n",
    "    st.markdown(outline_response)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Save markdown\n",
    "    md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "    with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(outline_response)\n",
    "\n",
    "    # Save JSON\n",
    "    json_data = extract_sections(outline_response)\n",
    "    json_data.update(data)\n",
    "    json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "\n",
    "    st.success(f\"‚úÖ Saved markdown: {md_path.name}\")\n",
    "    st.success(f\"‚úÖ Saved JSON: {json_path.name}\")\n",
    "\n",
    "    if eval_mode:\n",
    "        st.subheader(\"üîç Evaluation Mode ‚Äì Retrieved Chunks\")\n",
    "        docs = retriever.get_relevant_documents(topic)\n",
    "        log_path = output_dir / f\"retrieval_log_{filename_slug}_{timestamp}.csv\"\n",
    "        with open(log_path, \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([\"Chunk #\", \"Source Folder\", \"Filename\", \"Preview\"])\n",
    "            for i, doc in enumerate(docs):\n",
    "                source_folder = doc.metadata.get(\"source_folder\", \"unknown\")\n",
    "                filename = doc.metadata.get(\"filename\", \"unknown\")\n",
    "                preview = doc.page_content[:500].replace(\"\\n\", \" \")\n",
    "                st.markdown(f\"**{i+1}. {filename}**\\n\\n{preview}\")\n",
    "                writer.writerow([i+1, source_folder, filename, preview])\n",
    "        st.success(f\"‚úÖ Logged document traces: {log_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e55c9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò WELCOME TO THE CURRICULUM CODESIGNER TOOL\n",
      "\n",
      "üß© Step-by-step Instructions:\n",
      "1. Enter a unit topic, grade level, and student context.\n",
      "2. The system will retrieve documents and generate a unit outline.\n",
      "3. You may then expand individual lessons based on summaries.\n",
      "\n",
      "üß† Inspiration Bucket Guidelines:\n",
      "Include documents such as:\n",
      "- OpenSciEd units (PDFs)\n",
      "- NGSS-aligned science lessons\n",
      "- Local climate justice case studies\n",
      "- Equity frameworks (e.g., CRP, Cultivating Genius)\n",
      "- Teacher reflections and student perspectives (optional)\n",
      "\n",
      "üí¨ Tips:\n",
      "- Use a topic relevant to your context (e.g., \"climate justice in Chicago\").\n",
      "- Evaluation mode logs document traces for transparency.\n",
      "- Lesson expansions generate full instructional sequences.\n",
      "\n",
      "üìÅ Output files are saved in the 'outputs/' directory.\n",
      "\n",
      "\n",
      "ü§ñ Generating unit outline... Please wait...\n",
      "\n",
      "\n",
      "üìù Generated Unit Plan:\n",
      "\n",
      "## Unit Title: Climate Justice: Empowering Change in Chicago\n",
      "\n",
      "### Anchoring Phenomenon\n",
      "The disproportionate impact of urban heat islands and air pollution in predominantly Black and LatinX neighborhoods in Chicago.\n",
      "\n",
      "### Driving Question\n",
      "How can we use science and engineering to address climate justice issues in our community?\n",
      "\n",
      "### Introduction\n",
      "On the first day, students will explore their local neighborhood through a virtual or physical walk, documenting evidence of urban heat islands and air pollution. They will collect data using temperature sensors and air quality monitors, setting the stage for understanding how these environmental issues affect their community. This hands-on experience will connect students to the phenomenon by highlighting real-world problems they encounter daily.\n",
      "\n",
      "### Storyline Arc Summary\n",
      "The unit begins with students identifying climate justice issues in their community, focusing on urban heat islands and air pollution. They will investigate the science behind these phenomena, learning about the greenhouse effect, energy transfer, and the role of human activities. Through data collection and analysis, students will assess the impact of these issues on health and the environment. They will explore engineering solutions, such as green roofs and urban greening, and evaluate their feasibility in their neighborhoods. The unit culminates in a community presentation where students propose actionable solutions to local stakeholders, empowering them to advocate for change.\n",
      "\n",
      "### Lesson Sets\n",
      "1. **Understanding Urban Heat Islands**: Students will learn about the causes and effects of urban heat islands, using temperature data collected from their neighborhoods to identify hotspots.\n",
      "2. **Air Quality and Health**: This lesson focuses on air pollution sources and its health impacts. Students will analyze air quality data and discuss how pollution disproportionately affects marginalized communities.\n",
      "3. **The Science of Climate Change**: Students will explore the greenhouse effect and energy transfer, connecting these concepts to the local climate issues they observe.\n",
      "4. **Engineering Solutions for Climate Justice**: Students will investigate engineering solutions like green roofs and urban greening, evaluating their potential to mitigate local climate issues.\n",
      "5. **Community Advocacy and Action**: In the final lesson, students will prepare presentations to propose their solutions to local stakeholders, practicing advocacy and communication skills.\n",
      "\n",
      "### Week-by-Week Plan\n",
      "**Week 1: Introduction to Climate Justice**\n",
      "- Objective: Understand local climate issues and their impact on communities.\n",
      "- Key Activities: Neighborhood walk, data collection, and initial discussions on climate justice.\n",
      "- Assessment: Reflection journal on personal experiences with climate issues.\n",
      "\n",
      "**Week 2: Investigating Urban Heat Islands**\n",
      "- Objective: Analyze the causes and effects of urban heat islands.\n",
      "- Key Activities: Data analysis, mapping hotspots, and exploring mitigation strategies.\n",
      "- Assessment: Group presentation on findings and proposed solutions.\n",
      "\n",
      "**Week 3: Exploring Air Quality**\n",
      "- Objective: Understand air pollution sources and health impacts.\n",
      "- Key Activities: Air quality data analysis, discussions on health disparities.\n",
      "- Assessment: Written report on air quality and health in their community.\n",
      "\n",
      "**Week 4: Engineering Solutions**\n",
      "- Objective: Evaluate engineering solutions for climate mitigation.\n",
      "- Key Activities: Research and design projects on green infrastructure.\n",
      "- Assessment: Prototype or model of a proposed solution.\n",
      "\n",
      "**Week 5: Advocacy and Action**\n",
      "- Objective: Develop advocacy skills and propose solutions to stakeholders.\n",
      "- Key Activities: Preparing and delivering community presentations.\n",
      "- Assessment: Community presentation and feedback session.\n",
      "\n",
      "### Notes on Integrating Cultivating Genius\n",
      "- **Identity**: Encourage students to explore their personal and cultural connections to climate justice issues.\n",
      "- **Skill**: Develop scientific inquiry, data analysis, and communication skills.\n",
      "- **Intellect**: Foster critical thinking about the intersection of science, society, and justice.\n",
      "- **Criticality**: Empower students to recognize and challenge systemic inequities in environmental policies.\n",
      "\n",
      "### NGSS Performance Expectations\n",
      "- HS-ESS3-1: Construct an explanation based on evidence for how the availability of natural resources, occurrence of natural hazards, and climate change have influenced human activity.\n",
      "- HS-ESS3-4: Evaluate or refine a technological solution that reduces impacts of human activities on natural systems.\n",
      "- HS-ETS1-3: Evaluate a solution to a complex real-world problem based on prioritized criteria and trade-offs.\n",
      "\n",
      "### Suggested Teacher Reflection Prompts\n",
      "- How did students connect their personal experiences to the climate justice issues discussed?\n",
      "- What challenges did students face in proposing solutions, and how did they overcome them?\n",
      "- How did the unit foster a sense of empowerment and advocacy among students?\n",
      "\n",
      "### Links to Support Materials\n",
      "- [Climate Literacy: The Essential Principles of Climate Sciences](http://downloads.climatescience.gov/Literacy/Climate%20Literacy%20Booklet%20Low-Res.pdf)\n",
      "- [GenDread Climate Crisis Emotional Support Network](https://gendread.substack.com/)\n",
      "- [Beyond Doom and Gloom: Teaching Climate Change to Foster Empowerment](https://www.nsta.org/connected-science-learning/connected-science-learning-may-june-2023/beyond-doom-and-gloom-teaching)\n",
      "\n",
      "‚úÖ Saved unit plan to: unit_outline_climate_justice_9th_grade_20250417_185128.md\n",
      "‚úÖ Saved structured JSON to: unit_outline_climate_justice_9th_grade_20250417_185128.json\n",
      "\n",
      "üìä Evaluation Mode: Top Retrieved Chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhal\\AppData\\Local\\Temp\\ipykernel_46668\\2242919779.py:187: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(topic)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Chunk 1 from OpenSciEd/C.4 Teacher Edition.pdf:\n",
      "Encourage students to respond to and build on each others‚Äô ideas. Affirm that both addressing the root cause and mitigating local impacts are important and urgent, and that science and engineering as well as social and political action are important to help save the oysters, the ecosystems, and the communities connected to oysters. ‚ú± ‚ú± ATTENDING TO EQUITY To cultivate critical hope (Duncan-Andrade, 2009) in the face of eco-anxiety, highlight forms of social and political action already underway \n",
      "\n",
      "üîπ Chunk 2 from NGSS_Documents/A_Framework_for_K12_Science_Education.pdf:\n",
      "U.S. Global Change Research Program/Climate Change Science Program. (2009). Climate Literacy: The Essential Principles of Climate Sciences. Washington, DC:  Author. Available: http://downloads.climatescience.gov/Literacy/Climate%20 Literacy%20Booklet%20Low-Res.pdf [June 2011].\n",
      "\n",
      "üîπ Chunk 3 from OpenSciEd/C.4 Teacher Edition.pdf:\n",
      "Crossout explanation: ESS2.D.3 Weather and Climate was first developed in OpenSciEd Unit C.1: How can we slow the flow of energy on Earth to protect vulnerable coastal communities?\n",
      "\n",
      "üîπ Chunk 4 from OpenSciEd/C.5 Teacher Edition.pdf:\n",
      "Personalize. https://www.fueleconomy.gov/feg/Find.do?action=customize&return=https%3 A%2F%2Fwww.fueleconomy.gov%2Ffeg%2FFind.do%3Faction%3Dsbs%26id%3D46970%26%23tab1¬† For support with emotions and youth during the climate crisis GenDread Climate Crisis emotional support network: https://gendread.substack.com/¬† For energy stored in fields NRC. (2013).\n",
      "\n",
      "üîπ Chunk 5 from GholdyMuhammad/Cultivating genius_ a four-layered framework for culturally -- Gholdy Muhammad; Bettina L Love.pdf:\n",
      "What Is Criticality? Criticality is the capacity to read, write, and think in ways of understanding  power, privilege, social justice, and oppression, particularly for populations  who have been historically marginalized in the world (Muhammad, 2018). When youth have criticality, they are able to see, name, and interrogate  the world not only to make sense of injustice but also to work toward  social transformation. Thus, students need spaces to name and critique  injustice and ultimately have t\n",
      "\n",
      "üîπ Chunk 6 from OpenSciEd/B.2 Teacher Edition.pdf:\n",
      "Gold, L. James, and L. Zeitz. 2023. Beyond doom and gloom: Teaching climate change to foster empowerment. Connected Science Learning¬†5 (3). https://www.nsta.org/connected-science-learning/connected-science-learning-may-june-2023/beyond-doom-and-gloom-teaching Hickman, C., E. Marks, P.\n",
      "\n",
      "‚úÖ Logged retrieved chunks to: retrieval_log_climate_justice_9th_grade_20250417_185128.csv\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Updated Notebook Script: Teacher Input + Unit Outline + Lesson Expansion in One Script with Evaluation Mode + CSV Logging\n",
    "\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": None,\n",
    "        \"lesson_sets\": {},\n",
    "        \"investigations\": {},\n",
    "        \"ngss\": [],\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"## Unit Title\"):\n",
    "            current_section = \"title\"\n",
    "        elif line.startswith(\"### Anchoring Phenomenon\"):\n",
    "            current_section = \"phenomenon\"\n",
    "        elif line.startswith(\"### Driving Question\"):\n",
    "            current_section = \"driving_question\"\n",
    "        elif line.startswith(\"### Storyline Arc Summary\") or line.startswith(\"### Introduction\"):\n",
    "            current_section = \"summary\"\n",
    "        elif line.startswith(\"### Lesson Sets\"):\n",
    "            current_section = \"lesson_sets\"\n",
    "        elif line.startswith(\"### Key Investigations\"):\n",
    "            current_section = \"investigations\"\n",
    "        elif line.startswith(\"### NGSS Performance Expectations\"):\n",
    "            current_section = \"ngss\"\n",
    "        elif line.startswith(\"### Suggested Teacher Reflection Prompts\"):\n",
    "            current_section = \"reflection_prompts\"\n",
    "        elif current_section == \"lesson_sets\" and re.match(r\"^\\d+\\.\\s+\\*\\*Lesson\", line):\n",
    "            match = re.match(r\"^(\\d+)\\.\\s+\\*\\*(Lesson.*?)\\*\\*[:\\s]*(.*)\", line)\n",
    "            if match:\n",
    "                idx, title, desc = match.groups()\n",
    "                sections[\"lesson_sets\"][f\"Lesson {idx}: {title}\"] = desc.strip()\n",
    "        elif current_section == \"investigations\" and re.match(r\"-\\s+Investigation\", line):\n",
    "            match = re.match(r\"-\\s+(Investigation \\d+):\\s*(.*)\", line)\n",
    "            if match:\n",
    "                key, value = match.groups()\n",
    "                sections[\"investigations\"][key] = value.strip()\n",
    "        elif current_section == \"ngss\" and line.startswith(\"- \"):\n",
    "            sections[\"ngss\"].append(line[2:].strip())\n",
    "        elif current_section == \"reflection_prompts\" and line.startswith(\"- \"):\n",
    "            sections[\"reflection_prompts\"].append(line[2:].strip())\n",
    "        elif current_section in [\"title\", \"phenomenon\", \"driving_question\", \"summary\"] and line:\n",
    "            if not sections[current_section]:\n",
    "                sections[current_section] = line\n",
    "            else:\n",
    "                sections[current_section] += f\" {line}\"\n",
    "\n",
    "    return sections\n",
    "\n",
    "# -----------------------------\n",
    "# Load Prompts\n",
    "# -----------------------------\n",
    "unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "lesson_prompt = load_prompt_from_file(Path(\"prompts\") / \"lesson_set_expansion_prompt.txt\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(vectorstore_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# Teacher Sidebar Instructions\n",
    "# -----------------------------\n",
    "print(\"\"\"\n",
    "üìò WELCOME TO THE CURRICULUM CODESIGNER TOOL\n",
    "\n",
    "üß© Step-by-step Instructions:\n",
    "1. Enter a unit topic, grade level, and student context.\n",
    "2. The system will retrieve documents and generate a unit outline.\n",
    "3. You may then expand individual lessons based on summaries.\n",
    "\n",
    "üß† Inspiration Bucket Guidelines:\n",
    "Include documents such as:\n",
    "- OpenSciEd units (PDFs)\n",
    "- NGSS-aligned science lessons\n",
    "- Local climate justice case studies\n",
    "- Equity frameworks (e.g., CRP, Cultivating Genius)\n",
    "- Teacher reflections and student perspectives (optional)\n",
    "\n",
    "üí¨ Tips:\n",
    "- Use a topic relevant to your context (e.g., \"climate justice in Chicago\").\n",
    "- Evaluation mode logs document traces for transparency.\n",
    "- Lesson expansions generate full instructional sequences.\n",
    "\n",
    "üìÅ Output files are saved in the 'outputs/' directory.\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------\n",
    "# RAG Chain for Unit Outline with Evaluation Toggle\n",
    "# -----------------------------\n",
    "eval_mode = input(\"üß™ Enable evaluation mode? (y/n): \").strip().lower() == \"y\"\n",
    "\n",
    "unit_rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# User Input\n",
    "# -----------------------------\n",
    "topic = input(\"üß™ Unit topic? \")\n",
    "grade_level = input(\"üéì Grade level? \")\n",
    "student_context = input(\"üë• Student/community context? \")\n",
    "\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Generate Unit Outline\n",
    "# -----------------------------\n",
    "print(\"\\nü§ñ Generating unit outline... Please wait...\\n\")\n",
    "unit_output = unit_rag_chain.invoke(data)\n",
    "print(\"\\nüìù Generated Unit Plan:\\n\")\n",
    "print(unit_output)\n",
    "\n",
    "# Save Markdown + JSON\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(unit_output)\n",
    "\n",
    "json_data = extract_sections(unit_output)\n",
    "json_data.update(data)\n",
    "json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved unit plan to: {md_path.name}\")\n",
    "print(f\"‚úÖ Saved structured JSON to: {json_path.name}\")\n",
    "\n",
    "# Evaluation mode output and log\n",
    "if eval_mode:\n",
    "    print(\"\\nüìä Evaluation Mode: Top Retrieved Chunks\")\n",
    "    docs = retriever.get_relevant_documents(topic)\n",
    "    log_path = output_dir / f\"retrieval_log_{filename_slug}_{timestamp}.csv\"\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Chunk #\", \"Source Folder\", \"Filename\", \"Preview\"])\n",
    "        for i, doc in enumerate(docs):\n",
    "            source_folder = doc.metadata.get(\"source_folder\", \"unknown\")\n",
    "            filename = doc.metadata.get(\"filename\", \"unknown\")\n",
    "            preview = doc.page_content[:500].replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "            print(f\"\\nüîπ Chunk {i+1} from {source_folder}/{filename}:\")\n",
    "            print(preview)\n",
    "            writer.writerow([i+1, source_folder, filename, preview])\n",
    "    print(f\"\\n‚úÖ Logged retrieved chunks to: {log_path.name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: Expand Lessons\n",
    "# -----------------------------\n",
    "expand = input(\"\\n‚ú® Would you like to expand each lesson? (y/n): \").strip().lower()\n",
    "if expand == \"y\" and json_data.get(\"lesson_sets\"):\n",
    "    lesson_chain = (\n",
    "        RunnableMap({\n",
    "            \"lesson_summary\": lambda x: x[\"lesson_summary\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x[\"grade_level\"],\n",
    "            \"context\": lambda x: x[\"context\"]\n",
    "        })\n",
    "        | lesson_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    print(\"\\nüöÄ Expanding lesson sets...\\n\")\n",
    "    for lesson_key, summary in json_data[\"lesson_sets\"].items():\n",
    "        print(f\"üîß {lesson_key}...\")\n",
    "        input_data = {\n",
    "            \"lesson_summary\": summary,\n",
    "            \"student_context\": json_data[\"student_context\"],\n",
    "            \"grade_level\": json_data[\"grade_level\"],\n",
    "            \"context\": json_data.get(\"title\", topic)\n",
    "        }\n",
    "        lesson_detail = lesson_chain.invoke(input_data)\n",
    "\n",
    "        # Save individual lesson\n",
    "        lesson_filename = f\"lesson_{slugify(lesson_key)}_{timestamp}.md\"\n",
    "        with open(output_dir / lesson_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(lesson_detail)\n",
    "\n",
    "        print(f\"‚úÖ Saved: {lesson_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88eba910",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'prompts\\\\lesson_expander_prompt.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Load Prompts\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     84\u001b[39m unit_prompt = load_prompt_from_file(Path(\u001b[33m\"\u001b[39m\u001b[33mprompts\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[33m\"\u001b[39m\u001b[33munit_outline_prompt.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m lesson_prompt = \u001b[43mload_prompt_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlesson_expander_prompt.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Load Vectorstore\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     90\u001b[39m vectorstore_path = \u001b[33m\"\u001b[39m\u001b[33mdata/embeddings/faiss_index\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mload_prompt_from_file\u001b[39m\u001b[34m(prompt_path)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_prompt_from_file\u001b[39m(prompt_path):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m PromptTemplate.from_template(f.read())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mrhal\\anaconda3\\envs\\ragtest1-env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'prompts\\\\lesson_expander_prompt.txt'"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Updated Notebook Script: Teacher Input + Unit Outline + Lesson Expansion in One Script with Evaluation Mode + CSV Logging\n",
    "\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": None,\n",
    "        \"lesson_sets\": {},\n",
    "        \"investigations\": {},\n",
    "        \"ngss\": [],\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"## Unit Title\"):\n",
    "            current_section = \"title\"\n",
    "        elif line.startswith(\"### Anchoring Phenomenon\"):\n",
    "            current_section = \"phenomenon\"\n",
    "        elif line.startswith(\"### Driving Question\"):\n",
    "            current_section = \"driving_question\"\n",
    "        elif line.startswith(\"### Storyline Arc Summary\") or line.startswith(\"### Introduction\"):\n",
    "            current_section = \"summary\"\n",
    "        elif line.startswith(\"### Lesson Sets\"):\n",
    "            current_section = \"lesson_sets\"\n",
    "        elif line.startswith(\"### Key Investigations\"):\n",
    "            current_section = \"investigations\"\n",
    "        elif line.startswith(\"### NGSS Performance Expectations\"):\n",
    "            current_section = \"ngss\"\n",
    "        elif line.startswith(\"### Suggested Teacher Reflection Prompts\"):\n",
    "            current_section = \"reflection_prompts\"\n",
    "        elif current_section == \"lesson_sets\" and re.match(r\"^\\d+\\.\\s+\\*\\*Lesson\", line):\n",
    "            match = re.match(r\"^(\\d+)\\.\\s+\\*\\*(Lesson.*?)\\*\\*[:\\s]*(.*)\", line)\n",
    "            if match:\n",
    "                idx, title, desc = match.groups()\n",
    "                sections[\"lesson_sets\"][f\"Lesson {idx}: {title}\"] = desc.strip()\n",
    "        elif current_section == \"investigations\" and re.match(r\"-\\s+Investigation\", line):\n",
    "            match = re.match(r\"-\\s+(Investigation \\d+):\\s*(.*)\", line)\n",
    "            if match:\n",
    "                key, value = match.groups()\n",
    "                sections[\"investigations\"][key] = value.strip()\n",
    "        elif current_section == \"ngss\" and line.startswith(\"- \"):\n",
    "            sections[\"ngss\"].append(line[2:].strip())\n",
    "        elif current_section == \"reflection_prompts\" and line.startswith(\"- \"):\n",
    "            sections[\"reflection_prompts\"].append(line[2:].strip())\n",
    "        elif current_section in [\"title\", \"phenomenon\", \"driving_question\", \"summary\"] and line:\n",
    "            if not sections[current_section]:\n",
    "                sections[current_section] = line\n",
    "            else:\n",
    "                sections[current_section] += f\" {line}\"\n",
    "\n",
    "    return sections\n",
    "\n",
    "# -----------------------------\n",
    "# Load Prompts\n",
    "# -----------------------------\n",
    "unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "lesson_prompt = load_prompt_from_file(Path(\"prompts\") / \"lesson_expander_prompt.txt\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(vectorstore_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# RAG Chain for Unit Outline with Evaluation Toggle\n",
    "# -----------------------------\n",
    "eval_mode = input(\"üß™ Enable evaluation mode? (y/n): \").strip().lower() == \"y\"\n",
    "\n",
    "unit_rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# User Input\n",
    "# -----------------------------\n",
    "topic = input(\"üß™ Unit topic? \")\n",
    "grade_level = input(\"üéì Grade level? \")\n",
    "student_context = input(\"üë• Student/community context? \")\n",
    "\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Generate Unit Outline\n",
    "# -----------------------------\n",
    "print(\"\\nü§ñ Generating unit outline... Please wait...\\n\")\n",
    "unit_output = unit_rag_chain.invoke(data)\n",
    "print(\"\\nüìù Generated Unit Plan:\\n\")\n",
    "print(unit_output)\n",
    "\n",
    "# Save Markdown + JSON\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(unit_output)\n",
    "\n",
    "json_data = extract_sections(unit_output)\n",
    "json_data.update(data)\n",
    "json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved unit plan to: {md_path.name}\")\n",
    "print(f\"‚úÖ Saved structured JSON to: {json_path.name}\")\n",
    "\n",
    "# Evaluation mode output and log\n",
    "if eval_mode:\n",
    "    print(\"\\nüìä Evaluation Mode: Top Retrieved Chunks\")\n",
    "    docs = retriever.get_relevant_documents(topic)\n",
    "    log_path = output_dir / f\"retrieval_log_{filename_slug}_{timestamp}.csv\"\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Chunk #\", \"Source Folder\", \"Filename\", \"Preview\"])\n",
    "        for i, doc in enumerate(docs):\n",
    "            source_folder = doc.metadata.get(\"source_folder\", \"unknown\")\n",
    "            filename = doc.metadata.get(\"filename\", \"unknown\")\n",
    "            preview = doc.page_content[:500].replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "            print(f\"\\nüîπ Chunk {i+1} from {source_folder}/{filename}:\")\n",
    "            print(preview)\n",
    "            writer.writerow([i+1, source_folder, filename, preview])\n",
    "    print(f\"\\n‚úÖ Logged retrieved chunks to: {log_path.name}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: Expand Lessons\n",
    "# -----------------------------\n",
    "expand = input(\"\\n‚ú® Would you like to expand each lesson? (y/n): \").strip().lower()\n",
    "if expand == \"y\" and json_data.get(\"lesson_sets\"):\n",
    "    lesson_chain = (\n",
    "        RunnableMap({\n",
    "            \"lesson_summary\": lambda x: x[\"lesson_summary\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x[\"grade_level\"],\n",
    "            \"context\": lambda x: x[\"context\"]\n",
    "        })\n",
    "        | lesson_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    print(\"\\nüöÄ Expanding lesson sets...\\n\")\n",
    "    for lesson_key, summary in json_data[\"lesson_sets\"].items():\n",
    "        print(f\"üîß {lesson_key}...\")\n",
    "        input_data = {\n",
    "            \"lesson_summary\": summary,\n",
    "            \"student_context\": json_data[\"student_context\"],\n",
    "            \"grade_level\": json_data[\"grade_level\"],\n",
    "            \"context\": json_data.get(\"title\", topic)\n",
    "        }\n",
    "        lesson_detail = lesson_chain.invoke(input_data)\n",
    "\n",
    "        # Save individual lesson\n",
    "        lesson_filename = f\"lesson_{slugify(lesson_key)}_{timestamp}.md\"\n",
    "        with open(output_dir / lesson_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(lesson_detail)\n",
    "\n",
    "        print(f\"‚úÖ Saved: {lesson_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragtest1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
