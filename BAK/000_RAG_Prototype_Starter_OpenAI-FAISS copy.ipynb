{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file \n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Starter Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New test\n",
    "This code does two things:\n",
    "1. **Diagnoses your inspiration corpus**\n",
    "2. **Builds a retriever filtered by folder name**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791e6afb574c4561875c1f2dcd51fe17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading PDFs from inspiration folders:   0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total documents loaded: 13845\\n\n",
      "📄 Sample document preview:\n",
      "EQuIP RUBRIC FOR SCIENCE EVALUATION  \n",
      " \n",
      "  \n",
      " \n",
      "How Do Eggs Become \n",
      "Chickens or Other \n",
      "Living Things? \n",
      "DEVELOPER: University of Illinois, College of Education \n",
      "GRADE: 6–7 | DATE OF REVIEW: September 2020\n",
      "\\n📁 Folder distribution in corpus:\n",
      "  - Inspiration_folder: 114 documents\n",
      "  - CRP: 208 documents\n",
      "  - NGSSAligned: 1118 documents\n",
      "  - OpenSciEd: 7674 documents\n",
      "  - Research: 327 documents\n",
      "  - Chicken: 207 documents\n",
      "  - Heartworm: 105 documents\n",
      "  - Pdf: 61 documents\n",
      "  - Pdfs: 66 documents\n",
      "  - Student: 1037 documents\n",
      "  - Teacher: 2601 documents\n",
      "  - Curriculum Development: 184 documents\n",
      "  - ECE: 143 documents\n",
      "\\n🔎 Using 7674 documents from folder: 'OpenSciEd'\n",
      "✅ Filtered retriever is ready.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# === Load All PDFs from Subfolders ===\n",
    "def load_all_pdfs_with_metadata(folder_path):\n",
    "    all_docs = []\n",
    "    pdf_paths = list(Path(folder_path).rglob(\"*.pdf\"))\n",
    "    for path in tqdm(pdf_paths, desc=\"Loading PDFs from inspiration folders\"):\n",
    "        loader = PyMuPDFLoader(str(path))\n",
    "        docs = loader.load()\n",
    "        for doc in docs:\n",
    "            doc.metadata[\"filename\"] = path.name\n",
    "            doc.metadata[\"source_folder\"] = path.parent.name\n",
    "        all_docs.extend(docs)\n",
    "    return all_docs\n",
    "\n",
    "docs = load_all_pdfs_with_metadata(\"documents/ToSort/Inspiration_folder\")\n",
    "\n",
    "# === Diagnostics ===\n",
    "print(f\"✅ Total documents loaded: {len(docs)}\\\\n\")\n",
    "\n",
    "# Preview a sample\n",
    "print(\"📄 Sample document preview:\")\n",
    "print(docs[0].page_content[:500])\n",
    "\n",
    "# Show folder distribution\n",
    "from collections import Counter\n",
    "folders = [doc.metadata.get(\"source_folder\", \"Unknown\") for doc in docs]\n",
    "folder_counts = Counter(folders)\n",
    "print(\"\\\\n📁 Folder distribution in corpus:\")\n",
    "for folder, count in folder_counts.items():\n",
    "    print(f\"  - {folder}: {count} documents\")\n",
    "\n",
    "# === Filter by a folder (e.g., OpenSciEd) ===\n",
    "target_folder = \"OpenSciEd\"  # <- Change this to the folder you want to test\n",
    "\n",
    "filtered_docs = [doc for doc in docs if doc.metadata.get(\"source_folder\") == target_folder]\n",
    "\n",
    "print(f\"\\\\n🔎 Using {len(filtered_docs)} documents from folder: '{target_folder}'\")\n",
    "\n",
    "# === Continue: Split, Embed, Store ===\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(filtered_docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4})\n",
    "\n",
    "print(\"✅ Filtered retriever is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mrag_output.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     f.write(\u001b[33m\"\u001b[39m\u001b[33mQUESTION:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     f.write(\u001b[43mquestion\u001b[49m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     f.write(\u001b[33m\"\u001b[39m\u001b[33mRESPONSE:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     f.write(response)\n",
      "\u001b[31mNameError\u001b[39m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"rag_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"QUESTION:\\n\")\n",
    "    f.write(question + \"\\n\\n\")\n",
    "    f.write(\"RESPONSE:\\n\")\n",
    "    f.write(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Multiple Outputs (Append Mode)\n",
    "If you're doing multiple runs and want to keep them all, use \"a\" (append mode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mrag_log.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     f.write(\u001b[33m\"\u001b[39m\u001b[33m===\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m20\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     f.write(\u001b[33m\"\u001b[39m\u001b[33mQUESTION:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[43mquestion\u001b[49m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     f.write(\u001b[33m\"\u001b[39m\u001b[33mRESPONSE:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + response + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"rag_log.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"===\" * 20 + \"\\n\")\n",
    "    f.write(\"QUESTION:\\n\" + question + \"\\n\\n\")\n",
    "    f.write(\"RESPONSE:\\n\" + response + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save with Metadata (as JSON)\n",
    "If you're building for research or prototyping teacher tools, consider saving as a .json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      4\u001b[39m log = {\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: datetime.now().isoformat(),\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mquestion\u001b[49m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m: response\n\u001b[32m      8\u001b[39m }\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mrag_outputs.jsonl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     11\u001b[39m     f.write(json.dumps(log) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "log = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"question\": question,\n",
    "    \"response\": response\n",
    "}\n",
    "\n",
    "with open(\"rag_outputs.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(log) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rag_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m data = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mclimate change\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstudent_context\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mBlack middle school students in Oakland\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgrade_level\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m8th grade\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlocal_community_assets\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlocal parks, environmental justice organizations, and community gardens\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mrag_chain\u001b[49m.invoke(data)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[31mNameError\u001b[39m: name 'rag_chain' is not defined"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"topic\": \"climate change\",\n",
    "    \"student_context\": \"Black middle school students in Oakland\",\n",
    "    \"grade_level\": \"8th grade\",\n",
    "    \"local_community_assets\": \"local parks, environmental justice organizations, and community gardens\"\n",
    "}\n",
    "\n",
    "response = rag_chain.invoke(data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"topic\": \"plate tectonics and earthquakes\",\n",
    "    \"student_context\": \"multilingual students in East San Jose\",\n",
    "    \"grade_level\": \"7th grade\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rag_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mrag_chain\u001b[49m.invoke(data)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[31mNameError\u001b[39m: name 'rag_chain' is not defined"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke(data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mgenerated_unit_plan.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     f.write(\u001b[43mresponse\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"generated_unit_plan.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Unit Plan: Climate Change\n",
      "\n",
      "### Anchoring Phenomenon:\n",
      "The anchoring phenomenon for this unit will be the impact of climate change on local parks and community gardens in Oakland. Students will explore how rising temperatures, changing precipitation patterns, and extreme weather events are affecting these natural spaces that they may visit or be familiar with.\n",
      "\n",
      "### Driving Question:\n",
      "How is climate change impacting our local community and what can we do to address it?\n",
      "\n",
      "### Learning Objectives:\n",
      "1. Understand the causes and effects of climate change, including how human activities contribute to global warming.\n",
      "2. Analyze the impact of climate change on local ecosystems, such as parks and community gardens.\n",
      "3. Evaluate potential solutions and actions that can mitigate the effects of climate change on our community.\n",
      "4. Develop a deeper understanding of environmental justice issues related to climate change and its disproportionate impact on marginalized communities.\n",
      "\n",
      "### Lesson Sequence Summary:\n",
      "1. **Introduction to Climate Change**: Explore the basic concepts of climate change, including greenhouse gases, global warming, and the role of human activities. Discuss the impact of climate change on the environment and communities.\n",
      "   \n",
      "2. **Local Impacts of Climate Change**: Investigate how climate change is affecting local parks and community gardens in Oakland. Students will collect data, analyze trends, and identify specific changes in these natural spaces.\n",
      "   \n",
      "3. **Environmental Justice and Climate Change**: Discuss the concept of environmental justice and how climate change disproportionately affects marginalized communities, including Black communities in Oakland. Explore case studies and real-life examples.\n",
      "   \n",
      "4. **Mitigation and Action**: Brainstorm and propose solutions to address climate change at the local level. Students will create action plans, participate in community initiatives, or engage with environmental justice organizations in Oakland.\n",
      "\n",
      "### Assessment Ideas:\n",
      "1. **Data Analysis**: Students will analyze temperature data, precipitation patterns, and other environmental indicators to assess the impact of climate change on local parks and community gardens.\n",
      "   \n",
      "2. **Case Study Presentation**: Groups of students will research and present a case study on a specific environmental justice issue related to climate change, highlighting its impact on Black communities in Oakland.\n",
      "   \n",
      "3. **Action Plan Proposal**: Students will develop an action plan outlining steps they can take to address climate change in their community, considering the unique challenges faced by marginalized groups.\n",
      "\n",
      "### Relevance to Black Middle School Students in Oakland:\n",
      "This unit plan is designed to be culturally relevant and engaging for Black middle school students in Oakland by connecting the abstract concept of climate change to their local environment and community. By focusing on the impact of climate change on familiar spaces like parks and community gardens, students can see the direct relevance of the topic to their lives. Additionally, the exploration of environmental justice issues will empower students to advocate for their community and take action to address climate change in a way that is meaningful and impactful. \n",
      "\n",
      "### Connections to Local Community Assets:\n",
      "This unit plan will leverage local parks, environmental justice organizations, and community gardens in Oakland to provide students with real-world examples and opportunities for hands-on learning. Students may have the chance to visit these spaces, collaborate with community partners, or participate in environmental initiatives that directly impact their community. By engaging with local assets, students can develop a deeper understanding of the impact of climate change on their surroundings and explore ways to make a positive difference in their neighborhood.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Structured RAG Chain with Path 2 (Dictionary Input)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Define your structured prompt (no Jinja-style conditionals in LangChain PromptTemplate)\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a thinking partner for a middle school science teacher designing a new unit plan.\n",
    "\n",
    "Design a unit on the topic of: {topic}\n",
    "For students: {student_context}\n",
    "Grade Level: {grade_level}\n",
    "\n",
    "Use the retrieved instructional materials to help generate:\n",
    "1. Anchoring Phenomenon\n",
    "2. Driving Question\n",
    "3. Learning Objectives\n",
    "4. Lesson Sequence Summary (3–5 lessons)\n",
    "5. Assessment Ideas\n",
    "6. Relevance to Students in {student_context}\n",
    "\n",
    "Connections to local community assets (if applicable): {local_community_assets}\n",
    "\n",
    "# Context:\n",
    "{context}\n",
    "\n",
    "# Unit Plan:\n",
    "\"\"\")\n",
    "\n",
    "# 2. Create a structured RAG chain\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        # Retriever needs a string: use topic only\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        # Pass these to fill the template\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\"),\n",
    "        \"local_community_assets\": lambda x: x.get(\"local_community_assets\", \"None specified\")\n",
    "    })\n",
    "    | prompt\n",
    "    | llm  # Your language model (ChatOpenAI or HuggingFacePipeline)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 3. Run it with structured input\n",
    "data = {\n",
    "    \"topic\": \"climate change\",\n",
    "    \"student_context\": \"Black middle school students in Oakland\",\n",
    "    \"grade_level\": \"8th grade\",\n",
    "    \"local_community_assets\": \"local parks, environmental justice organizations, and community gardens\"\n",
    "}\n",
    "\n",
    "response = rag_chain.invoke(data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m      8\u001b[39m unit_outline_prompt = PromptTemplate.from_template(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33mYou are a curriculum design thinking partner for a middle school science teacher.\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33mUse the retrieved examples from high-quality units to help generate a general outline for a new unit.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[33m# Draft Unit Outline:\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 2. Create the structured RAG chain for outline generation\u001b[39;00m\n\u001b[32m     31\u001b[39m rag_chain = (\n\u001b[32m     32\u001b[39m     RunnableMap({\n\u001b[32m     33\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: retriever.invoke(x[\u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m     34\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     35\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstudent_context\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m\"\u001b[39m\u001b[33mstudent_context\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgrade_level\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x.get(\u001b[33m\"\u001b[39m\u001b[33mgrade_level\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmiddle school\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m     })\n\u001b[32m     38\u001b[39m     | unit_outline_prompt\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     | \u001b[43mllm\u001b[49m  \u001b[38;5;66;03m# Your language model (ChatOpenAI or HuggingFacePipeline)\u001b[39;00m\n\u001b[32m     40\u001b[39m     | StrOutputParser()\n\u001b[32m     41\u001b[39m )\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# 3. Example Run\u001b[39;00m\n\u001b[32m     44\u001b[39m example_data = {\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mecosystems and human impact\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstudent_context\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mBlack and Latinx middle school students in Los Angeles\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     47\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgrade_level\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m7th grade\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# ✅ Structured RAG Chain – Step 1: Generate High-Level Unit Outline\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Define the UNIT OUTLINE prompt\n",
    "unit_outline_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a curriculum design thinking partner for a middle school science teacher.\n",
    "Use the retrieved examples from high-quality units to help generate a general outline for a new unit.\n",
    "\n",
    "Design a unit on the topic of: {topic}\n",
    "Grade Level: {grade_level}\n",
    "Student Context: {student_context}\n",
    "\n",
    "The output should include:\n",
    "1. Title of the Unit\n",
    "2. Anchoring Phenomenon\n",
    "3. Driving Question\n",
    "4. Summary of the storyline arc (3–5 sentence description)\n",
    "5. List of 3–5 Lesson Sets (just short 1–2 sentence summaries)\n",
    "6. NGSS Performance Expectations (if known or retrievable)\n",
    "\n",
    "# Inspiration Context:\n",
    "{context}\n",
    "\n",
    "# Draft Unit Outline:\n",
    "\"\"\")\n",
    "\n",
    "# 2. Create the structured RAG chain for outline generation\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_outline_prompt\n",
    "    | llm  # Your language model (ChatOpenAI or HuggingFacePipeline)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 3. Example Run\n",
    "example_data = {\n",
    "    \"topic\": \"ecosystems and human impact\",\n",
    "    \"student_context\": \"Black and Latinx middle school students in Los Angeles\",\n",
    "    \"grade_level\": \"7th grade\"\n",
    "}\n",
    "\n",
    "response = rag_chain.invoke(example_data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression here. Maybe you meant '==' instead of '='? (4216505224.py, line 55)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mRunnableMap({\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m cannot assign to expression here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "# ✅ Structured RAG Chain – Step 1: Generate High-Level Unit Outline\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Define the UNIT OUTLINE prompt\n",
    "unit_outline_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a curriculum design thinking partner for a middle school science teacher.\n",
    "Use the retrieved examples from high-quality units to help generate a general outline for a new unit.\n",
    "\n",
    "Design a unit on the topic of: {topic}\n",
    "Grade Level: {grade_level}\n",
    "Student Context: {student_context}\n",
    "\n",
    "The output should include:\n",
    "1. Title of the Unit\n",
    "2. Anchoring Phenomenon\n",
    "3. Driving Question\n",
    "4. Summary of the storyline arc (3–5 sentence description)\n",
    "5. List of 3–5 Lesson Sets (just short 1–2 sentence summaries)\n",
    "6. NGSS Performance Expectations (if known or retrievable)\n",
    "\n",
    "# Inspiration Context:\n",
    "{context}\n",
    "\n",
    "# Draft Unit Outline:\n",
    "\"\"\")\n",
    "\n",
    "# 2. Define the LESSON EXPANSION prompt\n",
    "lesson_expansion_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are continuing the collaborative curriculum design process for a middle school science teacher.\n",
    "Expand the following lesson set description into a complete lesson sequence.\n",
    "\n",
    "Student Context: {student_context}\n",
    "Grade Level: {grade_level}\n",
    "\n",
    "Lesson Set Description: {lesson_summary}\n",
    "\n",
    "Use examples from high-quality instructional materials to generate:\n",
    "1. Lesson Titles\n",
    "2. Learning Objectives\n",
    "3. Key Activities or Investigations (briefly described)\n",
    "4. Instructional Strategies and Supports\n",
    "5. Assessment Opportunities (formal or informal)\n",
    "\n",
    "# Related Context:\n",
    "{context}\n",
    "\n",
    "# Expanded Lesson Set:\n",
    "\"\"\")\n",
    "\n",
    "# 3. Create the structured RAG chain for outline generation\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_outline_prompt\n",
    "    | llm  = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) # Your language model (ChatOpenAI or HuggingFacePipeline)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 4. Example Run for Unit Outline\n",
    "data_outline = {\n",
    "    \"topic\": \"ecosystems and human impact\",\n",
    "    \"student_context\": \"Black and Latinx middle school students in Los Angeles\",\n",
    "    \"grade_level\": \"7th grade\"\n",
    "}\n",
    "\n",
    "response = rag_chain.invoke(data_outline)\n",
    "print(response)\n",
    "\n",
    "# 5. Example Run for Lesson Set Expansion (you can run this after generating the unit outline)\n",
    "lesson_data = {\n",
    "    \"lesson_summary\": \"Students analyze how pollution and development affect food webs in local ecosystems.\",\n",
    "    \"student_context\": \"Black and Latinx middle school students in Los Angeles\",\n",
    "    \"grade_level\": \"7th grade\",\n",
    "    \"context\": retriever.invoke(\"ecosystems human impact food webs\")\n",
    "}\n",
    "\n",
    "lesson_expansion_chain = (\n",
    "    RunnableMap({\n",
    "        \"lesson_summary\": lambda x: x[\"lesson_summary\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x[\"grade_level\"],\n",
    "        \"context\": lambda x: x[\"context\"]\n",
    "    })\n",
    "    | lesson_expansion_prompt\n",
    "    | llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "lesson_response = lesson_expansion_chain.invoke(lesson_data)\n",
    "print(lesson_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragtest1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
