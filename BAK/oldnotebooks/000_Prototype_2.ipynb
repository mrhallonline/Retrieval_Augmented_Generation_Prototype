{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (24.2)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.33.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.24.0-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.8 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.1/9.8 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.8 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.9/9.8 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 14.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.5 MB 13.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 12.2 MB/s eta 0:00:00\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.9/25.3 MB 14.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.0/25.3 MB 14.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.9/25.3 MB 14.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.1/25.3 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.2/25.3 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.1/25.3 MB 14.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.0/25.3 MB 14.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.1/25.3 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 2.9/6.9 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.8/6.9 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading narwhals-1.33.0-py3-none-any.whl (322 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.24.0-cp312-cp312-win_amd64.whl (239 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, watchdog, tzdata, toml, smmap, rpds-py, pyarrow, narwhals, blinker, referencing, pydeck, pandas, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 gitdb-4.0.12 gitpython-3.1.44 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 narwhals-1.33.0 pandas-2.2.3 pyarrow-19.0.1 pydeck-0.9.1 pytz-2025.2 referencing-0.36.2 rpds-py-0.24.0 smmap-5.0.2 streamlit-1.44.1 toml-0.10.2 tzdata-2025.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🛠️ Curriculum CoDesigner - AI Thinking Partner:\n",
    "A Streamlit-based, interactive tool for teachers to collaboratively design culturally responsive instructional units.\n",
    "\n",
    "🚀 Core Features\n",
    "1️⃣ Upload & Input Stage\n",
    "Allows teachers to upload custom documents (PDFs).\n",
    "\n",
    "Inputs for the unit topic, grade level, and specific student/community context.\n",
    "\n",
    "2️⃣ Unit Builder (RAG-based)\n",
    "Retrieves relevant inspiration using uploaded documents or a built-in corpus.\n",
    "\n",
    "Uses Retrieval Augmented Generation (RAG) to automatically create an initial unit outline.\n",
    "\n",
    "Leverages the OpenAI API (GPT-4) and FAISS embeddings.\n",
    "\n",
    "3️⃣ Lesson Expansion\n",
    "Expands the initial outline into a set of detailed lesson plans.\n",
    "\n",
    "Teachers choose how many lessons to generate.\n",
    "\n",
    "4️⃣ Teacher Reflection\n",
    "Guided reflection prompts for teachers to consider culturally responsive pedagogy (CRP).\n",
    "\n",
    "Questions designed to encourage culturally relevant teaching approaches.\n",
    "\n",
    "5️⃣ Review & Export\n",
    "Final step combining the unit plan, detailed lessons, and teacher reflections.\n",
    "\n",
    "Exports all content into a downloadable PDF.\n",
    "\n",
    "🌟 Pedagogical Enhancements (CRP Integration)\n",
    "Sidebar CRP resources (definitions, links, and examples).\n",
    "\n",
    "Integrated tips and prompts to reinforce CRP principles during reflections and final review.\n",
    "\n",
    "📂 File Structure & Data Flow\n",
    "Prompts (unit_outline_prompt.txt, lesson_expander_prompt.txt) for structured and reproducible generation.\n",
    "\n",
    "Uploaded Documents stored temporarily for contextual RAG queries.\n",
    "\n",
    "Generated Outputs (unit outlines, lesson plans, reflections) saved locally for persistent storage and PDF export.\n",
    "\n",
    "🔮 Potential Next Steps:\n",
    "Editable outputs directly within the interface.\n",
    "\n",
    "User analytics to monitor teacher engagement and CRP integration over time.\n",
    "\n",
    "Sharing and collaboration tools for educator teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our notebook now includes updated prompts that:\n",
    "\n",
    "Embed culturally responsive pedagogy (CRP) principles\n",
    "\n",
    "Encourage epistemic awareness (e.g., multiple ways of knowing)\n",
    "\n",
    "Include optional teacher reflection points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     37\u001b[39m lesson_expansion_prompt = PromptTemplate.from_template(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[33mYou are continuing the collaborative curriculum design process for a middle school science teacher.\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[33mExpand the following lesson set description into a complete lesson sequence.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33m# Expanded Lesson Set:\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# 3. Create the structured RAG chain for outline generation\u001b[39;00m\n\u001b[32m     61\u001b[39m rag_chain = (\n\u001b[32m     62\u001b[39m     RunnableMap({\n\u001b[32m     63\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: retriever.invoke(x[\u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m     64\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstudent_context\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m\"\u001b[39m\u001b[33mstudent_context\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgrade_level\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x.get(\u001b[33m\"\u001b[39m\u001b[33mgrade_level\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmiddle school\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m     })\n\u001b[32m     68\u001b[39m     | unit_outline_prompt\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     | \u001b[43mllm\u001b[49m  \u001b[38;5;66;03m# Your language model (ChatOpenAI or HuggingFacePipeline)\u001b[39;00m\n\u001b[32m     70\u001b[39m     | StrOutputParser()\n\u001b[32m     71\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# 4. Example Run for Unit Outline\u001b[39;00m\n\u001b[32m     74\u001b[39m data_outline = {\n\u001b[32m     75\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mecosystems and human impact\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     76\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstudent_context\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mBlack and Latinx middle school students in Los Angeles\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgrade_level\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m7th grade\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# ✅ Structured RAG Chain – Step 1: Generate High-Level Unit Outline\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Define the UNIT OUTLINE prompt (with embedded CRP reflection)\n",
    "unit_outline_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a curriculum design thinking partner for a middle school science teacher.\n",
    "Use the retrieved examples from high-quality units to help generate a general outline for a new unit.\n",
    "\n",
    "Design a unit on the topic of: {topic}\n",
    "Grade Level: {grade_level}\n",
    "Student Context: {student_context}\n",
    "\n",
    "As you design, consider how this unit can:\n",
    "- Reflect students’ cultural identities or community experiences\n",
    "- Promote inclusive participation and multiple ways of knowing in science\n",
    "- Encourage relevance to students' local lives and social issues\n",
    "\n",
    "The output should include:\n",
    "1. Title of the Unit\n",
    "2. Anchoring Phenomenon\n",
    "3. Driving Question\n",
    "4. Summary of the storyline arc (3–5 sentence description)\n",
    "5. List of 3–5 Lesson Sets (just short 1–2 sentence summaries)\n",
    "6. NGSS Performance Expectations (if known or retrievable)\n",
    "7. Suggested Teacher Reflection Prompts (e.g., How might this connect to students' lived realities?)\n",
    "\n",
    "# Inspiration Context:\n",
    "{context}\n",
    "\n",
    "# Draft Unit Outline:\n",
    "\"\"\")\n",
    "\n",
    "# 2. Define the LESSON EXPANSION prompt (with CRP + epistemic awareness)\n",
    "lesson_expansion_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are continuing the collaborative curriculum design process for a middle school science teacher.\n",
    "Expand the following lesson set description into a complete lesson sequence.\n",
    "\n",
    "Student Context: {student_context}\n",
    "Grade Level: {grade_level}\n",
    "\n",
    "Lesson Set Description: {lesson_summary}\n",
    "\n",
    "Use examples from high-quality instructional materials to generate:\n",
    "1. Lesson Titles\n",
    "2. Learning Objectives\n",
    "3. Key Activities or Investigations (briefly described)\n",
    "4. Instructional Strategies and Supports (especially for equity and inclusion)\n",
    "5. Assessment Opportunities (formal or informal)\n",
    "6. Optional: Opportunities for integrating cultural knowledge, multilingualism, or community assets\n",
    "\n",
    "# Related Context:\n",
    "{context}\n",
    "\n",
    "# Expanded Lesson Set:\n",
    "\"\"\")\n",
    "\n",
    "# 3. Create the structured RAG chain for outline generation\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_outline_prompt\n",
    "    | llm  # Your language model (ChatOpenAI or HuggingFacePipeline)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 4. Example Run for Unit Outline\n",
    "data_outline = {\n",
    "    \"topic\": \"ecosystems and human impact\",\n",
    "    \"student_context\": \"Black and Latinx middle school students in Los Angeles\",\n",
    "    \"grade_level\": \"7th grade\"\n",
    "}\n",
    "\n",
    "response = rag_chain.invoke(data_outline)\n",
    "print(response)\n",
    "\n",
    "# 5. Example Run for Lesson Set Expansion (you can run this after generating the unit outline)\n",
    "lesson_data = {\n",
    "    \"lesson_summary\": \"Students analyze how pollution and development affect food webs in local ecosystems.\",\n",
    "    \"student_context\": \"Black and Latinx middle school students in Los Angeles\",\n",
    "    \"grade_level\": \"7th grade\",\n",
    "    \"context\": retriever.invoke(\"ecosystems human impact food webs\")\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "lesson_expansion_chain = (\n",
    "    RunnableMap({\n",
    "        \"lesson_summary\": lambda x: x[\"lesson_summary\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x[\"grade_level\"],\n",
    "        \"context\": lambda x: x[\"context\"]\n",
    "    })\n",
    "    | lesson_expansion_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "lesson_response = lesson_expansion_chain.invoke(lesson_data)\n",
    "print(lesson_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Ingest and embed\n",
    "1. Recursively load PDFs from documents\\ToSort\\Inspiration_folder\n",
    "2. Split them into chunks\n",
    "3. Generate embeddings using OpenAI\n",
    "4. Save the result as a FAISS vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loading documents...\n",
      "📄 Total documents loaded: 13845\n",
      "✂️ Splitting into chunks...\n",
      "🔹 Total chunks: 71651\n",
      "🧠 Generating embeddings and saving vectorstore...\n",
      "✅ Saved FAISS vectorstore to: data/embeddings/faiss_index\n"
     ]
    }
   ],
   "source": [
    "# ✅ Script: Ingest PDFs, Split, Embed, and Save FAISS Vector Store\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 🔧 CONFIG\n",
    "pdf_folder = \"documents/ToSort/Inspiration_folder\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "chunk_size = 500\n",
    "chunk_overlap = 50\n",
    "\n",
    "# 📥 1. Load all PDFs (recursive)\n",
    "def load_documents_from_folder(folder):\n",
    "    all_docs = []\n",
    "    for path in Path(folder).rglob(\"*.pdf\"):\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(path))\n",
    "            docs = loader.load()\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"source\"] = str(path)\n",
    "            all_docs.extend(docs)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {path}: {e}\")\n",
    "    return all_docs\n",
    "\n",
    "# 🧱 2. Split into chunks\n",
    "def split_documents(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "# 💾 3. Save vectorstore\n",
    "def save_vectorstore(chunks, embeddings, output_path=\"data/embeddings/faiss_index\"):\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    vectorstore.save_local(output_path)\n",
    "    print(f\"✅ Saved FAISS vectorstore to: {output_path}\")\n",
    "\n",
    "# 🔄 Run pipeline\n",
    "def ingest_pipeline():\n",
    "    print(\"📂 Loading documents...\")\n",
    "    docs = load_documents_from_folder(pdf_folder)\n",
    "    print(f\"📄 Total documents loaded: {len(docs)}\")\n",
    "\n",
    "    print(\"✂️ Splitting into chunks...\")\n",
    "    chunks = split_documents(docs)\n",
    "    print(f\"🔹 Total chunks: {len(chunks)}\")\n",
    "\n",
    "    print(\"🧠 Generating embeddings and saving vectorstore...\")\n",
    "    save_vectorstore(chunks, embedding_model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ingest_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Write prompts to files\n",
    "1. The script write_prompts_to_files.py is now ready. When you run it, it will:\n",
    "2. Create a prompts/ folder if it doesn’t exist\n",
    "3. Write 3 templated prompt files:\n",
    "4. unit_outline_prompt.txt\n",
    "5. lesson_set_expansion_prompt.txt\n",
    "6. teacher_reflection_prompt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prompts written to: prompts\n"
     ]
    }
   ],
   "source": [
    "# ✅ Script: Write Prompt Templates to /prompts folder\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "PROMPTS = {\n",
    "    \"unit_outline_prompt.txt\": \"\"\"\n",
    "You are a curriculum design thinking partner for a middle school science teacher.\n",
    "Use the retrieved examples from high-quality units to help generate a general outline for a new unit.\n",
    "\n",
    "Design a unit on the topic of: {topic}\n",
    "Grade Level: {grade_level}\n",
    "Student Context: {student_context}\n",
    "\n",
    "As you design, consider how this unit can:\n",
    "- Reflect students’ cultural identities or community experiences\n",
    "- Promote inclusive participation and multiple ways of knowing in science\n",
    "- Encourage relevance to students' local lives and social issues\n",
    "\n",
    "The output should include:\n",
    "1. Title of the Unit\n",
    "2. Anchoring Phenomenon\n",
    "3. Driving Question\n",
    "4. Summary of the storyline arc (3–5 sentence description)\n",
    "5. List of 3–5 Lesson Sets (just short 1–2 sentence summaries)\n",
    "6. NGSS Performance Expectations (if known or retrievable)\n",
    "7. Suggested Teacher Reflection Prompts\n",
    "\n",
    "# Inspiration Context:\n",
    "{context}\n",
    "\n",
    "# Draft Unit Outline:\n",
    "\"\"\",\n",
    "\n",
    "    \"lesson_set_expansion_prompt.txt\": \"\"\"\n",
    "You are continuing the collaborative curriculum design process for a middle school science teacher.\n",
    "Expand the following lesson set description into a complete lesson sequence.\n",
    "\n",
    "Student Context: {student_context}\n",
    "Grade Level: {grade_level}\n",
    "Lesson Set Description: {lesson_summary}\n",
    "\n",
    "Use examples from high-quality instructional materials to generate:\n",
    "1. Lesson Titles\n",
    "2. Learning Objectives\n",
    "3. Key Activities or Investigations\n",
    "4. Instructional Strategies and Supports\n",
    "5. Assessment Opportunities\n",
    "6. Optional: Opportunities for integrating cultural knowledge or community assets\n",
    "\n",
    "# Related Context:\n",
    "{context}\n",
    "\n",
    "# Expanded Lesson Set:\n",
    "\"\"\",\n",
    "\n",
    "    \"teacher_reflection_prompt.txt\": \"\"\"\n",
    "After reviewing the generated unit plan or lesson sequence, reflect on the following:\n",
    "\n",
    "1. How might this unit connect to students' lived experiences?\n",
    "2. What voices or perspectives might be missing?\n",
    "3. Are there opportunities to center local knowledge or community partnerships?\n",
    "4. How does this unit reflect your values as a science educator?\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# ✍️ Save to prompts folder\n",
    "def write_prompts(folder_path=\"prompts\"):\n",
    "    Path(folder_path).mkdir(parents=True, exist_ok=True)\n",
    "    for filename, content in PROMPTS.items():\n",
    "        with open(Path(folder_path) / filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content.strip())\n",
    "    print(f\"✅ Prompts written to: {folder_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    write_prompts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load Prompts\n",
    "1. The script Load Prompts Dynamic is ready and will:\n",
    "2. Load any .txt prompt file from the prompts/ folder\n",
    "3. Wrap it as a PromptTemplate for use in LangChain chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prompts loaded successfully.\n",
      "\n",
      "--- Unit Outline Prompt ---\n",
      "\n",
      "You are a curriculum design thinking partner for a middle school science teacher.\n",
      "Use the retrieved examples from high-quality units to help generate a general outline for a new unit.\n",
      "\n",
      "Design a unit on the topic of: {topic}\n",
      "Grade Level: {grade_level}\n",
      "Student Context: {student_context}\n",
      "\n",
      "As you design, consider how this unit can:\n",
      "- Reflect students’ cultural identities or community experiences\n",
      "- Pro...\n"
     ]
    }
   ],
   "source": [
    "# ✅ Utility Script: Load Prompt Templates from Files\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def load_prompt_from_file(file_path: str) -> PromptTemplate:\n",
    "    \"\"\"Loads a prompt template from a text file and returns a LangChain PromptTemplate.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompt_text = f.read()\n",
    "    return PromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = Path(\"prompts\")\n",
    "\n",
    "    unit_prompt = load_prompt_from_file(base_path / \"unit_outline_prompt.txt\")\n",
    "    lesson_prompt = load_prompt_from_file(base_path / \"lesson_set_expansion_prompt.txt\")\n",
    "    reflection_prompt = load_prompt_from_file(base_path / \"teacher_reflection_prompt.txt\")\n",
    "\n",
    "    print(\"✅ Prompts loaded successfully.\")\n",
    "    print(\"\\n--- Unit Outline Prompt ---\\n\")\n",
    "    print(unit_prompt.template[:400] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Teacher Outline generator\n",
    "1. Prompts for topic, grade, and student context\n",
    "2. Loads your custom unit design prompt\n",
    "3. Pulls relevant examples using your vectorstore\n",
    "4. Generates a rich outline with GPT-4\n",
    "5. Saves the result as a .md file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Generating unit outline... Please wait...\n",
      "\n",
      "\n",
      "📝 Generated Unit Plan:\n",
      "\n",
      "1. Title of the Unit: \"Climate Justice: Our Role in a Changing World\"\n",
      "\n",
      "2. Anchoring Phenomenon: The disproportionate impact of climate change on marginalized communities in Oakland, California.\n",
      "\n",
      "3. Driving Question: How does climate change impact our community, and what can we do to promote climate justice?\n",
      "\n",
      "4. Summary of the Storyline Arc: The unit begins with an exploration of the concept of climate justice and the effects of climate change on the students' local community. Students then investigate the causes of these disparities and discuss potential solutions. The unit concludes with students developing action plans to address climate justice in their community.\n",
      "\n",
      "5. Lesson Sets:\n",
      "   - Lesson 1: Understanding Climate Change and Its Local Impact: Students learn about climate change and its specific effects on their community.\n",
      "   - Lesson 2: Exploring Climate Justice: Students explore the concept of climate justice and how it relates to their lives.\n",
      "   - Lesson 3: Causes of Climate Injustice: Students investigate the root causes of climate injustice, including systemic and structural factors.\n",
      "   - Lesson 4: Solutions for Climate Justice: Students research and discuss potential solutions to climate injustice.\n",
      "   - Lesson 5: Taking Action for Climate Justice: Students develop and present action plans to promote climate justice in their community.\n",
      "\n",
      "6. NGSS Performance Expectations: MS-ESS3-3, MS-ESS3-5, MS-ETS1-1, MS-ETS1-2, MS-ETS1-3\n",
      "\n",
      "7. Suggested Teacher Reflection Prompts:\n",
      "   - How did the lessons reflect the students' cultural identities and community experiences?\n",
      "   - How did the lessons promote inclusive participation and multiple ways of knowing in science?\n",
      "   - How did the lessons relate to students' local lives and social issues?\n",
      "   - What adjustments could be made to better serve the students' learning needs and interests?\n",
      "   - How did students respond to the concept of climate justice, and how can this be built upon in future lessons?\n",
      "\n",
      "✅ Saved unit plan to: outputs\\unit_outline_climate_justice.md\n"
     ]
    }
   ],
   "source": [
    "# ✅ Updated Notebook Script: Teacher Input + Unit Outline Generator\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Assume a utility function for loading prompts\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Prompt Template\n",
    "# -----------------------------\n",
    "prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    vectorstore_path, \n",
    "    embedding_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "\n",
    "# Create retriever (updated usage)\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Chain\n",
    "# -----------------------------\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Simulated Teacher Input\n",
    "# -----------------------------\n",
    "topic = input(\"🧪 What is the topic for the unit? \")\n",
    "grade_level = input(\"🎓 What is the grade level? \")\n",
    "student_context = input(\"👥 Describe the student/community context: \")\n",
    "\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Run Chain and Save Output\n",
    "# -----------------------------\n",
    "print(\"\\n🤖 Generating unit outline... Please wait...\\n\")\n",
    "outline_response = rag_chain.invoke(data)\n",
    "\n",
    "# Output\n",
    "print(\"\\n📝 Generated Unit Plan:\\n\")\n",
    "print(outline_response)\n",
    "\n",
    "# Optional: Save output to file\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(outline_response)\n",
    "\n",
    "print(f\"\\n✅ Saved unit plan to: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Lesson_expansion_generator\n",
    "\n",
    "1. Accepts a short lesson summary\n",
    "2. Pulls relevant examples using MMR search\n",
    "3. Expands it into a full lesson sequence (titles, objectives, strategies, etc.)\n",
    "4. Saves the output to a markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛠️ Expanding lesson set... Please wait...\n",
      "\n",
      "\n",
      "📚 Expanded Lesson Sequence:\n",
      "\n",
      "Lesson 1: Understanding Climate Justice\n",
      "- Learning Objectives: Students will understand the concept of climate justice and its relevance to their lives. They will also learn about the impacts of climate change on different communities.\n",
      "- Key Activities: Introduction to climate justice, group discussions on the impacts of climate change, and a brainstorming session on how climate justice can be achieved.\n",
      "- Instructional Strategies: Use of multimedia resources, group discussions, and brainstorming sessions.\n",
      "- Assessment Opportunities: Assessment of students' understanding through their participation in discussions and their contributions to the brainstorming session.\n",
      "- Optional: Integration of cultural knowledge by discussing how climate change impacts different cultures differently.\n",
      "\n",
      "Lesson 2: Climate Change and Its Impacts\n",
      "- Learning Objectives: Students will learn about the science behind climate change and its impacts on the environment and human lives.\n",
      "- Key Activities: Watching a documentary on climate change, conducting a research project on its impacts, and presenting their findings.\n",
      "- Instructional Strategies: Use of multimedia resources, research projects, and presentations.\n",
      "- Assessment Opportunities: Assessment of students' understanding through their research projects and presentations.\n",
      "- Optional: Integration of community assets by inviting a local climate scientist to speak to the class.\n",
      "\n",
      "Lesson 3: Climate Action and Advocacy\n",
      "- Learning Objectives: Students will learn about different ways to take action against climate change and advocate for climate justice.\n",
      "- Key Activities: Researching different climate action movements, creating a climate action plan, and presenting their plan.\n",
      "- Instructional Strategies: Research projects, action plan creation, and presentations.\n",
      "- Assessment Opportunities: Assessment of students' understanding through their action plans and presentations.\n",
      "- Optional: Integration of cultural knowledge by discussing how different cultures approach climate action.\n",
      "\n",
      "Lesson 4: Climate Justice in Our Community\n",
      "- Learning Objectives: Students will understand how climate change impacts their community and how they can contribute to climate justice.\n",
      "- Key Activities: Conducting a local climate impact study, creating a community action plan, and presenting their plan.\n",
      "- Instructional Strategies: Local study, action plan creation, and presentations.\n",
      "- Assessment Opportunities: Assessment of students' understanding through their local study and action plan.\n",
      "- Optional: Integration of community assets by collaborating with local organizations for the local climate impact study.\n",
      "\n",
      "Lesson 5: Reflection and Future Actions\n",
      "- Learning Objectives: Students will reflect on what they have learned about climate justice and plan for future actions.\n",
      "- Key Activities: Reflection activities, creating a personal climate action plan, and sharing their plans.\n",
      "- Instructional Strategies: Reflection activities, personal action plan creation, and sharing sessions.\n",
      "- Assessment Opportunities: Assessment of students' understanding through their reflection activities and personal action plans.\n",
      "- Optional: Integration of cultural knowledge by discussing how they can incorporate their cultural practices in their climate action plans.\n",
      "\n",
      "✅ Saved expanded lesson set to: outputs\\lesson_expansion_climate_justice.md\n"
     ]
    }
   ],
   "source": [
    "# ✅ Updated Notebook Script: Expand a Lesson Set into Full Sequence\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Assume a utility function for loading prompts\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Prompt Template\n",
    "# -----------------------------\n",
    "prompt_path = Path(\"prompts\") / \"lesson_set_expansion_prompt.txt\"\n",
    "lesson_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(vectorstore_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.4)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Chain\n",
    "# -----------------------------\n",
    "lesson_chain = (\n",
    "    RunnableMap({\n",
    "        \"lesson_summary\": lambda x: x[\"lesson_summary\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x[\"grade_level\"],\n",
    "        \"context\": lambda x: retriever.invoke(x[\"lesson_summary\"])\n",
    "    })\n",
    "    | lesson_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Simulated Teacher Input\n",
    "# -----------------------------\n",
    "lesson_summary = input(\"📘 Enter a short summary of the lesson set to expand: \")\n",
    "grade_level = input(\"🎓 What is the grade level? \")\n",
    "student_context = input(\"👥 Describe the student/community context: \")\n",
    "\n",
    "data = {\n",
    "    \"lesson_summary\": lesson_summary,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Run Chain and Save Output\n",
    "# -----------------------------\n",
    "print(\"\\n🛠️ Expanding lesson set... Please wait...\\n\")\n",
    "lesson_response = lesson_chain.invoke(data)\n",
    "\n",
    "# Output\n",
    "print(\"\\n📚 Expanded Lesson Sequence:\\n\")\n",
    "print(lesson_response)\n",
    "\n",
    "# Optional: Save output to file\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "filename = output_dir / f\"lesson_expansion_{lesson_summary[:25].replace(' ', '_')}.md\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lesson_response)\n",
    "\n",
    "print(f\"\\n✅ Saved expanded lesson set to: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Unit bundler\n",
    "1. Select a unit outline\n",
    "2. Choose one or more expanded lessons\n",
    "3. Bundle them into a clean, organized .md file\n",
    "4. Save it with a timestamp for version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Available Unit Outlines:\n",
      "[0] unit_outline_climate_justice.md\n",
      "\n",
      "📚 Available Lesson Expansions:\n",
      "[0] lesson_expansion_climate_justice.md\n",
      "\n",
      "✅ Final bundled unit saved to: outputs\\full_unit_plan_20250402-1657.md\n"
     ]
    }
   ],
   "source": [
    "# ✅ Notebook Script: Bundle Unit Outline and Lesson Expansions into One File\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Config Paths\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_files = list(outputs_dir.glob(\"unit_outline_*.md\"))\n",
    "lesson_files = list(outputs_dir.glob(\"lesson_expansion_*.md\"))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Choose Unit Outline\n",
    "# -----------------------------\n",
    "print(\"📦 Available Unit Outlines:\")\n",
    "for i, f in enumerate(unit_files):\n",
    "    print(f\"[{i}] {f.name}\")\n",
    "unit_index = int(input(\"\\nEnter number for unit to bundle: \"))\n",
    "unit_path = unit_files[unit_index]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Select Lessons to Include\n",
    "# -----------------------------\n",
    "print(\"\\n📚 Available Lesson Expansions:\")\n",
    "for i, f in enumerate(lesson_files):\n",
    "    print(f\"[{i}] {f.name}\")\n",
    "selected_lesson_indexes = input(\"\\nEnter numbers of lessons to include (comma separated): \")\n",
    "selected_indexes = [int(i.strip()) for i in selected_lesson_indexes.split(\",\") if i.strip().isdigit()]\n",
    "selected_lessons = [lesson_files[i] for i in selected_indexes]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Bundle Content\n",
    "# -----------------------------\n",
    "def read_text(path):\n",
    "    return path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "unit_text = read_text(unit_path)\n",
    "lesson_texts = [read_text(p) for p in selected_lessons]\n",
    "\n",
    "final_text = f\"\"\"\n",
    "# 🧪 Bundled Science Unit Plan\n",
    "\n",
    "## 📝 Unit Outline\n",
    "\n",
    "{unit_text}\n",
    "\n",
    "## 📚 Expanded Lessons\n",
    "\n",
    "\"\"\"\n",
    "for i, text in enumerate(lesson_texts):\n",
    "    final_text += f\"\\n---\\n\\n### Lesson {i+1}\\n{text}\\n\"\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Save Bundled File\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "filename = outputs_dir / f\"full_unit_plan_{timestamp}.md\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_text)\n",
    "\n",
    "print(f\"\\n✅ Final bundled unit saved to: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04 Teacher Reflection notebook is now set up!\n",
    "\n",
    "It will:\n",
    "\n",
    "Automatically load the most recent bundled unit\n",
    "\n",
    "Present a series of thoughtful, CRP-aligned reflection questions\n",
    "\n",
    "Capture teacher responses interactively\n",
    "\n",
    "Save the reflection as a .md file for iterative documentation\n",
    "\n",
    "This closes the loop for a powerful first cycle of your RAG tool: Inspire → Design → Expand → Bundle → Reflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Loaded unit file: full_unit_plan_20250402-1657.md\n",
      "\n",
      "🪞 Teacher Reflection Questions:\n",
      "\n",
      "1. How might this unit connect to your students' lived experiences?\n",
      "\n",
      "---\n",
      "\n",
      "2. What voices or perspectives might be missing in this unit?\n",
      "\n",
      "---\n",
      "\n",
      "3. Are there opportunities to center local knowledge, language, or community assets?\n",
      "\n",
      "---\n",
      "\n",
      "4. How does this unit reflect your goals and values as a science educator?\n",
      "\n",
      "---\n",
      "\n",
      "5. What elements might support or challenge your existing beliefs about who science is for?\n",
      "\n",
      "---\n",
      "\n",
      "6. How might this unit invite multiple ways of knowing, doing, or expressing ideas in science?\n",
      "\n",
      "---\n",
      "\n",
      "✅ Reflection saved to: outputs\\unit_reflection_20250402-1702.md\n"
     ]
    }
   ],
   "source": [
    "# ✅ Notebook Script: Teacher Reflection + Ideological Prompts\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Latest Bundled Unit\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_files = sorted(outputs_dir.glob(\"full_unit_plan_*.md\"), reverse=True)\n",
    "\n",
    "if not unit_files:\n",
    "    raise FileNotFoundError(\"⚠️ No bundled unit files found. Run 03_unit_bundler first.\")\n",
    "\n",
    "latest_unit_path = unit_files[0]\n",
    "print(f\"📄 Loaded unit file: {latest_unit_path.name}\\n\")\n",
    "\n",
    "unit_text = latest_unit_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Reflection Prompts\n",
    "# -----------------------------\n",
    "reflection_prompts = [\n",
    "    \"1. How might this unit connect to your students' lived experiences?\",\n",
    "    \"2. What voices or perspectives might be missing in this unit?\",\n",
    "    \"3. Are there opportunities to center local knowledge, language, or community assets?\",\n",
    "    \"4. How does this unit reflect your goals and values as a science educator?\",\n",
    "    \"5. What elements might support or challenge your existing beliefs about who science is for?\",\n",
    "    \"6. How might this unit invite multiple ways of knowing, doing, or expressing ideas in science?\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Interactive Reflection Form\n",
    "# -----------------------------\n",
    "responses = []\n",
    "print(\"🪞 Teacher Reflection Questions:\\n\")\n",
    "for prompt in reflection_prompts:\n",
    "    print(prompt)\n",
    "    answer = input(\"✏️  Your thoughts: \")\n",
    "    responses.append((prompt, answer))\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Save Annotated Reflection\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "filename = outputs_dir / f\"unit_reflection_{timestamp}.md\"\n",
    "\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# 🧠 Teacher Reflection on Unit Design\\n\\n\")\n",
    "    f.write(f\"## Based on Unit: {latest_unit_path.name}\\n\\n\")\n",
    "    f.write(\"\\n---\\n\\n\")\n",
    "    for prompt, answer in responses:\n",
    "        f.write(f\"**{prompt}**\\n\\n{answer}\\n\\n\")\n",
    "\n",
    "print(f\"✅ Reflection saved to: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflection Analytics / Logging\n",
    "We’ll track:\n",
    "\n",
    "Frequency of reflective responses\n",
    "\n",
    "Sentiment or tone (e.g. using a simple NLP classifier)\n",
    "\n",
    "Shifts in ideology or themes over time across units\n",
    "\n",
    "Load all saved reflections\n",
    "\n",
    "Analyze each response for sentiment (via TextBlob)\n",
    "\n",
    "Visualize trends across prompts\n",
    "\n",
    "Save the full dataset as a .csv for deeper qualitative or longitudinal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Notebook Script: Analyze Teacher Reflections for Growth & Themes\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Reflections\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "reflection_files = sorted(outputs_dir.glob(\"unit_reflection_*.md\"))\n",
    "\n",
    "if not reflection_files:\n",
    "    raise FileNotFoundError(\"⚠️ No reflection files found. Run 04_teacher_reflection first.\")\n",
    "\n",
    "reflection_data = []\n",
    "for file in reflection_files:\n",
    "    text = file.read_text(encoding=\"utf-8\")\n",
    "    lines = text.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"**\") and i + 1 < len(lines):\n",
    "            question = line.strip(\"* \")\n",
    "            response = lines[i + 1].strip()\n",
    "            reflection_data.append({\n",
    "                \"file\": file.name,\n",
    "                \"question\": question,\n",
    "                \"response\": response\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(reflection_data)\n",
    "print(f\"✅ Loaded {len(df)} reflection responses from {len(reflection_files)} files.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Sentiment Analysis\n",
    "# -----------------------------\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df[\"sentiment\"] = df[\"response\"].apply(get_sentiment)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Display Summary Stats\n",
    "# -----------------------------\n",
    "print(\"\\n📊 Sentiment Summary by Question:\")\n",
    "print(df.groupby(\"question\")[\"sentiment\"].mean().round(2))\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Visualization\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot(column=\"sentiment\", by=\"question\", rot=45)\n",
    "plt.title(\"Sentiment by Reflection Question\")\n",
    "plt.suptitle(\"\")\n",
    "plt.ylabel(\"Sentiment Polarity (-1 to 1)\")\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Export as CSV (optional)\n",
    "# -----------------------------\n",
    "df.to_csv(outputs_dir / \"reflection_analysis.csv\", index=False)\n",
    "print(\"\\n📁 Saved raw reflection data to: reflection_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export PDF\n",
    "06_export_pdf_doc will:\n",
    "\n",
    "Grab your most recent bundled unit and reflection\n",
    "\n",
    "Export them to both PDF (via fpdf) and Word/Google Doc format (via python-docx)\n",
    "\n",
    "Keep everything organized in your outputs/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Notebook Script: Export Bundled Unit and Reflection to PDF or Google Doc\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from fpdf import FPDF\n",
    "import markdown2\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Most Recent Files\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_file = sorted(outputs_dir.glob(\"full_unit_plan_*.md\"), reverse=True)[0]\n",
    "reflection_file = sorted(outputs_dir.glob(\"unit_reflection_*.md\"), reverse=True)[0]\n",
    "\n",
    "unit_text = unit_file.read_text(encoding=\"utf-8\")\n",
    "reflection_text = reflection_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Convert Markdown to HTML (for reference)\n",
    "# -----------------------------\n",
    "html_unit = markdown2.markdown(unit_text)\n",
    "html_reflection = markdown2.markdown(reflection_text)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Convert to PDF using FPDF\n",
    "# -----------------------------\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font(\"Arial\", \"B\", 12)\n",
    "        self.cell(0, 10, \"Bundled Science Unit + Reflection\", ln=True, align=\"C\")\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font(\"Arial\", \"B\", 11)\n",
    "        self.cell(0, 10, title, ln=True)\n",
    "        self.ln(4)\n",
    "\n",
    "    def chapter_body(self, text):\n",
    "        self.set_font(\"Arial\", size=10)\n",
    "        self.multi_cell(0, 6, text)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "pdf.chapter_title(\"Unit Plan\")\n",
    "pdf.chapter_body(unit_text)\n",
    "pdf.chapter_title(\"Teacher Reflection\")\n",
    "pdf.chapter_body(reflection_text)\n",
    "\n",
    "pdf_file = outputs_dir / f\"unit_bundle_export_{datetime.now().strftime('%Y%m%d-%H%M')}.pdf\"\n",
    "pdf.output(str(pdf_file))\n",
    "\n",
    "print(f\"✅ PDF exported to: {pdf_file}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Google Docs (Optional, Outline Only)\n",
    "# -----------------------------\n",
    "try:\n",
    "    from docx import Document\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"Bundled Science Unit + Teacher Reflection\", 0)\n",
    "\n",
    "    doc.add_heading(\"Unit Plan\", level=1)\n",
    "    doc.add_paragraph(unit_text)\n",
    "\n",
    "    doc.add_heading(\"Teacher Reflection\", level=1)\n",
    "    doc.add_paragraph(reflection_text)\n",
    "\n",
    "    docx_file = outputs_dir / f\"unit_bundle_export_{datetime.now().strftime('%Y%m%d-%H%M')}.docx\"\n",
    "    doc.save(docx_file)\n",
    "    print(f\"✅ Word Doc exported to: {docx_file}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⚠️ To enable Word/Google Docs export, run: pip install python-docx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07 Teacher interface App\n",
    "\n",
    " unified Streamlit app is now ready in 07_teacher_interface_app.py!\n",
    "\n",
    "This prototype lets teachers:\n",
    "\n",
    "Input a topic, grade, and student context\n",
    "\n",
    "Generate a culturally responsive unit outline with RAG + GPT-4\n",
    "\n",
    "View the result in-browser and save it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 11:03:19.225 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.227 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.340 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\mrhal\\anaconda3\\envs\\ragtest1-env\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-03 11:03:19.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.345 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.346 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-03 11:03:19.347 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.352 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Updated Unified Teacher-Facing App – Streamlit Prototype\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Assume a utility function for loading prompts\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"🧠 Curriculum CoDesigner – AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ⏳\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"📘 Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"✅ Saved to: {filename.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Upload\n",
    "Teachers can now:\n",
    "\n",
    "Upload custom PDFs (e.g., low-quality or local lessons)\n",
    "\n",
    "Have those documents instantly split, embedded, and used for RAG generation\n",
    "\n",
    "Fall back to your core inspiration corpus if no files are uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Unified Teacher-Facing App – Streamlit Prototype with File Uploads\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"🧠 Curriculum CoDesigner – AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"📁 Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"✅ Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ⏳\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"📘 Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"✅ Saved to: {filename.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add CRP reflection prompts\n",
    "\n",
    "Streamlit app now includes built-in CRP reflection prompts!\n",
    "\n",
    "After a unit outline is generated, teachers are guided to reflect on:\n",
    "\n",
    "Cultural relevance\n",
    "\n",
    "Epistemological diversity\n",
    "\n",
    "Local significance\n",
    "\n",
    "Equity-related uncertainties\n",
    "\n",
    "Reflections are saved per unit alongside the design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Unified Teacher-Facing App – Streamlit Prototype with File Uploads + Reflection Prompts\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"🧠 Curriculum CoDesigner – AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"📁 Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"✅ Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ⏳\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"📘 Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"✅ Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"🪞 Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"💾 Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"✅ Reflection saved to: {reflection_file.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson expansion is now built into the Streamlit app!\n",
    "\n",
    "After generating the unit outline, teachers can:\n",
    "\n",
    "Select how many lessons they want (2–10)\n",
    "\n",
    "Automatically generate detailed lesson-level plans\n",
    "\n",
    "Save and view those lessons in-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Unified Teacher-Facing App – Streamlit Prototype with File Uploads + Reflection Prompts + Lesson Expansion\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"🧠 Curriculum CoDesigner – AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"📁 Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"✅ Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    lesson_path = Path(\"prompts\") / \"lesson_expander_prompt.txt\"\n",
    "    lesson_prompt = load_prompt_from_file(lesson_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ⏳\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"📘 Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"✅ Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Lesson Expansion Prompt\n",
    "    # -----------------------------\n",
    "    st.subheader(\"📚 Expand Unit into Detailed Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"How many lessons would you like to expand into?\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: unit_output,\n",
    "                \"topic\": lambda x: x[\"topic\"],\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        lesson_data = {\"topic\": topic, \"num_lessons\": num_lessons}\n",
    "        expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(expanded_lessons)\n",
    "\n",
    "        expanded_file = output_dir / f\"lesson_expansion_{topic.replace(' ', '_')}.md\"\n",
    "        with open(expanded_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(expanded_lessons)\n",
    "        st.success(f\"✅ Expanded lessons saved to: {expanded_file.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"🪞 Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"💾 Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"✅ Reflection saved to: {reflection_file.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF export added! After reflection is submitted, your app now:\n",
    "\n",
    "Combines unit outline, lessons, and reflection into one PDF\n",
    "\n",
    "Saves and displays a download button for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Unified Teacher-Facing App – Streamlit Prototype with File Uploads + Reflection Prompts + Lesson Expansion + PDF Export\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"🧠 Curriculum CoDesigner – AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"📁 Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"✅ Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    lesson_path = Path(\"prompts\") / \"lesson_expander_prompt.txt\"\n",
    "    lesson_prompt = load_prompt_from_file(lesson_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait ⏳\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"📘 Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"✅ Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Lesson Expansion Prompt\n",
    "    # -----------------------------\n",
    "    st.subheader(\"📚 Expand Unit into Detailed Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"How many lessons would you like to expand into?\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: unit_output,\n",
    "                \"topic\": lambda x: x[\"topic\"],\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        lesson_data = {\"topic\": topic, \"num_lessons\": num_lessons}\n",
    "        expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(expanded_lessons)\n",
    "\n",
    "        expanded_file = output_dir / f\"lesson_expansion_{topic.replace(' ', '_')}.md\"\n",
    "        with open(expanded_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(expanded_lessons)\n",
    "        st.success(f\"✅ Expanded lessons saved to: {expanded_file.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"🪞 Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"💾 Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"✅ Reflection saved to: {reflection_file.name}\")\n",
    "\n",
    "        # Export to PDF\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "        for line in (unit_output + \"\\n\" + expanded_lessons + \"\\n\" + reflection_text).split(\"\\n\"):\n",
    "            pdf.multi_cell(0, 10, line)\n",
    "        pdf_filename = output_dir / f\"unit_bundle_{topic.replace(' ', '_')}.pdf\"\n",
    "        pdf.output(str(pdf_filename))\n",
    "        with open(pdf_filename, \"rb\") as f:\n",
    "            st.download_button(\"📄 Download Full Unit PDF\", data=f, file_name=pdf_filename.name)\n",
    "        st.success(\"📁 Full unit PDF exported!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review and export\n",
    " Review & Export tab is now live! You can:\n",
    "\n",
    "See the full unit + lessons + reflection all together\n",
    "\n",
    "Download it as a bundled PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Unified Teacher-Facing App – Streamlit Prototype with Review + Export Page\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"🧠 Curriculum CoDesigner – AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# App State & Session Storage\n",
    "# -----------------------------\n",
    "if \"unit_output\" not in st.session_state:\n",
    "    st.session_state.unit_output = \"\"\n",
    "if \"expanded_lessons\" not in st.session_state:\n",
    "    st.session_state.expanded_lessons = \"\"\n",
    "if \"reflection_text\" not in st.session_state:\n",
    "    st.session_state.reflection_text = \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step-by-step workflow\n",
    "# -----------------------------\n",
    "st.sidebar.title(\"Navigation\")\n",
    "page = st.sidebar.radio(\"Go to:\", [\"1️⃣ Upload & Inputs\", \"2️⃣ Unit Builder\", \"3️⃣ Lesson Expansion\", \"4️⃣ Reflection\", \"5️⃣ Review & Export\"])\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 1: Upload & Inputs\n",
    "# -----------------------------\n",
    "if page == \"1️⃣ Upload & Inputs\":\n",
    "    with st.expander(\"📁 Upload Custom Documents (optional)\"):\n",
    "        uploaded_files = st.file_uploader(\"Upload PDFs for inspiration\", type=\"pdf\", accept_multiple_files=True)\n",
    "        temp_dir = Path(\"data/uploads\")\n",
    "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        st.session_state.custom_docs = []\n",
    "        if uploaded_files:\n",
    "            for file in uploaded_files:\n",
    "                file_path = temp_dir / file.name\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file.read())\n",
    "                loader = PyMuPDFLoader(str(file_path))\n",
    "                docs = loader.load()\n",
    "                splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "                split_docs = splitter.split_documents(docs)\n",
    "                st.session_state.custom_docs.extend(split_docs)\n",
    "            st.success(f\"✅ Loaded {len(st.session_state.custom_docs)} chunks from PDFs.\")\n",
    "\n",
    "    with st.form(\"unit_form\"):\n",
    "        st.session_state.topic = st.text_input(\"Unit Topic\", \"ecosystems and human impact\")\n",
    "        st.session_state.grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "        st.session_state.context = st.text_area(\"Describe your student/community context\", \"Black and Latinx students in LA\")\n",
    "        st.session_state.submit_inputs = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 2: Unit Builder\n",
    "# -----------------------------\n",
    "if page == \"2️⃣ Unit Builder\" and st.session_state.get(\"submit_inputs\"):\n",
    "    st.info(\"🔄 Generating outline using your topic and context...\")\n",
    "    unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if st.session_state.get(\"custom_docs\"):\n",
    "        custom_vectorstore = FAISS.from_documents(st.session_state.custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    data = {\n",
    "        \"topic\": st.session_state.topic,\n",
    "        \"student_context\": st.session_state.context,\n",
    "        \"grade_level\": st.session_state.grade\n",
    "    }\n",
    "    st.session_state.unit_output = rag_chain.invoke(data)\n",
    "    st.subheader(\"📘 Generated Unit Outline\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 3: Lesson Expansion\n",
    "# -----------------------------\n",
    "if page == \"3️⃣ Lesson Expansion\" and st.session_state.unit_output:\n",
    "    st.subheader(\"📚 Expand Into Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"Number of lessons\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_prompt = load_prompt_from_file(Path(\"prompts\") / \"lesson_expander_prompt.txt\")\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: st.session_state.unit_output,\n",
    "                \"topic\": lambda x: st.session_state.topic,\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        lesson_data = {\"num_lessons\": num_lessons}\n",
    "        st.session_state.expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(st.session_state.expanded_lessons)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 4: Reflection\n",
    "# -----------------------------\n",
    "if page == \"4️⃣ Reflection\" and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"🪞 Teacher Reflection\")\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities of your students?\")\n",
    "        q2 = st.text_area(\"2. Where can students bring in multiple ways of knowing?\")\n",
    "        q3 = st.text_area(\"3. What could make this more locally meaningful?\")\n",
    "        q4 = st.text_area(\"4. What are open questions you still have about equity in this unit?\")\n",
    "        submit_reflection = st.form_submit_button(\"💾 Save Reflection\")\n",
    "\n",
    "    if submit_reflection:\n",
    "        st.session_state.reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {st.session_state.topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        st.success(\"✅ Reflection saved. Proceed to Review & Export tab.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 5: Review and Export\n",
    "# -----------------------------\n",
    "if page == \"5️⃣ Review & Export\" and st.session_state.unit_output and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"📦 Review Final Bundle\")\n",
    "    st.markdown(\"### 🧾 Unit Plan\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "    st.markdown(\"### 🧩 Lessons\")\n",
    "    st.markdown(st.session_state.expanded_lessons)\n",
    "    st.markdown(\"### 🪞 Reflection\")\n",
    "    st.markdown(st.session_state.reflection_text)\n",
    "\n",
    "    full_text = f\"\"\"\n",
    "{st.session_state.unit_output}\n",
    "\n",
    "{st.session_state.expanded_lessons}\n",
    "\n",
    "{st.session_state.reflection_text}\n",
    "\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    for line in full_text.split(\"\\n\"):\n",
    "        pdf.multi_cell(0, 10, line)\n",
    "    filename = output_dir / f\"unit_bundle_{st.session_state.topic.replace(' ', '_')}.pdf\"\n",
    "    pdf.output(str(filename))\n",
    "    with open(filename, \"rb\") as f:\n",
    "        st.download_button(\"📄 Download Full Unit PDF\", data=f, file_name=filename.name)\n",
    "    st.success(\"✅ Your full curriculum design has been bundled!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrated CRP pedagogical enhancements into your app:\n",
    "\n",
    "A concise explanation and resource link added in the sidebar.\n",
    "\n",
    "Helpful CRP tips added to guide reflections and review steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Unified Teacher-Facing App – Streamlit Prototype with Review + Export Page\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# CRP Pedagogical Resources\n",
    "CRP_RESOURCES = \"\"\"\n",
    "### 🌟 What is Culturally Responsive Pedagogy (CRP)?\n",
    "Culturally Responsive Pedagogy emphasizes using students' cultural backgrounds, experiences, and perspectives as valuable resources for teaching and learning.\n",
    "\n",
    "- **Validate Students' Identities:** Affirm and celebrate diverse cultural identities.\n",
    "- **Multiple Ways of Knowing:** Encourage students to bring their cultural, linguistic, and experiential knowledge into the classroom.\n",
    "- **Social Relevance:** Connect learning to issues that are significant within students' communities.\n",
    "\n",
    "[Learn more about CRP here](https://www.tolerance.org/professional-development/culturally-responsive-teaching)\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"🧠 Curriculum CoDesigner – AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# App State & Session Storage\n",
    "# -----------------------------\n",
    "if \"unit_output\" not in st.session_state:\n",
    "    st.session_state.unit_output = \"\"\n",
    "if \"expanded_lessons\" not in st.session_state:\n",
    "    st.session_state.expanded_lessons = \"\"\n",
    "if \"reflection_text\" not in st.session_state:\n",
    "    st.session_state.reflection_text = \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step-by-step workflow\n",
    "# -----------------------------\n",
    "st.sidebar.title(\"Navigation\")\n",
    "st.sidebar.markdown(CRP_RESOURCES)\n",
    "page = st.sidebar.radio(\"Go to:\", [\"1️⃣ Upload & Inputs\", \"2️⃣ Unit Builder\", \"3️⃣ Lesson Expansion\", \"4️⃣ Reflection\", \"5️⃣ Review & Export\"])\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 1: Upload & Inputs\n",
    "# -----------------------------\n",
    "if page == \"1️⃣ Upload & Inputs\":\n",
    "    with st.expander(\"📁 Upload Custom Documents (optional)\"):\n",
    "        uploaded_files = st.file_uploader(\"Upload PDFs for inspiration\", type=\"pdf\", accept_multiple_files=True)\n",
    "        temp_dir = Path(\"data/uploads\")\n",
    "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        st.session_state.custom_docs = []\n",
    "        if uploaded_files:\n",
    "            for file in uploaded_files:\n",
    "                file_path = temp_dir / file.name\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file.read())\n",
    "                loader = PyMuPDFLoader(str(file_path))\n",
    "                docs = loader.load()\n",
    "                splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "                split_docs = splitter.split_documents(docs)\n",
    "                st.session_state.custom_docs.extend(split_docs)\n",
    "            st.success(f\"✅ Loaded {len(st.session_state.custom_docs)} chunks from PDFs.\")\n",
    "\n",
    "    with st.form(\"unit_form\"):\n",
    "        st.session_state.topic = st.text_input(\"Unit Topic\", \"ecosystems and human impact\")\n",
    "        st.session_state.grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "        st.session_state.context = st.text_area(\"Describe your student/community context\", \"Black and Latinx students in LA\")\n",
    "        st.session_state.submit_inputs = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 2: Unit Builder\n",
    "# -----------------------------\n",
    "if page == \"2️⃣ Unit Builder\" and st.session_state.get(\"submit_inputs\"):\n",
    "    st.info(\"🔄 Generating outline using your topic and context...\")\n",
    "    unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if st.session_state.get(\"custom_docs\"):\n",
    "        custom_vectorstore = FAISS.from_documents(st.session_state.custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    data = {\n",
    "        \"topic\": st.session_state.topic,\n",
    "        \"student_context\": st.session_state.context,\n",
    "        \"grade_level\": st.session_state.grade\n",
    "    }\n",
    "    st.session_state.unit_output = rag_chain.invoke(data)\n",
    "    st.subheader(\"📘 Generated Unit Outline\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 3: Lesson Expansion\n",
    "# -----------------------------\n",
    "if page == \"3️⃣ Lesson Expansion\" and st.session_state.unit_output:\n",
    "    st.subheader(\"📚 Expand Into Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"Number of lessons\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_prompt = load_prompt_from_file(Path(\"prompts\") / \"lesson_expander_prompt.txt\")\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: st.session_state.unit_output,\n",
    "                \"topic\": lambda x: st.session_state.topic,\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        lesson_data = {\"num_lessons\": num_lessons}\n",
    "        st.session_state.expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(st.session_state.expanded_lessons)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 4: Reflection\n",
    "# -----------------------------\n",
    "if page == \"4️⃣ Reflection\" and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"🪞 Teacher Reflection\")\n",
    "st.info(\"Tip: Think about how your unit design incorporates aspects of CRP. See sidebar for guidance.\")\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities of your students?\")\n",
    "        q2 = st.text_area(\"2. Where can students bring in multiple ways of knowing?\")\n",
    "        q3 = st.text_area(\"3. What could make this more locally meaningful?\")\n",
    "        q4 = st.text_area(\"4. What are open questions you still have about equity in this unit?\")\n",
    "        submit_reflection = st.form_submit_button(\"💾 Save Reflection\")\n",
    "\n",
    "    if submit_reflection:\n",
    "        st.session_state.reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {st.session_state.topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        st.success(\"✅ Reflection saved. Proceed to Review & Export tab.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 5: Review and Export\n",
    "# -----------------------------\n",
    "if page == \"5️⃣ Review & Export\" and st.session_state.unit_output and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"📦 Review Final Bundle\")\n",
    "st.markdown(\"🔍 **Reflect**: Have you addressed the principles of Culturally Responsive Pedagogy in your curriculum?\")\n",
    "    st.markdown(\"### 🧾 Unit Plan\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "    st.markdown(\"### 🧩 Lessons\")\n",
    "    st.markdown(st.session_state.expanded_lessons)\n",
    "    st.markdown(\"### 🪞 Reflection\")\n",
    "    st.markdown(st.session_state.reflection_text)\n",
    "\n",
    "    full_text = f\"\"\"\n",
    "{st.session_state.unit_output}\n",
    "\n",
    "{st.session_state.expanded_lessons}\n",
    "\n",
    "{st.session_state.reflection_text}\n",
    "\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    for line in full_text.split(\"\\n\"):\n",
    "        pdf.multi_cell(0, 10, line)\n",
    "    filename = output_dir / f\"unit_bundle_{st.session_state.topic.replace(' ', '_')}.pdf\"\n",
    "    pdf.output(str(filename))\n",
    "    with open(filename, \"rb\") as f:\n",
    "        st.download_button(\"📄 Download Full Unit PDF\", data=f, file_name=filename.name)\n",
    "    st.success(\"✅ Your full curriculum design has been bundled!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragtest1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
