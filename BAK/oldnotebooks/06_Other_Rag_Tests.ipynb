{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is NOT available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file \n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langchain-huggingface) (0.30.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langchain-huggingface) (0.3.49)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface)\n",
      "  Downloading sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langchain-huggingface) (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\n",
      "Requirement already satisfied: networkx in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
      "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading sentence_transformers-4.0.1-py3-none-any.whl (340 kB)\n",
      "Installing collected packages: sentence-transformers, langchain-huggingface\n",
      "Successfully installed langchain-huggingface-0.1.2 sentence-transformers-4.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.6/10.2 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.4/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.3/10.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 11.5 MB/s eta 0:00:00\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Installing collected packages: safetensors, transformers\n",
      "Successfully installed safetensors-0.5.3 transformers-4.50.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87958e9d80c34259992c54f1139957e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5b2730dce847b6a4d055c32105aea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:  53%|#####2    | 1.05G/1.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e9e5d8b2104841a3679b91aa9933d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:  85%|########4 | 1.33G/1.57G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdce77886dee4995954004ef547c58a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:  76%|#######6  | 1.52G/1.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9c5735995f45578483b710091f0699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6aa5940b714531b421a028518be8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8679d0f8764c41da824f6f23a23626f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a77a673fa26430a8893a4e1b22e0bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80ede011b554d5990256a89b8d7c0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6c6c2cf3e24849a2bdf41097c45816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac04578318c44d69d5ba198e8ca1c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this chapter, we'll discuss first steps with generative AI. We will cover the following topics:\\n\\n1. Introduction to Generative AI\\n2. Understanding the Basics of Generative AI\\n3. Implementing Generative AI in Python\\n4. Applications of Generative AI\\n\\n## Introduction to Generative AI\\n\\nGenerative AI, also known as Generative Adversarial Networks (GANs), is a type of machine learning model that can generate new data that is similar to the training data. GANs consist of two neural networks: a generator and a discriminator.\"}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generate_text = pipeline(\n",
    "    task = \"text-generation\",\n",
    "    model = \"liminerity/Phigments12\",\n",
    "    trust_remote_code = True,\n",
    "    torch_dtype = \"auto\",\n",
    "    max_new_tokens = 100,\n",
    ")\n",
    "\n",
    "generate_text(\"In this chapter, we'll discuss first steps with generative AI. We will cover the following topics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87df3d8ce053452b86b947c88644d8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df46ed0d54a47a3a292735138d5a0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf24e1a77b04e4ba17b0fe5c2a6874d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5912a14e94ad4d13813d6f26982afa1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30297dc575442e3b5f2ddccd419aaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "hf = HuggingFacePipeline.from_model_id(model_id=\"gpt2\", task=\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question concisely:\n",
      "What is electroencephalography? Explain in detail.\n",
      "\n",
      "There are two general criteria for evaluating the health of a person:\n",
      "\n",
      "1. Will it be safe to operate the device over a distance of\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "# Assume `hf` is your HuggingFacePipeline instance\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question concisely:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "# New chaining syntax\n",
    "chain = prompt | hf\n",
    "\n",
    "# Ask the question\n",
    "question = \"What is electroencephalography? Explain in detail.\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = HuggingFacePipeline.from_model_id(\n",
    " model_id=\"gpt2\", task=\"text-generation\", pipeline_kwargs={\"max_new_tokens\": 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = prompt | hf\n",
    "question = \"What is electroencephalography? Be concise!\"\n",
    "print(llm_chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragtest1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
