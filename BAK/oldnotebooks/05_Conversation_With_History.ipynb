{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from pdfplumber) (11.0.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\mrhal\\anaconda3\\envs\\ragtest1-env\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250327->pdfplumber)\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.8/5.6 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.6/3.0 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 2.1/3.2 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pypdfium2, pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed cffi-1.17.1 cryptography-44.0.2 pdfminer.six-20250327 pdfplumber-0.11.6 pycparser-2.22 pypdfium2-4.30.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define the chat prompt template with system message and history placeholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a Question-Answering chatbot. Please provide an answer to the given question.\",\n",
    "        ),\n",
    "        # Note: Keep 'chat_history' as the key name for maintaining conversation context\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        # Format user question as input variable {question}\n",
    "        (\"human\", \"#Question:\\n{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the ChatGPT language model\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Build the processing chain: prompt -> LLM -> string output\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store conversation sessions\n",
    "store = {}\n",
    "\n",
    "# Get or create chat history for a given session ID\n",
    "def get_session_history(session_ids):\n",
    "    print(f\"[Conversation Session ID]: {session_ids}\")\n",
    "    \n",
    "    if session_ids not in store:     \n",
    "        # Initialize new chat history for this session\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # Return existing or newly created chat history\n",
    "\n",
    "# Configure chain with conversation history management\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,  \n",
    "    input_messages_key=\"question\",  # User input variable name\n",
    "    history_messages_key=\"chat_history\",  # Conversation history variable name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Initial input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conversation Session ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, Kevin! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "\n",
    "    # User input message\n",
    "    {\"question\": \"My name is Kevin.\"},\n",
    "    \n",
    "    # Configure session ID for conversation tracking\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle follow up query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conversation Session ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Kevin.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "\n",
    "    # User follow-up question\n",
    "    {\"question\": \"What is my name?\"},\n",
    "\n",
    "    # Use same session ID to maintain conversation context\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from operator import itemgetter\n",
    "\n",
    "loader = PDFPlumberLoader(\"documents/HowtoWriteNGSSLessonPlans.pdf\") \n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know.\n",
    "\n",
    "#Previous Chat History:\n",
    "{chat_history}\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for storing session records\n",
    "store = {}\n",
    "\n",
    "# Retrieve session records by session ID\n",
    "def get_session_history(session_ids):\n",
    "    print(f\"[Conversation Session ID]: {session_ids}\")\n",
    "\n",
    "    if session_ids not in store:\n",
    "        # Initialize new ChatMessageHistory and store it\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  \n",
    "\n",
    "# Create RAG chain with conversation history tracking\n",
    "rag_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,  # Session history retrieval function\n",
    "    input_messages_key=\"question\",  # Template variable key for user question\n",
    "    history_messages_key=\"chat_history\",  # Key for conversation history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conversation Session ID]: rag123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In building an NGSS-aligned unit, it is important to focus on several key aspects:\\n\\n1. **Performance Expectations (PEs):** Start with a Performance Expectation to guide what students should know by the end of a topic. This helps in developing lessons and activities that align with these expectations.\\n\\n2. **Three Dimensions of NGSS:** Incorporate the three dimensions into lesson plans: \\n   - **Science and Engineering Practices:** Engage students in practices to explore phenomena.\\n   - **Crosscutting Concepts:** Use these concepts to support understanding of core ideas.\\n   - **Disciplinary Core Ideas:** Focus on the core ideas that students need to understand.\\n\\n3. **Student Ideas and Prior Knowledge:** Consider commonly-held student ideas and prior concepts that are necessary for understanding the core ideas. Build on these ideas during instruction.\\n\\n4. **Flexibility and Adaptation:** There is flexibility in preparing lesson plans, allowing adaptation to state, school district, and curriculum needs.\\n\\n5. **Familiarity with NGSS Framework:** Familiarize yourself with the NGSS framework and how the standards are structured to effectively develop lesson plans.\\n\\nBy focusing on these elements, educators can create effective NGSS-aligned units that enhance student learning in science and engineering.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_with_history.invoke(\n",
    "\n",
    "    # User query for analysis\n",
    "    {\"question\": \"What is important in building an NGSS aligned unit?\"},\n",
    "\n",
    "    # Session configuration for conversation tracking\n",
    "    config={\"configurable\": {\"session_id\": \"rag123\"}},\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conversation Session ID]: rag123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'En la construcción de una unidad alineada con NGSS, es importante centrarse en varios aspectos clave:\\n\\n1. **Expectativas de Desempeño (PEs):** Comienza con una Expectativa de Desempeño para guiar lo que los estudiantes deben saber al final de un tema. Esto ayuda a desarrollar lecciones y actividades que se alineen con estas expectativas.\\n\\n2. **Tres Dimensiones de NGSS:** Incorpora las tres dimensiones en los planes de lecciones:\\n   - **Prácticas de Ciencia e Ingeniería:** Involucra a los estudiantes en prácticas para explorar fenómenos.\\n   - **Conceptos Transversales:** Utiliza estos conceptos para apoyar la comprensión de ideas centrales.\\n   - **Ideas Centrales Disciplinarias:** Enfócate en las ideas centrales que los estudiantes necesitan entender.\\n\\n3. **Ideas y Conocimientos Previos de los Estudiantes:** Considera las ideas comúnmente sostenidas por los estudiantes y los conceptos previos necesarios para entender las ideas centrales. Construye sobre estas ideas durante la instrucción.\\n\\n4. **Flexibilidad y Adaptación:** Hay flexibilidad en la preparación de planes de lecciones, permitiendo la adaptación a las necesidades del estado, distrito escolar y currículo.\\n\\n5. **Familiaridad con el Marco NGSS:** Familiarízate con el marco NGSS y cómo están estructurados los estándares para desarrollar efectivamente los planes de lecciones.\\n\\nAl enfocarse en estos elementos, los educadores pueden crear unidades alineadas con NGSS efectivas que mejoren el aprendizaje de los estudiantes en ciencia e ingeniería.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_with_history.invoke(\n",
    "\n",
    "    # Request for translation of previous response\n",
    "    {\"question\": \"Please translate the previous answer into Spanish.\"},\n",
    "\n",
    "    # Session configuration for maintaining conversation context\n",
    "    config={\"configurable\": {\"session_id\": \"rag123\"}},\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragtest1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
