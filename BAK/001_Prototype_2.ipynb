{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file \n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Ingest and embed\n",
    "1. Recursively load PDFs from documents\\ToSort\\Inspiration_folder\n",
    "2. Split them into chunks\n",
    "3. Generate embeddings using OpenAI\n",
    "4. Save the result as a FAISS vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading PDFs from inspiration folders: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:20<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Total documents loaded: 8506\n",
      "\\ðŸ“ Folder distribution in corpus:\n",
      "  - Equip_Rubric: 154 documents\n",
      "  - NGSS_Documents: 401 documents\n",
      "  - OpenSciEd: 7674 documents\n",
      "  - CRP: 260 documents\n",
      "  - Curriculum Development: 17 documents\n",
      "âœ‚ï¸ Splitting into chunks...\n",
      "ðŸ”¹ Total chunks: 46539\n",
      "ðŸ§  Generating embeddings and saving vectorstore...\n",
      "âœ… Saved FAISS vectorstore to: data/embeddings/faiss_index\n"
     ]
    }
   ],
   "source": [
    "# âœ… Script: Ingest PDFs, Split, Embed, and Save FAISS Vector Store\n",
    "# 5 minutes on MAC\n",
    "# This script loads PDF documents from a specified folder, splits them into chunks, generates embeddings using OpenAI's text-embedding-3-small model, and saves the resulting vector store using FAISS.\n",
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file \n",
    "load_dotenv(override=True)\n",
    "\n",
    "# ðŸ”§ CONFIG\n",
    "pdf_folder = \"Inspiration_folder\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "chunk_size = 500\n",
    "chunk_overlap = 50\n",
    "\n",
    "# ðŸ“¥ 1. Load all PDFs (recursive)\n",
    "# === Load All PDFs from Subfolders ===\n",
    "def load_all_pdfs_with_metadata(folder_path):\n",
    "    all_docs = []\n",
    "    pdf_paths = list(Path(folder_path).rglob(\"*.pdf\"))\n",
    "    for path in tqdm(pdf_paths, desc=\"Loading PDFs from inspiration folders\"):\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(path))\n",
    "            docs = loader.load()\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"filename\"] = path.name\n",
    "                doc.metadata[\"source_folder\"] = path.parent.name\n",
    "            all_docs.extend(docs)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {path}: {e}\")\n",
    "    return all_docs\n",
    "\n",
    "# ðŸ§± 2. Split into chunks\n",
    "def split_documents(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "# ðŸ’¾ 3. Save vectorstore\n",
    "def save_vectorstore(chunks, embeddings, output_path=\"data/embeddings/faiss_index\"):\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    vectorstore.save_local(output_path)\n",
    "    print(f\"âœ… Saved FAISS vectorstore to: {output_path}\")\n",
    "\n",
    "# ðŸ”„ Run pipeline\n",
    "def ingest_pipeline():\n",
    "    print(\"ðŸ“‚ Loading documents...\")\n",
    "    docs = load_all_pdfs_with_metadata(pdf_folder)\n",
    "    print(f\"ðŸ“„ Total documents loaded: {len(docs)}\")\n",
    "\n",
    "    # Show folder distribution\n",
    "    from collections import Counter\n",
    "    folders = [doc.metadata.get(\"source_folder\", \"Unknown\") for doc in docs]\n",
    "    folder_counts = Counter(folders)\n",
    "    print(\"ðŸ“ Folder distribution in corpus:\")\n",
    "    for folder, count in folder_counts.items():\n",
    "        print(f\"  - {folder}: {count} documents\")\n",
    "\n",
    "    print(\"âœ‚ï¸ Splitting into chunks...\")\n",
    "    chunks = split_documents(docs)\n",
    "    print(f\"ðŸ”¹ Total chunks: {len(chunks)}\")\n",
    "\n",
    "    print(\"ðŸ§  Generating embeddings and saving vectorstore...\")\n",
    "    save_vectorstore(chunks, embedding_model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ingest_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Write prompts to files\n",
    "1. The script write_prompts_to_files.py is now ready. When you run it, it will:\n",
    "2. Create a prompts/ folder if it doesnâ€™t exist\n",
    "3. Write 3 templated prompt files:\n",
    "4. unit_outline_prompt.txt\n",
    "5. lesson_set_expansion_prompt.txt\n",
    "6. teacher_reflection_prompt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prompts written to: prompts\n"
     ]
    }
   ],
   "source": [
    "# âœ… Script: Write Prompt Templates to /prompts folder\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "PROMPTS = {\n",
    "    \"unit_outline_prompt.txt\": \"\"\"\n",
    "You are an experienced curriculum design thinking partner for a middle school science teacher. You have \n",
    "full knowledge of creating Next Generation Science Standards (NGSS) aligned lessons supported by understanding\n",
    "of the EQuIP Rubric for Lessons & Units: Science as well as Culturally Responsive Pedagogy.\n",
    "Use the retrieved examples from high-quality NGSS and OpenSciEd units to help generate a general outline for a new unit.\n",
    "Your task is to design a High Quality unit that is culturally relevant and responsive to the students' community context rooted in and NGSS.\n",
    "Design a unit on the topic of: {topic}\n",
    "Grade Level: {grade_level}\n",
    "Student Context: {student_context}\n",
    "\n",
    "As you design, consider how this unit can:\n",
    "- Reflect studentsâ€™ cultural identities or community experiences\n",
    "- Promote inclusive participation and multiple ways of knowing in science\n",
    "- Encourage relevance to students' local lives and social issues\n",
    "\n",
    "The output should include:\n",
    "1. Title of the Unit\n",
    "2. NGSS Anchoring Phenomenon\n",
    "3. Driving Question\n",
    "4. Summary of the storyline arc (8-10 detailed sentences in length)\n",
    "5. List of 3â€“5 Lesson Sets (3-4 sentences each)\n",
    "6. List of 3â€“5 Key Investigations (3-4 sentences each)\n",
    "6. NGSS Performance Expectations (if known or retrievable)\n",
    "7. Suggested Teacher Reflection Prompts\n",
    "\n",
    "# Inspiration Context:\n",
    "{context}\n",
    "\n",
    "# Draft Unit Outline:\n",
    "\"\"\",\n",
    "\n",
    "    \"lesson_set_expansion_prompt.txt\": \"\"\"\n",
    "You are continuing the collaborative curriculum design process for a middle school science teacher.\n",
    "Expand the following lesson set description into a complete lesson sequence.\n",
    "\n",
    "Student Context: {student_context}\n",
    "Grade Level: {grade_level}\n",
    "Lesson Set Description: {lesson_summary}\n",
    "\n",
    "Use examples from high-quality instructional materials to generate:\n",
    "1. Lesson Titles\n",
    "2. Learning Objectives\n",
    "3. Key Activities or Investigations\n",
    "4. Instructional Strategies and Supports\n",
    "5. Assessment Opportunities\n",
    "6. Optional: Opportunities for integrating cultural knowledge or community assets\n",
    "\n",
    "# Related Context:\n",
    "{context}\n",
    "\n",
    "# Expanded Lesson Set:\n",
    "\"\"\",\n",
    "\n",
    "    \"teacher_reflection_prompt.txt\": \"\"\"\n",
    "After reviewing the generated unit plan or lesson sequence, reflect on the following:\n",
    "\n",
    "1. How might this unit connect to students' lived experiences?\n",
    "2. What voices or perspectives might be missing?\n",
    "3. Are there opportunities to center local knowledge or community partnerships?\n",
    "4. How does this unit reflect your values as a science educator?\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# âœï¸ Save to prompts folder\n",
    "def write_prompts(folder_path=\"prompts\"):\n",
    "    Path(folder_path).mkdir(parents=True, exist_ok=True)\n",
    "    for filename, content in PROMPTS.items():\n",
    "        with open(Path(folder_path) / filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content.strip())\n",
    "    print(f\"âœ… Prompts written to: {folder_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    write_prompts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load Prompts\n",
    "1. The script Load Prompts Dynamic is ready and will:\n",
    "2. Load any .txt prompt file from the prompts/ folder\n",
    "3. Wrap it as a PromptTemplate for use in LangChain chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prompts loaded successfully.\n",
      "\n",
      "--- Unit Outline Prompt ---\n",
      "\n",
      "You are an experienced curriculum design thinking partner for a middle school science teacher. You have \n",
      "full knowledge of creating Next Generation Science Standards (NGSS) aligned lessons supported by understanding\n",
      "of the EQuIP Rubric for Lessons & Units: Science as well as Culturally Responsive Pedagogy.\n",
      "Use the retrieved examples from high-quality NGSS and OpenSciEd units to help generate a gen...\n"
     ]
    }
   ],
   "source": [
    "# âœ… Utility Script: Load Prompt Templates from Files\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def load_prompt_from_file(file_path: str) -> PromptTemplate:\n",
    "    \"\"\"Loads a prompt template from a text file and returns a LangChain PromptTemplate.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompt_text = f.read()\n",
    "    return PromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = Path(\"prompts\")\n",
    "\n",
    "    unit_prompt = load_prompt_from_file(base_path / \"unit_outline_prompt.txt\")\n",
    "    lesson_prompt = load_prompt_from_file(base_path / \"lesson_set_expansion_prompt.txt\")\n",
    "    reflection_prompt = load_prompt_from_file(base_path / \"teacher_reflection_prompt.txt\")\n",
    "\n",
    "    print(\"âœ… Prompts loaded successfully.\")\n",
    "    print(\"\\n--- Unit Outline Prompt ---\\n\")\n",
    "    print(unit_prompt.template[:400] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Teacher Outline generator\n",
    "1. Prompts for topic, grade, and student context\n",
    "2. Loads your custom unit design prompt\n",
    "3. Pulls relevant examples using your vectorstore\n",
    "4. Generates a rich outline with GPT-4\n",
    "5. Saves the result as a .md file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Generating unit outline... Please wait...\n",
      "\n",
      "\n",
      "ðŸ“ Generated Unit Plan:\n",
      "\n",
      "1. Title of the Unit: \"Biology and Society: Understanding Sex, Gender, and Athletic Performance\"\n",
      "\n",
      "2. NGSS Anchoring Phenomenon: The differences in athletic performance between individuals of different biological sexes, and how these differences are influenced by genetic mutations and societal perceptions of gender.\n",
      "\n",
      "3. Driving Question: \"How do biological sex, genetic mutations, and societal understanding of gender influence athletic performance?\"\n",
      "\n",
      "4. Summary of the Storyline Arc: \n",
      "The unit begins with students observing a local sports event, noting differences in performance between male and female athletes. They then explore the concepts of biological sex and gender, understanding that while they are often used interchangeably, they are distinct. Students will learn about the role of chromosomes in determining biological sex and how genetic mutations can affect the development of sex characteristics. They will then investigate how these biological factors can influence athletic performance. The unit concludes with a discussion on societal perceptions of gender and how these can impact opportunities and expectations in athletics. Throughout the unit, students will be encouraged to consider their local context and the implications of these concepts on their community.\n",
      "\n",
      "5. Lesson Sets:\n",
      "   - Lesson 1: Observing and Discussing Local Sports Events\n",
      "   - Lesson 2: Understanding Biological Sex and Gender\n",
      "   - Lesson 3: Exploring Chromosomes and Genetic Mutations\n",
      "   - Lesson 4: Investigating the Impact of Biology on Athletic Performance\n",
      "   - Lesson 5: Discussing Societal Perceptions of Gender in Athletics\n",
      "\n",
      "6. Key Investigations:\n",
      "   - Investigation 1: Observing Differences in Athletic Performance\n",
      "   - Investigation 2: Modeling Chromosomes and Genetic Mutations\n",
      "   - Investigation 3: Researching the Biological Factors Influencing Athletic Performance\n",
      "   - Investigation 4: Exploring Societal Perceptions of Gender in Local Athletics\n",
      "   - Investigation 5: Reflecting on the Impact of Biology and Society on Athletic Performance\n",
      "\n",
      "7. NGSS Performance Expectations: \n",
      "   - HS-LS1-4: Use a model to illustrate the role of cellular division (mitosis) and differentiation in producing and maintaining complex organisms.\n",
      "   - HS-LS3-1: Ask questions to clarify relationships about the role of DNA and chromosomes in coding the instructions for characteristic traits passed from parents to offspring.\n",
      "\n",
      "8. Suggested Teacher Reflection Prompts:\n",
      "   - How did students' understanding of biological sex and gender evolve throughout the unit?\n",
      "   - How effectively did students apply their understanding of genetics to the context of athletic performance?\n",
      "   - How did the unit promote inclusive participation and multiple ways of knowing in science?\n",
      "   - How did students connect the content to their local lives and social issues?\n",
      "   - How can this unit be improved to better reflect studentsâ€™ cultural identities or community experiences?\n",
      "\n",
      "âœ… Saved unit plan to: unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_200924.md\n",
      "âœ… Saved structured JSON to: unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_200924.json\n"
     ]
    }
   ],
   "source": [
    "# âœ… Updated Notebook Script: Teacher Input + Unit Outline Generator with JSON Output\n",
    "\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": None,\n",
    "        \"lesson_sets\": [],\n",
    "        \"investigations\": [],\n",
    "        \"ngss\": None,\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.startswith(\"1. Title\"):\n",
    "            current_section = \"title\"\n",
    "        elif line.startswith(\"2. Anchoring Phenomenon\"):\n",
    "            current_section = \"phenomenon\"\n",
    "        elif line.startswith(\"3. Driving Question\"):\n",
    "            current_section = \"driving_question\"\n",
    "        elif line.startswith(\"4. Summary\"):\n",
    "            current_section = \"summary\"\n",
    "        elif line.startswith(\"5. Lesson Sets\"):\n",
    "            current_section = \"lesson_sets\"\n",
    "        elif line.startswith(\"6. NGSS\"):\n",
    "            current_section = \"ngss\"\n",
    "        elif line.startswith(\"7. Suggested Teacher Reflection\"):\n",
    "            current_section = \"reflection_prompts\"\n",
    "        elif current_section:\n",
    "            if current_section in [\"lesson_sets\", \"reflection_prompts\"] and line.startswith(\"-\"):\n",
    "                sections[current_section].append(line[1:].strip())\n",
    "            elif current_section in [\"title\", \"phenomenon\", \"driving_question\", \"summary\", \"ngss\"] and line:\n",
    "                if not sections[current_section]:\n",
    "                    sections[current_section] = line\n",
    "                else:\n",
    "                    sections[current_section] += f\" {line}\"\n",
    "\n",
    "    return sections\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Prompt Template\n",
    "# -----------------------------\n",
    "prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    vectorstore_path,\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Chain\n",
    "# -----------------------------\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Simulated Teacher Input\n",
    "# -----------------------------\n",
    "topic = input(\"ðŸ§ª What is the topic for the unit? \")\n",
    "grade_level = input(\"ðŸŽ“ What is the grade level? \")\n",
    "student_context = input(\"ðŸ‘¥ Describe the student/community context: \")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Run Chain and Save Output\n",
    "# -----------------------------\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ¤– Generating unit outline... Please wait...\\n\")\n",
    "outline_response = rag_chain.invoke(data)\n",
    "print(\"\\nðŸ“ Generated Unit Plan:\\n\")\n",
    "print(outline_response)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save as Markdown and JSON\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Markdown\n",
    "md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(outline_response)\n",
    "\n",
    "# JSON\n",
    "sections = extract_sections(outline_response)\n",
    "sections.update(data)\n",
    "json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Saved unit plan to: {md_path.name}\")\n",
    "print(f\"âœ… Saved structured JSON to: {json_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Generating unit outline... Please wait...\n",
      "\n",
      "\n",
      "ðŸ“ Generated Unit Plan:\n",
      "\n",
      "1. **Title of the Unit:** \"Understanding Biological Sex, Gender, and Genetic Mutations: A Biological and Sociocultural Exploration\"\n",
      "\n",
      "2. **NGSS Anchoring Phenomenon:** The variation in physical characteristics and athletic abilities among individuals due to differences in biological sex and the impact of genetic mutations.\n",
      "\n",
      "3. **Driving Question:** How do biological sex and gender differ, and how can genetic mutations affect the development of sex characteristics and athletic performance?\n",
      "\n",
      "4. **Summary of the Storyline Arc:** The unit begins by exploring the concepts of biological sex and gender, emphasizing their differences and societal implications. Students then delve into the role of genes in determining biological sex and how mutations can affect the development of sex characteristics. They will examine real-world examples of genetic mutations and their impacts on individuals. The unit then transitions to the influence of biological sex on athletic performance, exploring physiological differences and their effects on various sports. The unit concludes with a discussion on the societal and ethical implications of these biological differences in sports and other areas of life.\n",
      "\n",
      "5. **Lesson Sets:**\n",
      "   - Lesson 1: Introduction to Biological Sex and Gender: This lesson introduces students to the concepts of biological sex and gender, highlighting their differences and societal constructs around them.\n",
      "   - Lesson 2: Role of Genes in Determining Biological Sex: Students explore the role of genes in determining biological sex, including the X and Y chromosomes.\n",
      "   - Lesson 3: Genetic Mutations and Sex Characteristics: This lesson delves into how genetic mutations can affect the development of sex characteristics, using real-world examples.\n",
      "   - Lesson 4: Biological Sex and Athletic Performance: Students investigate how biological sex can influence athletic performance, examining physiological differences.\n",
      "   - Lesson 5: Societal and Ethical Implications: The final lesson involves a discussion on the societal and ethical implications of biological sex differences in sports and other areas of life.\n",
      "\n",
      "6. **Key Investigations:**\n",
      "   - Investigation 1: Research on Genetic Mutations: Students research real-world examples of genetic mutations affecting sex characteristics.\n",
      "   - Investigation 2: Case Study Analysis: Students analyze case studies of athletes with different biological sex characteristics and their performances.\n",
      "   - Investigation 3: Debate on Ethical Implications: Students participate in a debate on the ethical implications of biological sex differences in sports.\n",
      "\n",
      "7. **NGSS Performance Expectations:** HS-LS1-4, HS-LS3-1, HS-LS3-2\n",
      "\n",
      "8. **Suggested Teacher Reflection Prompts:**\n",
      "   - How did students respond to the differentiation between biological sex and gender? \n",
      "   - Were students able to understand and explain the role of genes in determining biological sex?\n",
      "   - How effectively did students apply their understanding of genetic mutations to real-world examples?\n",
      "   - Did students demonstrate a clear understanding of the influence of biological sex on athletic performance?\n",
      "   - Were students able to engage in thoughtful discussion about the societal and ethical implications of biological sex differences?\n",
      "\n",
      "âœ… Saved unit plan to: unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_200709.md\n",
      "âœ… Saved structured JSON to: unit_outline_describe_how_biological_sex_and_gender_differ_from_each_othe_20250410_200709.json\n"
     ]
    }
   ],
   "source": [
    "# âœ… Updated Notebook Script: Teacher Input + Unit Outline Generator with JSON Output\n",
    "\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Functions\n",
    "# -----------------------------\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "def slugify(text, max_length=60):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", text.lower()).strip(\"_\")\n",
    "    return slug[:max_length]\n",
    "\n",
    "def extract_sections(markdown_text):\n",
    "    sections = {\n",
    "        \"title\": None,\n",
    "        \"phenomenon\": None,\n",
    "        \"driving_question\": None,\n",
    "        \"summary\": None,\n",
    "        \"lesson_sets\": [],\n",
    "        \"investigations\": [],\n",
    "        \"ngss\": None,\n",
    "        \"reflection_prompts\": []\n",
    "    }\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Match section headers more flexibly\n",
    "        if re.match(r\"^1\\.\\s*Title\", line, re.IGNORECASE):\n",
    "            current_section = \"title\"\n",
    "        elif re.match(r\"^2\\.\\s*Anchoring Phenomenon\", line, re.IGNORECASE):\n",
    "            current_section = \"phenomenon\"\n",
    "        elif re.match(r\"^3\\.\\s*Driving Question\", line, re.IGNORECASE):\n",
    "            current_section = \"driving_question\"\n",
    "        elif re.match(r\"^4\\.\\s*Summary\", line, re.IGNORECASE):\n",
    "            current_section = \"summary\"\n",
    "        elif re.match(r\"^5\\.\\s*Lesson Sets\", line, re.IGNORECASE):\n",
    "            current_section = \"lesson_sets\"\n",
    "        elif re.match(r\"^6\\.\\s*NGSS\", line, re.IGNORECASE):\n",
    "            current_section = \"ngss\"\n",
    "        elif re.match(r\"^7\\.\\s*Suggested Teacher Reflection\", line, re.IGNORECASE):\n",
    "            current_section = \"reflection_prompts\"\n",
    "        elif current_section:\n",
    "            if current_section in [\"lesson_sets\", \"reflection_prompts\", \"investigations\"]:\n",
    "                # Accept bullets or numbered list items\n",
    "                if re.match(r\"^[-*]\\s+\", line) or re.match(r\"^\\d+\\.\\s+\", line):\n",
    "                    clean_text = re.sub(r\"^[-*\\d.]+\\s+\", \"\", line)\n",
    "                    sections[current_section].append(clean_text.strip())\n",
    "                elif line:\n",
    "                    # Unprefixed continuation lines inside list items\n",
    "                    sections[current_section].append(line.strip())\n",
    "            elif current_section in [\"title\", \"phenomenon\", \"driving_question\", \"summary\", \"ngss\"] and line:\n",
    "                if not sections[current_section]:\n",
    "                    sections[current_section] = line\n",
    "                else:\n",
    "                    sections[current_section] += f\" {line}\"\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Prompt Template\n",
    "# -----------------------------\n",
    "prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load Vectorstore\n",
    "# -----------------------------\n",
    "vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    vectorstore_path,\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Chain\n",
    "# -----------------------------\n",
    "rag_chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "        \"topic\": lambda x: x[\"topic\"],\n",
    "        \"student_context\": lambda x: x[\"student_context\"],\n",
    "        \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "    })\n",
    "    | unit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Simulated Teacher Input\n",
    "# -----------------------------\n",
    "topic = input(\"ðŸ§ª What is the topic for the unit? \")\n",
    "grade_level = input(\"ðŸŽ“ What is the grade level? \")\n",
    "student_context = input(\"ðŸ‘¥ Describe the student/community context: \")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Run Chain and Save Output\n",
    "# -----------------------------\n",
    "data = {\n",
    "    \"topic\": topic,\n",
    "    \"grade_level\": grade_level,\n",
    "    \"student_context\": student_context\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ¤– Generating unit outline... Please wait...\\n\")\n",
    "outline_response = rag_chain.invoke(data)\n",
    "print(\"\\nðŸ“ Generated Unit Plan:\\n\")\n",
    "print(outline_response)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save as Markdown and JSON\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename_slug = slugify(f\"{topic}_{grade_level}\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Markdown\n",
    "md_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(outline_response)\n",
    "\n",
    "# JSON\n",
    "sections = extract_sections(outline_response)\n",
    "sections.update(data)\n",
    "json_path = output_dir / f\"unit_outline_{filename_slug}_{timestamp}.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sections, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Saved unit plan to: {md_path.name}\")\n",
    "print(f\"âœ… Saved structured JSON to: {json_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Lesson_expansion_generator\n",
    "\n",
    "1. Accepts a short lesson summary\n",
    "2. Pulls relevant examples using MMR search\n",
    "3. Expands it into a full lesson sequence (titles, objectives, strategies, etc.)\n",
    "4. Saves the output to a markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lesson Expansion Script ===\n",
      "\n",
      "=== Found the following Lesson Sets portion ===\n",
      "\n",
      "List of Lesson Sets:\n",
      "   - Lesson 1: Introduction to Biological Sex and Gender: Understanding the differences and societal implications.\n",
      "   - Lesson 2: The Role of Genes in Sex Determination: Exploring the genetic basis of biological sex.\n",
      "   - Lesson 3: Genetic Mutations and Variations: Examining how mutations can affect sex characteristics.\n",
      "   - Lesson 4: Biological Sex Characteristics and Athletic Performance: Investigating the potential impacts on sports and competition.\n",
      "   - Lesson 5: Reflecting on Gender Categories in Sports: Discussing the implications of biological sex characteristics for gender divisions in athletics.\n",
      "6. NGSS Performance Expectations: \n",
      "   - HS-LS1-4: Use a model to illustrate the role of cellular division (mitosis) and differentiation in producing and maintaining complex organisms.\n",
      "   - HS-LS3-1: Ask questions to clarify relationships about the role of DNA and chromosomes in coding the instructions for characteristic traits passed from parents to offspring.\n",
      "7. Suggested Teacher Reflection Prompts:\n",
      "   - How did students' understanding of the difference between biological sex and gender evolve throughout the unit?\n",
      "   - Did students demonstrate an understanding of how genetic mutations can affect sex characteristics?\n",
      "   - How did students respond to the discussion of biological sex characteristics' impact on athletic performance?\n",
      "   - How effectively did the unit promote inclusive participation and respect for diverse perspectives on gender?\n",
      "   - How can I improve the unit to better reflect students' cultural identities and community experiences?\n",
      "\n",
      "==============================================\n",
      "\n",
      "Loading Vector Store for expansions if needed ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Lesson expansions saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpansions_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 115\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# 10) Run the chain\u001b[39;00m\n\u001b[1;32m    110\u001b[0m data_for_expansion \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m: lesson_summary,\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_context\u001b[39m\u001b[38;5;124m\"\u001b[39m: student_context,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m\"\u001b[39m: grade_level\n\u001b[1;32m    114\u001b[0m }\n\u001b[0;32m--> 115\u001b[0m expansions_response \u001b[38;5;241m=\u001b[39m \u001b[43mexpansions_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_for_expansion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== EXPANDED LESSONS ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(expansions_response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:3144\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3132\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3133\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3134\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3143\u001b[0m         ]\n\u001b[0;32m-> 3144\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3145\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:3144\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3132\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3133\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3134\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3143\u001b[0m         ]\n\u001b[0;32m-> 3144\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3145\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:3961\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3959\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m   3960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3963\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3968\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3969\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3970\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3971\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1624\u001b[0m         Output,\n\u001b[0;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1633\u001b[0m     )\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/base.py:3835\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3833\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   3834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3835\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   3837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3838\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   3839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 102\u001b[0m, in \u001b[0;36mmain.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     94\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# 9) Construct a chain \u001b[39;00m\n\u001b[1;32m     97\u001b[0m expansions_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     98\u001b[0m     RunnableMap({\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_context\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_context\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m--> 102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msome query about expansions for \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlesson_summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     })\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;241m|\u001b[39m lesson_expansion_prompt\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# 10) Run the chain\u001b[39;00m\n\u001b[1;32m    110\u001b[0m data_for_expansion \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlesson_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m: lesson_summary,\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent_context\u001b[39m\u001b[38;5;124m\"\u001b[39m: student_context,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m\"\u001b[39m: grade_level\n\u001b[1;32m    114\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/retrievers.py:141\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mstr\u001b[39m, config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    140\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/retrievers.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    244\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    248\u001b[0m         result,\n\u001b[1;32m    249\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/retrievers.py:238\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 238\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_core/vectorstores.py:705\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    703\u001b[0m     docs \u001b[38;5;241m=\u001b[39m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities]\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 705\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_marginal_relevance_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:757\u001b[0m, in \u001b[0;36mFAISS.max_marginal_relevance_search\u001b[0;34m(self, query, k, fetch_k, lambda_mult, filter, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmax_marginal_relevance_search\u001b[39m(\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    733\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    739\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    740\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs selected using the maximal marginal relevance.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[38;5;124;03m    Maximal marginal relevance optimizes for similarity to query AND diversity\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;124;03m        List of Documents selected by maximal marginal relevance.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search_by_vector(\n\u001b[1;32m    759\u001b[0m         embedding,\n\u001b[1;32m    760\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/langchain_ai/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:156\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function\u001b[38;5;241m.\u001b[39membed_query(text)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not callable"
     ]
    }
   ],
   "source": [
    "# âœ… Updated Lesson Expansion Script \n",
    "# This code reads the \"unit_outline_*.md\" file from the Outline step, \n",
    "# parses out the \"List of Lesson Sets\", and then helps the teacher expand \n",
    "# one chosen lesson set.\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1) Load the lesson expansion prompt from file (or define inline)\n",
    "def load_prompt_from_file(prompt_path: Path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return PromptTemplate.from_template(text)\n",
    "\n",
    "def parse_lesson_sets_from_file(filename: Path) -> str:\n",
    "    \"\"\"\n",
    "    Tries to locate the 'List of Lesson Sets' portion from the unit outline file,\n",
    "    returning them as a single text string. \n",
    "    If not found, returns empty string.\n",
    "    \"\"\"\n",
    "    content = filename.read_text(encoding=\"utf-8\")\n",
    "    \n",
    "    # A naive approach: Look for heading that says \"List of Lesson Sets\"\n",
    "    # and read the subsequent lines up to the next heading or blank line \n",
    "    # This is just an example. You may refine or do a better parse.\n",
    "    pattern = r\"(List of Lesson Sets.*?)(?:\\n\\n|\\Z)\"\n",
    "    match = re.search(pattern, content, flags=re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    print(\"=== Lesson Expansion Script ===\")\n",
    "\n",
    "    # 2) We assume the teacher's previously generated unit outline is saved \n",
    "    # as something like \"unit_outline_7th_grade.md\".\n",
    "    # We'll ask the teacher for that filename here or use a default:\n",
    "    default_outline_file = \"outputs/unit_outline_7th_grade.md\"\n",
    "    outline_file_str = input(f\"Enter path to your unit outline markdown file [default: {default_outline_file}]: \").strip()\n",
    "    if not outline_file_str:\n",
    "        outline_file_str = default_outline_file\n",
    "    outline_file = Path(outline_file_str)\n",
    "    if not outline_file.exists():\n",
    "        print(f\"Error: Outline file '{outline_file}' does not exist.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 3) Parse out the \"List of Lesson Sets\"\n",
    "    lesson_sets_text = parse_lesson_sets_from_file(outline_file)\n",
    "    if not lesson_sets_text:\n",
    "        print(\"Warning: Could not find 'List of Lesson Sets' in the outline. The teacher may have to do this step manually.\")\n",
    "        print(\"Full file content:\\n\", outline_file.read_text(encoding='utf-8'))\n",
    "    \n",
    "    # Show teacher the lesson sets\n",
    "    print(\"\\n=== Found the following Lesson Sets portion ===\\n\")\n",
    "    print(lesson_sets_text)\n",
    "    print(\"\\n==============================================\\n\")\n",
    "\n",
    "    # 4) In your original Outline code, you might have stored the grade level & context. \n",
    "    # For demonstration, let's ask user if they want to manually specify them \n",
    "    # or parse them from the file. \n",
    "    # For now, let's just do input:\n",
    "    grade_level = input(\"Enter the same grade level you used in the Outline step (e.g., '7th grade'): \")\n",
    "    student_context = input(\"Enter the same student context from the outline step: \")\n",
    "\n",
    "    # 5) Now ask teacher which lesson set they want to expand\n",
    "    lesson_summary = input(\"Copy/paste the text for a single Lesson Set you want to expand:\\n> \")\n",
    "\n",
    "    # 6) Load the expansions prompt \n",
    "    expansions_prompt_path = Path(\"prompts\") / \"lesson_set_expansion_prompt.txt\"\n",
    "    lesson_expansion_prompt = load_prompt_from_file(expansions_prompt_path)\n",
    "\n",
    "    # 7) Setup RAG if you want or if you have to retrieve from vectorstore \n",
    "    # for additional references. \n",
    "    # For demonstration, we skip or do a minimal approach:\n",
    "    print(\"Loading Vector Store for expansions if needed ...\")\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings_model = ... # e.g. OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        vectorstore_path, \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    # 8) LLM\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    # 9) Construct a chain \n",
    "    expansions_chain = (\n",
    "        RunnableMap({\n",
    "            \"lesson_summary\": lambda x: x[\"lesson_summary\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x[\"grade_level\"],\n",
    "            \"context\": lambda x: retriever.invoke(\"some query about expansions for \" + x[\"lesson_summary\"])\n",
    "        })\n",
    "        | lesson_expansion_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 10) Run the chain\n",
    "    data_for_expansion = {\n",
    "        \"lesson_summary\": lesson_summary,\n",
    "        \"student_context\": student_context,\n",
    "        \"grade_level\": grade_level\n",
    "    }\n",
    "    expansions_response = expansions_chain.invoke(data_for_expansion)\n",
    "    print(\"\\n=== EXPANDED LESSONS ===\\n\")\n",
    "    print(expansions_response)\n",
    "\n",
    "    # 11) Optionally save expansions\n",
    "    out_dir = Path(\"outputs\")\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    expansions_file = out_dir / f\"lesson_expansion_{grade_level.replace(' ','_')}.md\"\n",
    "    expansions_file.write_text(expansions_response, encoding='utf-8')\n",
    "    print(f\"\\nâœ… Lesson expansions saved to: {expansions_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Unit bundler\n",
    "1. Select a unit outline\n",
    "2. Choose one or more expanded lessons\n",
    "3. Bundle them into a clean, organized .md file\n",
    "4. Save it with a timestamp for version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Available Unit Outlines:\n",
      "[0] unit_outline_climate_justice.md\n",
      "[1] unit_outline_9th_grade_biology.md\n",
      "[2] unit_outline_ecosystems_and_human_impact.md\n",
      "\n",
      "ðŸ“š Available Lesson Expansions:\n",
      "[0] lesson_expansion_climate_justice.md\n",
      "[1] lesson_expansion_unit_outline_9th_grade_bi.md\n",
      "\n",
      "âœ… Final bundled unit saved to: outputs/full_unit_plan_20250410-1646.md\n"
     ]
    }
   ],
   "source": [
    "# âœ… Notebook Script: Bundle Unit Outline and Lesson Expansions into One File\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Config Paths\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_files = list(outputs_dir.glob(\"unit_outline_*.md\"))\n",
    "lesson_files = list(outputs_dir.glob(\"lesson_expansion_*.md\"))\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Choose Unit Outline\n",
    "# -----------------------------\n",
    "print(\"ðŸ“¦ Available Unit Outlines:\")\n",
    "for i, f in enumerate(unit_files):\n",
    "    print(f\"[{i}] {f.name}\")\n",
    "unit_index = int(input(\"\\nEnter number for unit to bundle: \"))\n",
    "unit_path = unit_files[unit_index]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Select Lessons to Include\n",
    "# -----------------------------\n",
    "print(\"\\nðŸ“š Available Lesson Expansions:\")\n",
    "for i, f in enumerate(lesson_files):\n",
    "    print(f\"[{i}] {f.name}\")\n",
    "selected_lesson_indexes = input(\"\\nEnter numbers of lessons to include (comma separated): \")\n",
    "selected_indexes = [int(i.strip()) for i in selected_lesson_indexes.split(\",\") if i.strip().isdigit()]\n",
    "selected_lessons = [lesson_files[i] for i in selected_indexes]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Bundle Content\n",
    "# -----------------------------\n",
    "def read_text(path):\n",
    "    return path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "unit_text = read_text(unit_path)\n",
    "lesson_texts = [read_text(p) for p in selected_lessons]\n",
    "\n",
    "final_text = f\"\"\"\n",
    "# ðŸ§ª Bundled Science Unit Plan\n",
    "\n",
    "## ðŸ“ Unit Outline\n",
    "\n",
    "{unit_text}\n",
    "\n",
    "## ðŸ“š Expanded Lessons\n",
    "\n",
    "\"\"\"\n",
    "for i, text in enumerate(lesson_texts):\n",
    "    final_text += f\"\\n---\\n\\n### Lesson {i+1}\\n{text}\\n\"\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Save Bundled File\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "filename = outputs_dir / f\"full_unit_plan_{timestamp}.md\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_text)\n",
    "\n",
    "print(f\"\\nâœ… Final bundled unit saved to: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04 Teacher Reflection notebook is now set up!\n",
    "\n",
    "It will:\n",
    "\n",
    "Automatically load the most recent bundled unit\n",
    "\n",
    "Present a series of thoughtful, CRP-aligned reflection questions\n",
    "\n",
    "Capture teacher responses interactively\n",
    "\n",
    "Save the reflection as a .md file for iterative documentation\n",
    "\n",
    "This closes the loop for a powerful first cycle of your RAG tool: Inspire â†’ Design â†’ Expand â†’ Bundle â†’ Reflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded unit file: full_unit_plan_20250402-1657.md\n",
      "\n",
      "ðŸªž Teacher Reflection Questions:\n",
      "\n",
      "1. How might this unit connect to your students' lived experiences?\n",
      "\n",
      "---\n",
      "\n",
      "2. What voices or perspectives might be missing in this unit?\n",
      "\n",
      "---\n",
      "\n",
      "3. Are there opportunities to center local knowledge, language, or community assets?\n",
      "\n",
      "---\n",
      "\n",
      "4. How does this unit reflect your goals and values as a science educator?\n",
      "\n",
      "---\n",
      "\n",
      "5. What elements might support or challenge your existing beliefs about who science is for?\n",
      "\n",
      "---\n",
      "\n",
      "6. How might this unit invite multiple ways of knowing, doing, or expressing ideas in science?\n",
      "\n",
      "---\n",
      "\n",
      "âœ… Reflection saved to: outputs\\unit_reflection_20250402-1702.md\n"
     ]
    }
   ],
   "source": [
    "# âœ… Notebook Script: Teacher Reflection + Ideological Prompts\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Latest Bundled Unit\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_files = sorted(outputs_dir.glob(\"full_unit_plan_*.md\"), reverse=True)\n",
    "\n",
    "if not unit_files:\n",
    "    raise FileNotFoundError(\"âš ï¸ No bundled unit files found. Run 03_unit_bundler first.\")\n",
    "\n",
    "latest_unit_path = unit_files[0]\n",
    "print(f\"ðŸ“„ Loaded unit file: {latest_unit_path.name}\\n\")\n",
    "\n",
    "unit_text = latest_unit_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Reflection Prompts\n",
    "# -----------------------------\n",
    "reflection_prompts = [\n",
    "    \"1. How might this unit connect to your students' lived experiences?\",\n",
    "    \"2. What voices or perspectives might be missing in this unit?\",\n",
    "    \"3. Are there opportunities to center local knowledge, language, or community assets?\",\n",
    "    \"4. How does this unit reflect your goals and values as a science educator?\",\n",
    "    \"5. What elements might support or challenge your existing beliefs about who science is for?\",\n",
    "    \"6. How might this unit invite multiple ways of knowing, doing, or expressing ideas in science?\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Interactive Reflection Form\n",
    "# -----------------------------\n",
    "responses = []\n",
    "print(\"ðŸªž Teacher Reflection Questions:\\n\")\n",
    "for prompt in reflection_prompts:\n",
    "    print(prompt)\n",
    "    answer = input(\"âœï¸  Your thoughts: \")\n",
    "    responses.append((prompt, answer))\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Save Annotated Reflection\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "filename = outputs_dir / f\"unit_reflection_{timestamp}.md\"\n",
    "\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# ðŸ§  Teacher Reflection on Unit Design\\n\\n\")\n",
    "    f.write(f\"## Based on Unit: {latest_unit_path.name}\\n\\n\")\n",
    "    f.write(\"\\n---\\n\\n\")\n",
    "    for prompt, answer in responses:\n",
    "        f.write(f\"**{prompt}**\\n\\n{answer}\\n\\n\")\n",
    "\n",
    "print(f\"âœ… Reflection saved to: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflection Analytics / Logging\n",
    "Weâ€™ll track:\n",
    "\n",
    "Frequency of reflective responses\n",
    "\n",
    "Sentiment or tone (e.g. using a simple NLP classifier)\n",
    "\n",
    "Shifts in ideology or themes over time across units\n",
    "\n",
    "Load all saved reflections\n",
    "\n",
    "Analyze each response for sentiment (via TextBlob)\n",
    "\n",
    "Visualize trends across prompts\n",
    "\n",
    "Save the full dataset as a .csv for deeper qualitative or longitudinal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Notebook Script: Analyze Teacher Reflections for Growth & Themes\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Reflections\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "reflection_files = sorted(outputs_dir.glob(\"unit_reflection_*.md\"))\n",
    "\n",
    "if not reflection_files:\n",
    "    raise FileNotFoundError(\"âš ï¸ No reflection files found. Run 04_teacher_reflection first.\")\n",
    "\n",
    "reflection_data = []\n",
    "for file in reflection_files:\n",
    "    text = file.read_text(encoding=\"utf-8\")\n",
    "    lines = text.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"**\") and i + 1 < len(lines):\n",
    "            question = line.strip(\"* \")\n",
    "            response = lines[i + 1].strip()\n",
    "            reflection_data.append({\n",
    "                \"file\": file.name,\n",
    "                \"question\": question,\n",
    "                \"response\": response\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(reflection_data)\n",
    "print(f\"âœ… Loaded {len(df)} reflection responses from {len(reflection_files)} files.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Sentiment Analysis\n",
    "# -----------------------------\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df[\"sentiment\"] = df[\"response\"].apply(get_sentiment)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Display Summary Stats\n",
    "# -----------------------------\n",
    "print(\"\\nðŸ“Š Sentiment Summary by Question:\")\n",
    "print(df.groupby(\"question\")[\"sentiment\"].mean().round(2))\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Visualization\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot(column=\"sentiment\", by=\"question\", rot=45)\n",
    "plt.title(\"Sentiment by Reflection Question\")\n",
    "plt.suptitle(\"\")\n",
    "plt.ylabel(\"Sentiment Polarity (-1 to 1)\")\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Export as CSV (optional)\n",
    "# -----------------------------\n",
    "df.to_csv(outputs_dir / \"reflection_analysis.csv\", index=False)\n",
    "print(\"\\nðŸ“ Saved raw reflection data to: reflection_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export PDF\n",
    "06_export_pdf_doc will:\n",
    "\n",
    "Grab your most recent bundled unit and reflection\n",
    "\n",
    "Export them to both PDF (via fpdf) and Word/Google Doc format (via python-docx)\n",
    "\n",
    "Keep everything organized in your outputs/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Notebook Script: Export Bundled Unit and Reflection to PDF or Google Doc\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from fpdf import FPDF\n",
    "import markdown2\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Most Recent Files\n",
    "# -----------------------------\n",
    "outputs_dir = Path(\"outputs\")\n",
    "unit_file = sorted(outputs_dir.glob(\"full_unit_plan_*.md\"), reverse=True)[0]\n",
    "reflection_file = sorted(outputs_dir.glob(\"unit_reflection_*.md\"), reverse=True)[0]\n",
    "\n",
    "unit_text = unit_file.read_text(encoding=\"utf-8\")\n",
    "reflection_text = reflection_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Convert Markdown to HTML (for reference)\n",
    "# -----------------------------\n",
    "html_unit = markdown2.markdown(unit_text)\n",
    "html_reflection = markdown2.markdown(reflection_text)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Convert to PDF using FPDF\n",
    "# -----------------------------\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font(\"Arial\", \"B\", 12)\n",
    "        self.cell(0, 10, \"Bundled Science Unit + Reflection\", ln=True, align=\"C\")\n",
    "        self.ln(5)\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font(\"Arial\", \"B\", 11)\n",
    "        self.cell(0, 10, title, ln=True)\n",
    "        self.ln(4)\n",
    "\n",
    "    def chapter_body(self, text):\n",
    "        self.set_font(\"Arial\", size=10)\n",
    "        self.multi_cell(0, 6, text)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "pdf.chapter_title(\"Unit Plan\")\n",
    "pdf.chapter_body(unit_text)\n",
    "pdf.chapter_title(\"Teacher Reflection\")\n",
    "pdf.chapter_body(reflection_text)\n",
    "\n",
    "pdf_file = outputs_dir / f\"unit_bundle_export_{datetime.now().strftime('%Y%m%d-%H%M')}.pdf\"\n",
    "pdf.output(str(pdf_file))\n",
    "\n",
    "print(f\"âœ… PDF exported to: {pdf_file}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Google Docs (Optional, Outline Only)\n",
    "# -----------------------------\n",
    "try:\n",
    "    from docx import Document\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"Bundled Science Unit + Teacher Reflection\", 0)\n",
    "\n",
    "    doc.add_heading(\"Unit Plan\", level=1)\n",
    "    doc.add_paragraph(unit_text)\n",
    "\n",
    "    doc.add_heading(\"Teacher Reflection\", level=1)\n",
    "    doc.add_paragraph(reflection_text)\n",
    "\n",
    "    docx_file = outputs_dir / f\"unit_bundle_export_{datetime.now().strftime('%Y%m%d-%H%M')}.docx\"\n",
    "    doc.save(docx_file)\n",
    "    print(f\"âœ… Word Doc exported to: {docx_file}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ To enable Word/Google Docs export, run: pip install python-docx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07 Teacher interface App\n",
    "\n",
    " unified Streamlit app is now ready in 07_teacher_interface_app.py!\n",
    "\n",
    "This prototype lets teachers:\n",
    "\n",
    "Input a topic, grade, and student context\n",
    "\n",
    "Generate a culturally responsive unit outline with RAG + GPT-4\n",
    "\n",
    "View the result in-browser and save it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 11:03:19.225 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.227 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.340 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\mrhal\\anaconda3\\envs\\ragtest1-env\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-03 11:03:19.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.345 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.346 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-03 11:03:19.347 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.352 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-03 11:03:19.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# âœ… Updated Unified Teacher-Facing App â€“ Streamlit Prototype\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Assume a utility function for loading prompts\n",
    "def load_prompt_from_file(prompt_path):\n",
    "    with open(prompt_path, encoding=\"utf-8\") as f:\n",
    "        return PromptTemplate.from_template(f.read())\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"ðŸ§  Curriculum CoDesigner â€“ AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait â³\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"ðŸ“˜ Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"âœ… Saved to: {filename.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Upload\n",
    "Teachers can now:\n",
    "\n",
    "Upload custom PDFs (e.g., low-quality or local lessons)\n",
    "\n",
    "Have those documents instantly split, embedded, and used for RAG generation\n",
    "\n",
    "Fall back to your core inspiration corpus if no files are uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Unified Teacher-Facing App â€“ Streamlit Prototype with File Uploads\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"ðŸ§  Curriculum CoDesigner â€“ AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"ðŸ“ Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"âœ… Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait â³\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"ðŸ“˜ Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"âœ… Saved to: {filename.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add CRP reflection prompts\n",
    "\n",
    "Streamlit app now includes built-in CRP reflection prompts!\n",
    "\n",
    "After a unit outline is generated, teachers are guided to reflect on:\n",
    "\n",
    "Cultural relevance\n",
    "\n",
    "Epistemological diversity\n",
    "\n",
    "Local significance\n",
    "\n",
    "Equity-related uncertainties\n",
    "\n",
    "Reflections are saved per unit alongside the design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Unified Teacher-Facing App â€“ Streamlit Prototype with File Uploads + Reflection Prompts\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"ðŸ§  Curriculum CoDesigner â€“ AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"ðŸ“ Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"âœ… Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait â³\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"ðŸ“˜ Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"âœ… Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"ðŸªž Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"ðŸ’¾ Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"âœ… Reflection saved to: {reflection_file.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson expansion is now built into the Streamlit app!\n",
    "\n",
    "After generating the unit outline, teachers can:\n",
    "\n",
    "Select how many lessons they want (2â€“10)\n",
    "\n",
    "Automatically generate detailed lesson-level plans\n",
    "\n",
    "Save and view those lessons in-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Unified Teacher-Facing App â€“ Streamlit Prototype with File Uploads + Reflection Prompts + Lesson Expansion\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"ðŸ§  Curriculum CoDesigner â€“ AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"ðŸ“ Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"âœ… Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    lesson_path = Path(\"prompts\") / \"lesson_expander_prompt.txt\"\n",
    "    lesson_prompt = load_prompt_from_file(lesson_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait â³\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"ðŸ“˜ Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"âœ… Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Lesson Expansion Prompt\n",
    "    # -----------------------------\n",
    "    st.subheader(\"ðŸ“š Expand Unit into Detailed Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"How many lessons would you like to expand into?\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: unit_output,\n",
    "                \"topic\": lambda x: x[\"topic\"],\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        lesson_data = {\"topic\": topic, \"num_lessons\": num_lessons}\n",
    "        expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(expanded_lessons)\n",
    "\n",
    "        expanded_file = output_dir / f\"lesson_expansion_{topic.replace(' ', '_')}.md\"\n",
    "        with open(expanded_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(expanded_lessons)\n",
    "        st.success(f\"âœ… Expanded lessons saved to: {expanded_file.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"ðŸªž Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"ðŸ’¾ Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"âœ… Reflection saved to: {reflection_file.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF export added! After reflection is submitted, your app now:\n",
    "\n",
    "Combines unit outline, lessons, and reflection into one PDF\n",
    "\n",
    "Saves and displays a download button for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Unified Teacher-Facing App â€“ Streamlit Prototype with File Uploads + Reflection Prompts + Lesson Expansion + PDF Export\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "# -----------------------------\n",
    "# 1. App Config\n",
    "# -----------------------------\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"ðŸ§  Curriculum CoDesigner â€“ AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. File Upload Section\n",
    "# -----------------------------\n",
    "with st.expander(\"ðŸ“ Upload Custom Documents (optional)\"):\n",
    "    uploaded_files = st.file_uploader(\"Upload PDFs for inspiration (e.g., existing lessons)\", type=\"pdf\", accept_multiple_files=True)\n",
    "    temp_dir = Path(\"data/uploads\")\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    custom_docs = []\n",
    "    if uploaded_files:\n",
    "        for file in uploaded_files:\n",
    "            file_path = temp_dir / file.name\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "            loader = PyMuPDFLoader(str(file_path))\n",
    "            docs = loader.load()\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            custom_docs.extend(split_docs)\n",
    "        st.success(f\"âœ… Loaded and split {len(custom_docs)} chunks from uploaded PDFs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Input from Teacher\n",
    "# -----------------------------\n",
    "with st.form(\"unit_form\"):\n",
    "    topic = st.text_input(\"Unit Topic (e.g., Climate Change)\", \"ecosystems and human impact\")\n",
    "    grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "    context = st.text_area(\"Describe your students or community context\", \"Black and Latinx students in Los Angeles\")\n",
    "    submitted = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Setup RAG Components\n",
    "# -----------------------------\n",
    "if submitted:\n",
    "    st.info(\"Loading models and retriever...\")\n",
    "\n",
    "    prompt_path = Path(\"prompts\") / \"unit_outline_prompt.txt\"\n",
    "    unit_prompt = load_prompt_from_file(prompt_path)\n",
    "\n",
    "    lesson_path = Path(\"prompts\") / \"lesson_expander_prompt.txt\"\n",
    "    lesson_prompt = load_prompt_from_file(lesson_path)\n",
    "\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if custom_docs:\n",
    "        custom_vectorstore = FAISS.from_documents(custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"topic\": topic,\n",
    "        \"student_context\": context,\n",
    "        \"grade_level\": grade\n",
    "    }\n",
    "\n",
    "    st.success(\"Generating unit outline... Please wait â³\")\n",
    "    unit_output = rag_chain.invoke(data)\n",
    "\n",
    "    # Display\n",
    "    st.subheader(\"ðŸ“˜ Draft Unit Outline\")\n",
    "    st.markdown(unit_output)\n",
    "\n",
    "    # Save\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    filename = output_dir / f\"unit_outline_{topic.replace(' ', '_')}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(unit_output)\n",
    "    st.success(f\"âœ… Saved to: {filename.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Lesson Expansion Prompt\n",
    "    # -----------------------------\n",
    "    st.subheader(\"ðŸ“š Expand Unit into Detailed Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"How many lessons would you like to expand into?\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: unit_output,\n",
    "                \"topic\": lambda x: x[\"topic\"],\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        lesson_data = {\"topic\": topic, \"num_lessons\": num_lessons}\n",
    "        expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(expanded_lessons)\n",
    "\n",
    "        expanded_file = output_dir / f\"lesson_expansion_{topic.replace(' ', '_')}.md\"\n",
    "        with open(expanded_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(expanded_lessons)\n",
    "        st.success(f\"âœ… Expanded lessons saved to: {expanded_file.name}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. CRP Reflection Prompts\n",
    "    # -----------------------------\n",
    "    st.subheader(\"ðŸªž Teacher Reflection\")\n",
    "    st.markdown(\"Please respond to the following questions to reflect on your design:\")\n",
    "\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities or experiences of your students?\")\n",
    "        q2 = st.text_area(\"2. Where could students bring in multiple ways of knowing (cultural, linguistic, experiential)?\")\n",
    "        q3 = st.text_area(\"3. What might make this more locally relevant or socially meaningful?\")\n",
    "        q4 = st.text_area(\"4. What questions do you still have about how to support equity in this unit?\")\n",
    "        save_reflection = st.form_submit_button(\"ðŸ’¾ Save Reflection\")\n",
    "\n",
    "    if save_reflection:\n",
    "        reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        reflection_file = output_dir / f\"unit_reflection_{topic.replace(' ', '_')}.md\"\n",
    "        with open(reflection_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(reflection_text)\n",
    "        st.success(f\"âœ… Reflection saved to: {reflection_file.name}\")\n",
    "\n",
    "        # Export to PDF\n",
    "        pdf = FPDF()\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "        for line in (unit_output + \"\\n\" + expanded_lessons + \"\\n\" + reflection_text).split(\"\\n\"):\n",
    "            pdf.multi_cell(0, 10, line)\n",
    "        pdf_filename = output_dir / f\"unit_bundle_{topic.replace(' ', '_')}.pdf\"\n",
    "        pdf.output(str(pdf_filename))\n",
    "        with open(pdf_filename, \"rb\") as f:\n",
    "            st.download_button(\"ðŸ“„ Download Full Unit PDF\", data=f, file_name=pdf_filename.name)\n",
    "        st.success(\"ðŸ“ Full unit PDF exported!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review and export\n",
    " Review & Export tab is now live! You can:\n",
    "\n",
    "See the full unit + lessons + reflection all together\n",
    "\n",
    "Download it as a bundled PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Unified Teacher-Facing App â€“ Streamlit Prototype with Review + Export Page\n",
    "\n",
    "import streamlit as st\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"ðŸ§  Curriculum CoDesigner â€“ AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# App State & Session Storage\n",
    "# -----------------------------\n",
    "if \"unit_output\" not in st.session_state:\n",
    "    st.session_state.unit_output = \"\"\n",
    "if \"expanded_lessons\" not in st.session_state:\n",
    "    st.session_state.expanded_lessons = \"\"\n",
    "if \"reflection_text\" not in st.session_state:\n",
    "    st.session_state.reflection_text = \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step-by-step workflow\n",
    "# -----------------------------\n",
    "st.sidebar.title(\"Navigation\")\n",
    "page = st.sidebar.radio(\"Go to:\", [\"1ï¸âƒ£ Upload & Inputs\", \"2ï¸âƒ£ Unit Builder\", \"3ï¸âƒ£ Lesson Expansion\", \"4ï¸âƒ£ Reflection\", \"5ï¸âƒ£ Review & Export\"])\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 1: Upload & Inputs\n",
    "# -----------------------------\n",
    "if page == \"1ï¸âƒ£ Upload & Inputs\":\n",
    "    with st.expander(\"ðŸ“ Upload Custom Documents (optional)\"):\n",
    "        uploaded_files = st.file_uploader(\"Upload PDFs for inspiration\", type=\"pdf\", accept_multiple_files=True)\n",
    "        temp_dir = Path(\"data/uploads\")\n",
    "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        st.session_state.custom_docs = []\n",
    "        if uploaded_files:\n",
    "            for file in uploaded_files:\n",
    "                file_path = temp_dir / file.name\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file.read())\n",
    "                loader = PyMuPDFLoader(str(file_path))\n",
    "                docs = loader.load()\n",
    "                splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "                split_docs = splitter.split_documents(docs)\n",
    "                st.session_state.custom_docs.extend(split_docs)\n",
    "            st.success(f\"âœ… Loaded {len(st.session_state.custom_docs)} chunks from PDFs.\")\n",
    "\n",
    "    with st.form(\"unit_form\"):\n",
    "        st.session_state.topic = st.text_input(\"Unit Topic\", \"ecosystems and human impact\")\n",
    "        st.session_state.grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "        st.session_state.context = st.text_area(\"Describe your student/community context\", \"Black and Latinx students in LA\")\n",
    "        st.session_state.submit_inputs = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 2: Unit Builder\n",
    "# -----------------------------\n",
    "if page == \"2ï¸âƒ£ Unit Builder\" and st.session_state.get(\"submit_inputs\"):\n",
    "    st.info(\"ðŸ”„ Generating outline using your topic and context...\")\n",
    "    unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if st.session_state.get(\"custom_docs\"):\n",
    "        custom_vectorstore = FAISS.from_documents(st.session_state.custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    data = {\n",
    "        \"topic\": st.session_state.topic,\n",
    "        \"student_context\": st.session_state.context,\n",
    "        \"grade_level\": st.session_state.grade\n",
    "    }\n",
    "    st.session_state.unit_output = rag_chain.invoke(data)\n",
    "    st.subheader(\"ðŸ“˜ Generated Unit Outline\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 3: Lesson Expansion\n",
    "# -----------------------------\n",
    "if page == \"3ï¸âƒ£ Lesson Expansion\" and st.session_state.unit_output:\n",
    "    st.subheader(\"ðŸ“š Expand Into Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"Number of lessons\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_prompt = load_prompt_from_file(Path(\"prompts\") / \"lesson_expander_prompt.txt\")\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: st.session_state.unit_output,\n",
    "                \"topic\": lambda x: st.session_state.topic,\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        lesson_data = {\"num_lessons\": num_lessons}\n",
    "        st.session_state.expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(st.session_state.expanded_lessons)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 4: Reflection\n",
    "# -----------------------------\n",
    "if page == \"4ï¸âƒ£ Reflection\" and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"ðŸªž Teacher Reflection\")\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities of your students?\")\n",
    "        q2 = st.text_area(\"2. Where can students bring in multiple ways of knowing?\")\n",
    "        q3 = st.text_area(\"3. What could make this more locally meaningful?\")\n",
    "        q4 = st.text_area(\"4. What are open questions you still have about equity in this unit?\")\n",
    "        submit_reflection = st.form_submit_button(\"ðŸ’¾ Save Reflection\")\n",
    "\n",
    "    if submit_reflection:\n",
    "        st.session_state.reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {st.session_state.topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        st.success(\"âœ… Reflection saved. Proceed to Review & Export tab.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 5: Review and Export\n",
    "# -----------------------------\n",
    "if page == \"5ï¸âƒ£ Review & Export\" and st.session_state.unit_output and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"ðŸ“¦ Review Final Bundle\")\n",
    "    st.markdown(\"### ðŸ§¾ Unit Plan\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "    st.markdown(\"### ðŸ§© Lessons\")\n",
    "    st.markdown(st.session_state.expanded_lessons)\n",
    "    st.markdown(\"### ðŸªž Reflection\")\n",
    "    st.markdown(st.session_state.reflection_text)\n",
    "\n",
    "    full_text = f\"\"\"\n",
    "{st.session_state.unit_output}\n",
    "\n",
    "{st.session_state.expanded_lessons}\n",
    "\n",
    "{st.session_state.reflection_text}\n",
    "\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    for line in full_text.split(\"\\n\"):\n",
    "        pdf.multi_cell(0, 10, line)\n",
    "    filename = output_dir / f\"unit_bundle_{st.session_state.topic.replace(' ', '_')}.pdf\"\n",
    "    pdf.output(str(filename))\n",
    "    with open(filename, \"rb\") as f:\n",
    "        st.download_button(\"ðŸ“„ Download Full Unit PDF\", data=f, file_name=filename.name)\n",
    "    st.success(\"âœ… Your full curriculum design has been bundled!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrated CRP pedagogical enhancements into your app:\n",
    "\n",
    "A concise explanation and resource link added in the sidebar.\n",
    "\n",
    "Helpful CRP tips added to guide reflections and review steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Unified Teacher-Facing App â€“ Streamlit Prototype with Review + Export Page\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# CRP Pedagogical Resources\n",
    "CRP_RESOURCES = \"\"\"\n",
    "### ðŸŒŸ What is Culturally Responsive Pedagogy (CRP)?\n",
    "Culturally Responsive Pedagogy emphasizes using students' cultural backgrounds, experiences, and perspectives as valuable resources for teaching and learning.\n",
    "\n",
    "- **Validate Students' Identities:** Affirm and celebrate diverse cultural identities.\n",
    "- **Multiple Ways of Knowing:** Encourage students to bring their cultural, linguistic, and experiential knowledge into the classroom.\n",
    "- **Social Relevance:** Connect learning to issues that are significant within students' communities.\n",
    "\n",
    "[Learn more about CRP here](https://www.tolerance.org/professional-development/culturally-responsive-teaching)\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from utils.load_prompts import load_prompt_from_file\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from fpdf import FPDF\n",
    "\n",
    "st.set_page_config(page_title=\"Curriculum CoDesigner\", layout=\"centered\")\n",
    "st.title(\"ðŸ§  Curriculum CoDesigner â€“ AI Thinking Partner\")\n",
    "\n",
    "# -----------------------------\n",
    "# App State & Session Storage\n",
    "# -----------------------------\n",
    "if \"unit_output\" not in st.session_state:\n",
    "    st.session_state.unit_output = \"\"\n",
    "if \"expanded_lessons\" not in st.session_state:\n",
    "    st.session_state.expanded_lessons = \"\"\n",
    "if \"reflection_text\" not in st.session_state:\n",
    "    st.session_state.reflection_text = \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step-by-step workflow\n",
    "# -----------------------------\n",
    "st.sidebar.title(\"Navigation\")\n",
    "st.sidebar.markdown(CRP_RESOURCES)\n",
    "page = st.sidebar.radio(\"Go to:\", [\"1ï¸âƒ£ Upload & Inputs\", \"2ï¸âƒ£ Unit Builder\", \"3ï¸âƒ£ Lesson Expansion\", \"4ï¸âƒ£ Reflection\", \"5ï¸âƒ£ Review & Export\"])\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 1: Upload & Inputs\n",
    "# -----------------------------\n",
    "if page == \"1ï¸âƒ£ Upload & Inputs\":\n",
    "    with st.expander(\"ðŸ“ Upload Custom Documents (optional)\"):\n",
    "        uploaded_files = st.file_uploader(\"Upload PDFs for inspiration\", type=\"pdf\", accept_multiple_files=True)\n",
    "        temp_dir = Path(\"data/uploads\")\n",
    "        temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        st.session_state.custom_docs = []\n",
    "        if uploaded_files:\n",
    "            for file in uploaded_files:\n",
    "                file_path = temp_dir / file.name\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(file.read())\n",
    "                loader = PyMuPDFLoader(str(file_path))\n",
    "                docs = loader.load()\n",
    "                splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "                split_docs = splitter.split_documents(docs)\n",
    "                st.session_state.custom_docs.extend(split_docs)\n",
    "            st.success(f\"âœ… Loaded {len(st.session_state.custom_docs)} chunks from PDFs.\")\n",
    "\n",
    "    with st.form(\"unit_form\"):\n",
    "        st.session_state.topic = st.text_input(\"Unit Topic\", \"ecosystems and human impact\")\n",
    "        st.session_state.grade = st.selectbox(\"Grade Level\", [\"6th\", \"7th\", \"8th\", \"middle school\"])\n",
    "        st.session_state.context = st.text_area(\"Describe your student/community context\", \"Black and Latinx students in LA\")\n",
    "        st.session_state.submit_inputs = st.form_submit_button(\"Generate Unit Outline\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 2: Unit Builder\n",
    "# -----------------------------\n",
    "if page == \"2ï¸âƒ£ Unit Builder\" and st.session_state.get(\"submit_inputs\"):\n",
    "    st.info(\"ðŸ”„ Generating outline using your topic and context...\")\n",
    "    unit_prompt = load_prompt_from_file(Path(\"prompts\") / \"unit_outline_prompt.txt\")\n",
    "    vectorstore_path = \"data/embeddings/faiss_index\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = FAISS.load_local(vectorstore_path, embeddings)\n",
    "\n",
    "    if st.session_state.get(\"custom_docs\"):\n",
    "        custom_vectorstore = FAISS.from_documents(st.session_state.custom_docs, embeddings)\n",
    "        retriever = custom_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "    else:\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "    rag_chain = (\n",
    "        RunnableMap({\n",
    "            \"context\": lambda x: retriever.invoke(x[\"topic\"]),\n",
    "            \"topic\": lambda x: x[\"topic\"],\n",
    "            \"student_context\": lambda x: x[\"student_context\"],\n",
    "            \"grade_level\": lambda x: x.get(\"grade_level\", \"middle school\")\n",
    "        })\n",
    "        | unit_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    data = {\n",
    "        \"topic\": st.session_state.topic,\n",
    "        \"student_context\": st.session_state.context,\n",
    "        \"grade_level\": st.session_state.grade\n",
    "    }\n",
    "    st.session_state.unit_output = rag_chain.invoke(data)\n",
    "    st.subheader(\"ðŸ“˜ Generated Unit Outline\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 3: Lesson Expansion\n",
    "# -----------------------------\n",
    "if page == \"3ï¸âƒ£ Lesson Expansion\" and st.session_state.unit_output:\n",
    "    st.subheader(\"ðŸ“š Expand Into Lessons\")\n",
    "    with st.form(\"lesson_form\"):\n",
    "        num_lessons = st.slider(\"Number of lessons\", 2, 10, 4)\n",
    "        expand_button = st.form_submit_button(\"Expand Lessons\")\n",
    "\n",
    "    if expand_button:\n",
    "        lesson_prompt = load_prompt_from_file(Path(\"prompts\") / \"lesson_expander_prompt.txt\")\n",
    "        llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "        lesson_chain = (\n",
    "            RunnableMap({\n",
    "                \"unit_outline\": lambda x: st.session_state.unit_output,\n",
    "                \"topic\": lambda x: st.session_state.topic,\n",
    "                \"num_lessons\": lambda x: x[\"num_lessons\"]\n",
    "            })\n",
    "            | lesson_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        lesson_data = {\"num_lessons\": num_lessons}\n",
    "        st.session_state.expanded_lessons = lesson_chain.invoke(lesson_data)\n",
    "        st.markdown(st.session_state.expanded_lessons)\n",
    "\n",
    "# -----------------------------\n",
    "# Page 4: Reflection\n",
    "# -----------------------------\n",
    "if page == \"4ï¸âƒ£ Reflection\" and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"ðŸªž Teacher Reflection\")\n",
    "st.info(\"Tip: Think about how your unit design incorporates aspects of CRP. See sidebar for guidance.\")\n",
    "    with st.form(\"reflection_form\"):\n",
    "        q1 = st.text_area(\"1. How does this unit reflect the cultural identities of your students?\")\n",
    "        q2 = st.text_area(\"2. Where can students bring in multiple ways of knowing?\")\n",
    "        q3 = st.text_area(\"3. What could make this more locally meaningful?\")\n",
    "        q4 = st.text_area(\"4. What are open questions you still have about equity in this unit?\")\n",
    "        submit_reflection = st.form_submit_button(\"ðŸ’¾ Save Reflection\")\n",
    "\n",
    "    if submit_reflection:\n",
    "        st.session_state.reflection_text = f\"\"\"\n",
    "**Reflection for Unit: {st.session_state.topic}**\n",
    "\n",
    "**1. Cultural Identities:**\n",
    "{q1}\n",
    "\n",
    "**2. Multiple Ways of Knowing:**\n",
    "{q2}\n",
    "\n",
    "**3. Local Relevance:**\n",
    "{q3}\n",
    "\n",
    "**4. Open Questions:**\n",
    "{q4}\n",
    "\"\"\"\n",
    "        st.success(\"âœ… Reflection saved. Proceed to Review & Export tab.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Page 5: Review and Export\n",
    "# -----------------------------\n",
    "if page == \"5ï¸âƒ£ Review & Export\" and st.session_state.unit_output and st.session_state.expanded_lessons:\n",
    "    st.subheader(\"ðŸ“¦ Review Final Bundle\")\n",
    "st.markdown(\"ðŸ” **Reflect**: Have you addressed the principles of Culturally Responsive Pedagogy in your curriculum?\")\n",
    "    st.markdown(\"### ðŸ§¾ Unit Plan\")\n",
    "    st.markdown(st.session_state.unit_output)\n",
    "    st.markdown(\"### ðŸ§© Lessons\")\n",
    "    st.markdown(st.session_state.expanded_lessons)\n",
    "    st.markdown(\"### ðŸªž Reflection\")\n",
    "    st.markdown(st.session_state.reflection_text)\n",
    "\n",
    "    full_text = f\"\"\"\n",
    "{st.session_state.unit_output}\n",
    "\n",
    "{st.session_state.expanded_lessons}\n",
    "\n",
    "{st.session_state.reflection_text}\n",
    "\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    for line in full_text.split(\"\\n\"):\n",
    "        pdf.multi_cell(0, 10, line)\n",
    "    filename = output_dir / f\"unit_bundle_{st.session_state.topic.replace(' ', '_')}.pdf\"\n",
    "    pdf.output(str(filename))\n",
    "    with open(filename, \"rb\") as f:\n",
    "        st.download_button(\"ðŸ“„ Download Full Unit PDF\", data=f, file_name=filename.name)\n",
    "    st.success(\"âœ… Your full curriculum design has been bundled!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragtest1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
